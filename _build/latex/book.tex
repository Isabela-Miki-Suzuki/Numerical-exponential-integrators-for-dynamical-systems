%% Generated by Sphinx.
\def\sphinxdocclass{jupyterBook}
\documentclass[letterpaper,10pt,english]{jupyterBook}
\ifdefined\pdfpxdimen
   \let\sphinxpxdimen\pdfpxdimen\else\newdimen\sphinxpxdimen
\fi \sphinxpxdimen=.75bp\relax
\ifdefined\pdfimageresolution
    \pdfimageresolution= \numexpr \dimexpr1in\relax/\sphinxpxdimen\relax
\fi
%% let collapsible pdf bookmarks panel have high depth per default
\PassOptionsToPackage{bookmarksdepth=5}{hyperref}
%% turn off hyperref patch of \index as sphinx.xdy xindy module takes care of
%% suitable \hyperpage mark-up, working around hyperref-xindy incompatibility
\PassOptionsToPackage{hyperindex=false}{hyperref}
%% memoir class requires extra handling
\makeatletter\@ifclassloaded{memoir}
{\ifdefined\memhyperindexfalse\memhyperindexfalse\fi}{}\makeatother

\PassOptionsToPackage{warn}{textcomp}

\catcode`^^^^00a0\active\protected\def^^^^00a0{\leavevmode\nobreak\ }
\usepackage{cmap}
\usepackage{fontspec}
\defaultfontfeatures[\rmfamily,\sffamily,\ttfamily]{}
\usepackage{amsmath,amssymb,amstext}
\usepackage{polyglossia}
\setmainlanguage{english}



\setmainfont{FreeSerif}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Italic,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldItalic
]
\setsansfont{FreeSans}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]
\setmonofont{FreeMono}[
  Extension      = .otf,
  UprightFont    = *,
  ItalicFont     = *Oblique,
  BoldFont       = *Bold,
  BoldItalicFont = *BoldOblique,
]



\usepackage[Bjarne]{fncychap}
\usepackage[,numfigreset=1,mathnumfig]{sphinx}

\fvset{fontsize=\small}
\usepackage{geometry}


% Include hyperref last.
\usepackage{hyperref}
% Fix anchor placement for figures with captions.
\usepackage{hypcap}% it must be loaded after hyperref.
% Set up styles of URL: it should be placed after hyperref.
\urlstyle{same}


\usepackage{sphinxmessages}



        % Start of preamble defined in sphinx-jupyterbook-latex %
         \usepackage[Latin,Greek]{ucharclasses}
        \usepackage{unicode-math}
        % fixing title of the toc
        \addto\captionsenglish{\renewcommand{\contentsname}{Contents}}
        \hypersetup{
            pdfencoding=auto,
            psdextra
        }
        % End of preamble defined in sphinx-jupyterbook-latex %
        

\title{Numerical exponential integrators for dynamical systems}
\date{Sep 04, 2023}
\release{}
\author{Isabela Miki Suzuki}
\newcommand{\sphinxlogo}{\vbox{}}
\renewcommand{\releasename}{}
\makeindex
\begin{document}

\pagestyle{empty}
\sphinxmaketitle
\pagestyle{plain}
\sphinxtableofcontents
\pagestyle{normal}
\phantomsection\label{\detokenize{intro::doc}}

\begin{itemize}
\item {} 
\sphinxAtStartPar
Title:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Numerical exponential integrators for dynamical systems}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Researcher in charge:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{André Salles Carvalho, Prof. Dr.}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Beneficiary:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Isabela Miki Suzuki}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Host institution:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Instituto de Matemática e Estatística at the Universidade de São Paulo}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Research team:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{Isabela Miki Suzuki}

\sphinxAtStartPar
\sphinxstylestrong{Pedro S. Peixoto, Prof. Dr.}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Number of the research project:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{2021/06678\sphinxhyphen{}5}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Duration:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{1 August 2021 to 31 July 2023}
\begin{itemize}
\item {} 
\sphinxAtStartPar
Period covered by this research report:

\end{itemize}

\sphinxAtStartPar
\sphinxstylestrong{1 August 2022 to 26 June 2023}
\begin{itemize}
\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Summary_of_the_proposed_project::doc}]{\sphinxcrossref{Summary of the proposed project}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Project_execution::doc}]{\sphinxcrossref{Project execution}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{References::doc}]{\sphinxcrossref{References}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{Participation_in_scientific_event,_list_of_publications_and_list_of_papers_prepared_or_submitted::doc}]{\sphinxcrossref{Participation in scientific event, list of publications and list of papers prepared or submitted}}}

\item {} 
\sphinxAtStartPar
{\hyperref[\detokenize{appendix::doc}]{\sphinxcrossref{Appendix}}}

\end{itemize}

\sphinxstepscope


\chapter{Summary of the proposed project}
\label{\detokenize{Summary_of_the_proposed_project:summary-of-the-proposed-project}}\label{\detokenize{Summary_of_the_proposed_project::doc}}
\sphinxAtStartPar
This is a scientific initiation project that proposes the deep study of some of the main methods
of exponential integration for problems in dynamic systems, with emphasis on the paper {[}1{]}.
Here, the undergraduate will study the construction, analysis, implementation and application
of them and at the end, it is expected that she is familiar with modern techniques of numerical
methods.

\sphinxAtStartPar
\sphinxstylestrong{Keywords:} exponential integrator, numerical methods, dynamical systems.

\sphinxstepscope


\chapter{Project execution}
\label{\detokenize{Project_execution:project-execution}}\label{\detokenize{Project_execution::doc}}
\sphinxstepscope


\section{Motivation \sphinxhyphen{} Stiffness}
\label{\detokenize{cap1:motivation-stiffness}}\label{\detokenize{cap1::doc}}
\sphinxAtStartPar
The reason for studying exponential methods is that those are good with \(\textbf{stiff differential equations}\) in terms of precision and how small the time step is required to be to achieve good accuracy.


\subsection{Cauchy problem}
\label{\detokenize{cap1:cauchy-problem}}
\sphinxAtStartPar
A \(\textbf{Cauchy problem}\) is a ordinary differential equation (ODE) with initial conditions. Being its standard scalar form:

\sphinxAtStartPar
\(\begin{cases}
    y'(t) = f(y(t), t), t \in (t_0, T) \\
    y(t_0) = y_0 \in \mathbb{K} \text{,}
\end{cases}\)

\sphinxAtStartPar
with \(\mathbb{K}\) a field, \(f\) function with image in \(\mathbb{K}\) and \(t_0, T \in \mathbb{R}\).

\sphinxAtStartPar
Sometimes, it is convenient to separate the linear part of \(f\) as indicated below:
\begin{equation*}
\begin{split}
    f(y(t), t) = g(y(t), t) - \lambda y(t) \text{,}
\end{split}
\end{equation*}
\sphinxAtStartPar
with \(\lambda \in \mathbb{K}\) or \(\mathscr{M}_{N \times N}(\mathbb{K})\).

\sphinxAtStartPar
So the system is:

\sphinxAtStartPar
\(\begin{cases}
    y'(t) + \lambda y(t) = g(y(t), t), t \in (t_0, T) \\
    y(0) = y_0 
    \text{.}
\end{cases}\)

\sphinxAtStartPar
In this project, the stiff ones were those addressed.

\sphinxAtStartPar
Notation as in {[}1{]}.


\subsection{Stiffness}
\label{\detokenize{cap1:stiffness}}
\sphinxAtStartPar
The error of the approximation given by a method trying to estimate the solution of a Cauchy problem is always given by a term multiplied by a higher derivative of the exact solution, because of the Taylor expansion with Lagrange form of the remainder. In that way, if that is enough information about this derivative, the error can be estimated.

\sphinxAtStartPar
If the norm of the derivative increases with the time, but the exact solution doesn’t, that is possible that the error dominates the approximation and the precision is lost. Those problems are called \(\textbf{stiff equations}\).

\sphinxAtStartPar
Between them, there are the \(\textbf{stiff differential equations}\), that have exact solution given by the sum of a \(\textit{transient solution}\) with a \(\textit{steady state solution}\).

\sphinxAtStartPar
The \(\textbf{transient solution}\) is of the form:
\begin{equation*}
\begin{split}
    e^{-ct} \text{, with c >>1, }
\end{split}
\end{equation*}
\sphinxAtStartPar
which is known to go to zero really fast as t increases. But its \(n\)th derivative
\begin{equation*}
\begin{split}
    \mp c^{n}e^{-ct}
\end{split}
\end{equation*}
\sphinxAtStartPar
doesn’t go as quickly and may increase in magnitude.

\sphinxAtStartPar
The \(\textbf{steady state solution}\), however, as its name implies, have small changes as time passes, with higher derivative being almost constant zero.

\sphinxAtStartPar
In a system of ODE’s, these characteristics are most common in problems in which the solution of the initial value problem is of the form
\begin{equation*}
\begin{split}
    e^{A}
\end{split}
\end{equation*}
\sphinxAtStartPar
being \(A\) a matrix such that \(\lambda_{min}\) and \(\lambda_{max}\) are the eigenvalue with minimum and maximum value in modulus and \(\lambda_{min} << \lambda_{max}\). On the bigger magnitude eigenvalue direction, the behaviour is very similar to the transient solution, having drastic changes over time and on the smaller one, comparing to that, changes almost nothing as times passes, like the steady state solution.

\sphinxAtStartPar
Work around these problems and being able to accurately approximate these so contrasting parts of the solutions requires more robust methods than the more classic and common one\sphinxhyphen{}step methods addressed at the beginning of the study of numerical methods for Cauchy problems. For the systems, it is also required that that is a precise way to calculate the exponential of a matrix.

\sphinxAtStartPar
In this project, we studied the \(\textbf{exponential methods}\), their capabilities to deal with these problems and the comparision with other simpler methods.

\sphinxAtStartPar
Definition from {[}2{]}.

\sphinxstepscope


\section{Classical methods}
\label{\detokenize{cap2:classical-methods}}\label{\detokenize{cap2::doc}}
\sphinxAtStartPar
In order to show that the exponential methods improve in dealing with Stiff problems, that is necessary to know how the previows methods deal with them, so a review on the theory of the classical methods is made in this chapter. In particular there will be focus on the one step methods. All the information is from {[}3{]}.


\subsection{One step methods for ODE}
\label{\detokenize{cap2:one-step-methods-for-ode}}
\sphinxAtStartPar
In order to find a approximation for the solution of the problem
\(\begin{cases}
y'(t) = f(t, y(t)), t \in [t_0,T] \\
y(t_0)=y_0 \text{,}
\end{cases}\)

\sphinxAtStartPar
they are of the form:
\begin{equation*}
\begin{split}
y_{k+1} = y_{k} + h \phi (t_{k},y_{k},t_{k+1},y_{k+1},h) \text{,}
\end{split}
\end{equation*}
\sphinxAtStartPar
with
\begin{equation*}
\begin{split}k = 0, 1, ..., n-1;\end{split}
\end{equation*}\begin{equation*}
\begin{split}
N \in \mathbb{N}; h = \frac{T-t_0}{N}; \\
\{t_i = t_0 + ih : i = 0, 1, ..., N\}; \\ 
y_n \thickapprox y(t_n) .
\end{split}
\end{equation*}
\sphinxAtStartPar
To analyse the method, there is a model problem
\begin{equation*}
\begin{split}
\begin{cases}
    y'(t) = - \lambda y(t) \text{ ; } t \in[t_0,T]\\ 
    y(t_0)=y_0,\\
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
whose solution is \(y(t) = y_0 e^{-\lambda (t-t_0)}\)
with \(\lambda > 0.\)

\sphinxAtStartPar
If that is possible to manipulate the method so that, for this problem, can be written as \(y_{k+1} = \zeta(\lambda,h) y_k,\)

\sphinxAtStartPar
then \(\zeta(\lambda,h)\) is called \(\textbf{amplification factor}\) of the method.

\sphinxAtStartPar
By induction, it gives
\begin{equation*}
\begin{split}
y_{k+1} = \zeta(\lambda, h)^{k+1} y_0.
\end{split}
\end{equation*}
\sphinxAtStartPar
It is well known that this expression only converges as k goes to infinity if \( |\zeta(\lambda, h)| < 1\)

\sphinxAtStartPar
and then converges to zero.

\sphinxAtStartPar
When it occurs, i.e.,
\begin{equation*}
\begin{split}
    k \rightarrow \infty \Rightarrow y_k \rightarrow 0
\end{split}
\end{equation*}
\sphinxAtStartPar
such as the exact solution
\begin{equation*}
\begin{split}
    y(t) = y_0 e^{-\lambda (t-t_0)},
\end{split}
\end{equation*}
\sphinxAtStartPar
it is said that there is \(\textbf{stability}\).

\sphinxAtStartPar
The interval with the values of \(\lambda h\) such as
\begin{equation*}
\begin{split}
|\zeta(\lambda, h)|<1,
\end{split}
\end{equation*}
\sphinxAtStartPar
is called \(\textbf{interval of stability}\).

\sphinxAtStartPar
And if the interval of stability contains all the points \(z\) such that
\begin{equation*}
\begin{split}
    Re(z) < 0,
\end{split}
\end{equation*}
\sphinxAtStartPar
the method is said \(\textbf{A-stable}\).

\sphinxAtStartPar
The reason for taking this specific problem is that it models the behaviour of the difference between the approximation and the solution on a small neighbourhood of any Cauchy problem:

\sphinxAtStartPar
Taking
\begin{equation*}
\begin{split}
\begin{cases}
    y'(t) = f(y(t), t), t \in (t_0, T) \\
    y(t_0) = y_0 \in \mathbb{K}
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
and a approximation \(z\) of the solution \(y\), doing
\$\(
\sigma(t) = z(t) - y(t) \Rightarrow
\)\$
\begin{equation*}
\begin{split}
\dot{\sigma}(t) = \dot{z}(t) - \dot{y}(t) = f(z(t), t) - f(y(t), t) \Rightarrow
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\dot{\sigma}(t) + \dot{y}(t) = \dot{z}(t) = f(z(t), t) = f(y(t)+\sigma(t), t)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
 = f(y(t), t) + \sigma(t)\frac{\partial f}{\partial y} + O(\sigma^2(t)),
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
\begin{cases}
    \dot{\sigma}(t) \approx \sigma(t) \frac{\partial f}{\partial y} (y(t), t) \\
    \sigma(t_k) = \sigma_k.
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
Other important definitions are:

\sphinxAtStartPar
\(\textbf{Local truncation error:}\) Is the difference between the exact expression and its numerical approximation in a certain point and with a certain domain discretization. If the domain is equally spaced by \(h\) is often denoted by \(\tau(h,t_0)\) being \(t_0\) the point.

\sphinxAtStartPar
\(\textbf{Order of the local truncation error:}\) the local truncation error (which depends on the \(h\) spacing of the discretized domain) \(\tau(h)\) has order \(n \in \mathbb{N}\) if \(\tau(h) = O(h^n) \), i.e., if there is constant \(M \in \mathbb{R}\) and \(h_0 \in \mathbb{R}\) such that \(\tau(h) \leq M h^n\), \(\forall h \leq h_0\).

\sphinxAtStartPar
\(\textbf{Global error:}\) Is the difference between the approximation given by the method for the solution of the problem on a certain point and the exact one (unlike the local truncation error, here we take the solution we got, not the expression used to find the approximation).

\sphinxAtStartPar
\(\textbf{Consistency:}\) The method is said consistent if \(\lim _{h \to 0} \frac{1}{h}\tau(h,x_0) = 0\).

\sphinxAtStartPar
\(\textbf{Obs.:}\) For consistency, we usually only analyse for the linear part of the Cauchy problem, since this is the part that most influences in the consistency.

\sphinxAtStartPar
\(\textbf{Order of consistency:}\) is the smallest order (varying the points at which the local error is calculated) of the local truncation error.

\sphinxAtStartPar
\(\textbf{Convergence:}\) A numerical method is convergent if, and only if, for any well\sphinxhyphen{}posed Cauchy problem and for every \(t \in (t_0, T)\),
\begin{equation*}
\begin{split}\lim_{h \to 0} e_k = 0\end{split}
\end{equation*}
\sphinxAtStartPar
with \(t - t_0 = kh\) fixed and \(e_k\) denoting the global error on \(t_k\) (following the past notation).

\sphinxAtStartPar
\(\textbf{Theorem:}\) A one\sphinxhyphen{}step explicit method given by
\begin{equation*}
\begin{split}
y_0 = y(t_0) \\
y_{k+1} = y_{k} + h \phi (t_{k},y_{k},h)
\end{split}
\end{equation*}
\sphinxAtStartPar
such that \(\phi\) is Lipschitzian in y, continuous in their arguments, and consistent for any well\sphinxhyphen{}posed Cauchy problem is convergent. Besides that, the convergence order is greater or equal to the consistency order.

\sphinxAtStartPar
\(\textit{Prove:}\) {[}3{]} pág 29\sphinxhyphen{}31.


\subsection{Examples}
\label{\detokenize{cap2:examples}}
\sphinxAtStartPar
Euler method:
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = f(t_{k},y_{k})
\end{split}
\end{equation*}
\sphinxAtStartPar
Modified Euler method:
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = \frac{1}{2} \left[ f(t_{k},y_{k}) + f(t_{k+1},y_{k} + h f(t_{k},y_{k})) \right]
\end{split}
\end{equation*}
\sphinxAtStartPar
Midpoint method:
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = f(t_{k} + \frac{h}{2},y_{k} + \frac{h}{2} f(t_{k},y_{k}))
\end{split}
\end{equation*}
\sphinxAtStartPar
Classic Runge\sphinxhyphen{}Kutta (RK 4\sphinxhyphen{}4):
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = \frac{1}{6} \left( \kappa_1 + 2 \kappa_2 + 2 \kappa_3 + \kappa_4 \right), \text{with }\\
    \kappa_1 = f(t_{k},y_{k})\\
    \kappa_2 = f(t_{k} + \frac{h}{2},y_{k} + \frac{h}{2} \kappa_1)\\
    \kappa_3 = f(t_{k} + \frac{h}{2},y_{k} + \frac{h}{2} \kappa_2)\\
    \kappa_4 = f(t_{k} + h, y_{k} + h \kappa_3)
\end{split}
\end{equation*}
\sphinxAtStartPar
Further detailing the Euler mathod, explicit one\sphinxhyphen{}step method of
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = f(t_{k},y_{k}),
\end{split}
\end{equation*}
\sphinxAtStartPar
an analysis on stability, convergence and order of convergence is done on the appendix.

\sphinxstepscope


\section{Important concepts for the study of exponential methods}
\label{\detokenize{cap3:important-concepts-for-the-study-of-exponential-methods}}\label{\detokenize{cap3::doc}}
\sphinxAtStartPar
In this chapter, a review on matrix exponential is done, essencial for the linear problems treated here, followed by a section of \(\phi\) functions, because of its need when applying exponential methods in systems of ODE with initial value. Besides that, the format of the treated problem is shown.


\subsection{Matrix exponential}
\label{\detokenize{cap3:matrix-exponential}}
\sphinxAtStartPar
This part has information from {[}4{]}.

\sphinxAtStartPar
Based on the Maclaurin series of the exponential function
\begin{equation*}
\begin{split}
    e^x = \sum_{i=0}^{\infty} \frac{x^i}{i!},
\end{split}
\end{equation*}
\sphinxAtStartPar
the \(\textbf{exponential of a square complex matrix }A\) is defined as
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!}.
\end{split}
\end{equation*}
\sphinxAtStartPar
This is well defined because it has been proven that the sequence \({p_k}\) with, \(\forall k \in \mathbb{N}\):
\begin{equation*}
\begin{split}
    p_k = \sum_{i=0}^{k} \frac{A^i}{i!}, \forall A \text{ as decribed above,}
\end{split}
\end{equation*}
\sphinxAtStartPar
is a Cauchy sequence, and therefore converge to a limit matrix which was denoted \(e^A\), since the set of the square complex matrix with fixed lenght with the norm
\begin{equation*}
\begin{split}
||A|| = \max_{||x||=1} ||Ax||
\end{split}
\end{equation*}
\sphinxAtStartPar
is a Banach space.


\subsubsection{Exponential of a zeros matrix}
\label{\detokenize{cap3:exponential-of-a-zeros-matrix}}
\sphinxAtStartPar
If \(A =   
\left[ {\begin{array}{ccccc}
    0 & 0 & 0 & \dotsm & 0\\
    0 & 0 & 0 & \dotsm & 0\\
    0 & 0 & 0 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & 0\\
\end{array} } \right] \),
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = I + A + \frac{A^2}{2} + \dotsm = I + 0 + 0 + \dotsm = I.
\end{split}
\end{equation*}

\subsubsection{Exponential of a diagonal matrix}
\label{\detokenize{cap3:exponential-of-a-diagonal-matrix}}
\sphinxAtStartPar
If \(A =   
\left[ {\begin{array}{ccccc}
    \lambda_1 & 0 & 0 & \dotsm & 0\\
    0 & \lambda_2 & 0 & \dotsm & 0\\
    0 & 0 & \lambda_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_{N}\\
\end{array} } \right] 
  = diag(\lambda_1, \lambda_2, \lambda_3, \dotsm, \lambda_N)\),

\sphinxAtStartPar
it is easy to note that
\begin{equation*}
\begin{split}
    A^2 = diag \left(\lambda_1^2, \lambda_2^2, \lambda_3^2, \dotsc, \lambda_N^2 \right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^3 = diag \left(\lambda_1^3, \lambda_2^3, \lambda_3^3, \dotsc, \lambda_N^3 \right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\vdots
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^j = diag \left(\lambda_1^j, \lambda_2^j, \lambda_3^j, \dotsc, \lambda_N^j \right) , \forall j \in \mathbb{N}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\vdots
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = diag\left(\sum_{i=0}^{\infty} \frac{\lambda_1^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_2^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_3^i}{i!}, \dotsc, \sum_{i=0}^{\infty} \frac{\lambda_N^i}{i!}\right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = diag \left( e^{\lambda_1}, e^{\lambda_2}, e^{\lambda_3}, \dotsc, e^{\lambda_N} \right).
\end{split}
\end{equation*}
\sphinxAtStartPar
In the same way, if B is a diagonal by blocks matrix:
\begin{equation*}
\begin{split}
B =   
\left[ {\begin{array}{ccccc}
    B_1 & 0 & 0 & \dotsm & 0\\
    0 & B_2 & 0 & \dotsm & 0\\
    0 & 0 & B_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & B_{N}\\
\end{array} } \right] 
  = diag(B_1, B_2, B_3, \dotsm, B_N),
\end{split}
\end{equation*}
\sphinxAtStartPar
then
\begin{equation*}
\begin{split}
e^B = diag(e^{B_1}, e^{B_2}, e^{B_3}, \dotsm, e^{B_N}).
\end{split}
\end{equation*}

\subsubsection{Exponential of a matrix of ones above the diagonal}
\label{\detokenize{cap3:exponential-of-a-matrix-of-ones-above-the-diagonal}}
\sphinxAtStartPar
If \(A = A_{N \times N} =   
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] \),

\sphinxAtStartPar
one can calculate
\begin{equation*}
\begin{split}
A^2 = A \cdot A =  
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right]  \cdot 
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  =   \left[ {\begin{array}{ccccccc}
    0 & 0 & 1 &  &  &  & \\
     & 0 & 0 & 1 &  &  &\\
     &  & 0 & 0 & 1 &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & 1 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right], 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^3 = A \cdot A^2 = \left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccccc}
    0 & 0 & 1 &  &  &  & \\
     & 0 & 0 & 1 &  &  &\\
     &  & 0 & 0 & 1 &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & 1 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccccc}
    0 & 0 & 0 & 1 &  &  & \\
     & 0 & 0 & 0 & 1 &  &\\
     &  & 0 & 0 & 0 & \ddots &\\
     &  &  & 0 & 0 & \ddots & 1\\
     &  &  &  & 0 & \ddots & 0 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    \vdots
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N-2} = \left[ {\begin{array}{ccccccc}
     &  &  &  & 0 & 1 & 0\\
     &  &  &  &  & 0 & 1 \\
     &  &  &  &  &  & 0 \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N-1} = \left[ {\begin{array}{ccccccc}
     &  &  &  &  &  & 1\\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N} = 0.
\end{split}
\end{equation*}
\sphinxAtStartPar
And then, with \(t \in \mathbb{R}\)
\begin{equation*}
\begin{split}
    e^{tA} \doteq \sum_{i=0}^{\infty} \frac{tA^i}{i!}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = Id + tA + \frac{t^2 A^2}{2} + \frac{t^3 A^3}{6} + \dotsc + \frac{t^{N-2} A^{N-2}}{(N-2)!} + \frac{t^{N-1} A^{N-1}}{(N-1)!} + 0 + 0 + \dotsc + 0
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 &  &  &  &  &  & \\
     & 1 &  &  &  &  &\\
     &  & 1 &  &  &  &\\
     &  &  & 1 &  &  &\\
     &  &  &  & 1 &  &\\
     &  &  &  &  & \ddots &\\
     &  &  &  &  &  & 1 \\
\end{array} } \right] + \left[ {\begin{array}{ccccccc}
    0 & t &  &  &  &  & \\
     & 0 & t &  &  &  &\\
     &  & 0 & t &  &  &\\
     &  &  & 0 & t &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & t \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] + 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \left[ {\begin{array}{ccccccc}
    0 & 0 & \frac{t^2}{2} &  &  &  & \\
     & 0 & 0 & \frac{t^2}{2} &  &  &\\
     &  & 0 & 0 & \frac{t^2}{2} &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & \frac{t^2}{2} \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] + \dotsc + \left[ {\begin{array}{ccccccc}
     &  &  &  &  &  & \frac{t^{N-1}}{(N-1)!}\\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right]
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 & t & \frac{t^2}{2} & \frac{t^3}{3!} & \frac{t^4}{4!} & \dotsc & \frac{t^{N-1}}{(N-1)!}\\
     & 1 & t & \frac{t^2}{2} & \frac{t^3}{3!} & \ddots & \vdots \\
     &  & 1 & t & \frac{t^2}{2} & \ddots & \frac{t^4}{4!}\\
     &  &  & 1 & t & \ddots & \frac{t^3}{3!}\\
     &  &  &  & 1 & \ddots & \frac{t^2}{2} \\
     &  &  &  &  & \ddots & t \\
     &  &  &  &  &  & 1 \\
\end{array} } \right].
\end{split}
\end{equation*}

\subsubsection{Exponential of a Jordan block}
\label{\detokenize{cap3:exponential-of-a-jordan-block}}
\sphinxAtStartPar
\(\textbf{Proposition:}\) \(A_1, A_2 \in \mathscr{M}_{N \times N}(\mathbb{C})\). If \(A_1 \cdot A_2 = A_2 \cdot A_1\), then \(e^{A_1+A_2} = e^{A_1} \cdot e^{A_2}\).

\sphinxAtStartPar
A Jordan block is of the form:
\$\(
J = \left[ {\begin{array}{ccccc}
    \lambda_i & 1 & 0 & \dotsm & 0\\
    0 & \lambda_i & 1 & \dotsm & 0\\
    0 & 0 & \lambda_i & \ddots & 0\\
    \vdots & \vdots & \vdots & \ddots & 1\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] 
\)\$
\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] + \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = D + N,
\end{split}
\end{equation*}
\sphinxAtStartPar
and
\$\(
\left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] 
\)\$
\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    0 & \lambda_i &  &  & \\
     & 0 & \lambda_i &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & \lambda_i\\
     &  &  &  & 0\\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right],
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
    e^{tJ} = e^{tD+tN} = e^{tD} \cdot e^{tN}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} & 0 & 0 & \dotsm & 0\\
    0 & e^{t \lambda_i} & 0 & \dotsm & 0\\
    0 & 0 & e^{t \lambda_i} & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & e^{t \lambda_i}\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    1 & t & \frac{t^2}{2} & \dotsc & \frac{t^{N-1}}{(N-1)!}\\
     & 1 & t & \ddots & \vdots\\
     &  & 1 & \ddots & \frac{t^2}{2} \\
     &  &  & \ddots & t \\
     &  &  &  & 1 \\
\end{array} } \right]
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} & e^{t \lambda_i}t & \frac{e^{t \lambda_i} t^2}{2} & \dotsc & \frac{e^{t \lambda_i} t^{N-1}}{(N-1)!}\\
     & e^{t \lambda_i} & e^{t \lambda_i} t & \ddots & \vdots\\
     &  & e^{t \lambda_i} & \ddots & \frac{e^{t \lambda_i} t^2}{2} \\
     &  &  & \ddots & e^{t \lambda_i} t \\
     &  &  &  & e^{t \lambda_i} \\
\end{array} } \right], t \in \mathbb{R}.
\end{split}
\end{equation*}

\subsubsection{Exponential of any matrix}
\label{\detokenize{cap3:exponential-of-any-matrix}}
\sphinxAtStartPar
\(\textbf{Proposition: } \forall A \in \mathscr{M}_{N \times N}(\mathbb{C}), \exists M \in \mathscr{M}_{N \times N}(\mathbb{C})\) invertible, such that \(A = MJM^{-1}\), with
\begin{equation*}
\begin{split} 
J = \left[ {\begin{array}{ccccc}
    J_1 & 0 & 0 & \dotsm & 0\\
    0 & J_2 & 0 & \dotsm & 0\\
    0 & 0 & J_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & J_{N}\\
\end{array} } \right]
\end{split}
\end{equation*}
\sphinxAtStartPar
and each \(J_i\), \(i = 1, 2, 3, \dotsc, N\) being a Jordan block, i.e.,
\begin{equation*}
\begin{split}
J_i = \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right]
\end{split}
\end{equation*}
\sphinxAtStartPar
for some \(\lambda_i \in \mathbb{C}\) .

\sphinxAtStartPar
Note that
\$\(
    (MJM^{-1})^k = MJM^{-1}MJM^{-1}MJM^{-1} \dotsc MJM^{-1} 
\)\$
\begin{equation*}
\begin{split}
    = MJIJIJM^{-1} \dotsc MJM^{-1} = MJJJ \dotsc JM^{-1} = MJ^kM^{-1}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Because of the formula of the series that defines the expansion, it implicates in \(e^{MJM^{-1}} = M e^J M^{-1}\).

\sphinxAtStartPar
And then, using the same notation from the last proposition,
\$\(
e^{tA} = e^{tMJM^{-1}} = e^{MtJM^{-1}} = Me^{tJ}M^{-1} 
\)\$
\begin{equation*}
\begin{split}
    = M \left[ { \begin{array}{ccccc}
        e^{tJ_1} & 0 & 0 & \dotsm & 0\\
        0 & e^{tJ_2} & 0 & \dotsm & 0\\
        0 & 0 & e^{tJ_3} & \dotsm & 0\\
        \vdots & \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & 0 & \dotsm & e^{tJ_{N}}\\
    \end{array} } \right] M^{-1}, t \in \mathbb{R},
\end{split}
\end{equation*}
\sphinxAtStartPar
with each block as the section above indicates.


\subsection{Linear problem}
\label{\detokenize{cap3:linear-problem}}
\sphinxAtStartPar
The linear problem is, following with the used notation:
\begin{equation*}
\begin{split}
\begin{cases}
    y'(t) + \lambda y(t) = g(y(t), t), t \in (t_0, T) \\
    y(t_0) = y_0 
    \text{,}
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
the one with \(g \equiv 0.\)

\sphinxAtStartPar
So, generaly, it is of the form:
\begin{equation*}
\begin{split}
\begin{cases}
    y'(t) = A y(t), t \in (t_0, T) \\
    y(t_0) = y_0 
    \text{,}
\end{cases}
\end{split}
\end{equation*}
\sphinxAtStartPar
with \(A \in \mathscr{M}_{N \times N}(\mathbb{C}), N \in \mathbb{N}\)  (remembering that a matrix \(1 \times 1\) is simply a number).

\sphinxAtStartPar
Because \(A y(t)\) is a \(C^1\) function in \(y\), continuous in \(t\) and \(t \in (t_0, T)\), a limited interval, by the existence and uniqueness theorem, there is a single solution of the problem.

\sphinxAtStartPar
Since
\begin{equation*}
\begin{split}
    \frac{d}{dt}y_0e^{A(t-t_0)} \doteq \lim_{h\to0} \frac{y_0e^{A(t-t_0+h)}-y_0e^{A(t-t_0)}}{h}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = y_0e^{(t-t_0)A}\lim_{h\to0} \frac{e^{Ah}-I}{h} 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = y_0e^{(t-t_0)A}\lim_{h\to0} \frac{Ae^{Ah}}{1} 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = y_0e^{(t-t_0)A} \frac{Ae^{A0}}{1}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = y_0e^{(t-t_0)A} A I = A y_0e^{(t-t_0)A} 
\end{split}
\end{equation*}
\sphinxAtStartPar
using L’Hôpital’s rule on the second equality and noting that \(A(t-t_0+h) = A(t-t_0)+Ah\) and \(A(t-t_0) \cdot Ah = (t-t_0)hAA = Ah \cdot A(t-t_0)\), so it was possible to apply the last proposition and make \(e^{A(t-t_0+h)} = e^{A(t-t_0)} \cdot e^{Ah}\),

\sphinxAtStartPar
taking
\begin{equation*}
\begin{split}
    y(t) = y_0e^{A(t-t_0)},
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    y'(t) = A y_0 e^{(t-t_0)A} = A y(t) \text{ and } y(t_0) = y_0 e^{(t_0-t_0)A} = y_0 I = y_0.
\end{split}
\end{equation*}
\sphinxAtStartPar
So, the solution for the general linear problem is \(y(t)=y_0 e^{A(t-t_0)}\).

\sphinxAtStartPar
All information about matrix exponential is from {[}4{]}.


\subsection{General problem}
\label{\detokenize{cap3:general-problem}}
\sphinxAtStartPar
Returning to the general case

\sphinxAtStartPar
\(\begin{cases}
    y'(t) + \lambda y(t) = g(y(t), t), t \in (t_0, T) \\
    y(t_0) = y_0 
    \text{,}
\end{cases}\)

\sphinxAtStartPar
there is the variation of constants formula:
\begin{equation*}
\begin{split}
    y(t) = e^{-t \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau.
\end{split}
\end{equation*}
\sphinxAtStartPar
This well known implicit function, gives a solution of the problem.

\sphinxAtStartPar
If the integral part can be solved, there is a explicit solution, and if the problem satisfies the hypotesis of the Piccard problem, being Lipschitz in \(t\), this is the only solution.

\sphinxAtStartPar
This formula is the basis of all the exponential methods.


\subsection{\protect\(\phi\protect\) functions}
\label{\detokenize{cap3:phi-functions}}
\sphinxAtStartPar
Before introducing exponential methods, it is useful to present the \(\phi\) functions.

\sphinxAtStartPar
They are \(\mathbb{C} \rightarrow \mathbb{C}\) functions defined as:
\begin{equation*}
\begin{split}
  \phi_0 (z) = e^z;
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  \phi_n (z) = \int_{0}^{1} e^{(1-\tau)z} \frac{\tau^{n-1}}{(n-1)!} \,d\tau, n \geq 1.
\end{split}
\end{equation*}
\sphinxAtStartPar
By integration by parts,
\begin{equation*}
\begin{split}
  \phi_{n+1} (z) = \int_{0}^{1} e^{(1-\tau)z} \frac{\tau^n}{n!} \,d\tau \\
  = - \frac{e^{(1-1)z}}{z} \frac{1^n}{n!} + \frac{e^{(1-0)z}}{z} \frac{0^n}{l!} - \int_{0}^{1} -\frac{e^{(1-\tau)z}}{z} \frac{\tau^{n-1}}{(n-1)!} \,d\tau \\
  = - \frac{1}{n!z} + \frac{1}{z}\int_{0}^{1} e^{(1-\tau)z} \frac{\tau^{n-1}}{(n-1)!} \,d\tau.
\end{split}
\end{equation*}
\sphinxAtStartPar
Since
\begin{equation*}
\begin{split}
  \phi_n(0) = \int_{0}^{1} e^0 \frac{\tau^{n-1}}{(n-1)!} \,d\tau = \int_{0}^{1} \frac{\tau^{n-1}}{(n-1)!} \,d\tau = \frac{1^n}{n!} - 0 = \frac{1}{n!},
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  \phi_{n+1}(z) = \frac{\phi_n(z) - \phi_n(0)}{z}, \textbf{the recursive characterization}.
\end{split}
\end{equation*}
\sphinxAtStartPar
By the properties of integral {[}5{]}, if \(h \in \mathbb{R}^*, t_k \in \mathbb{R}, t_k+h = t_{k+1},\)
\begin{equation*}
\begin{split}
  \phi_n (z) = \int_{0}^{1} e^{(1-\tau)z} \frac{\tau^{n-1}}{(n-1)!} \,d\tau \\
  = \frac{1}{h}\int_{0}^{h} e^{\frac{(h-\tau)z}{h}} \frac{\tau^{n-1}}{h^{n-1}(n-1)!} \,d\tau \\
  = \frac{1}{h}\int_{t_k}^{t_k + h} e^{\frac{(h-\tau+t_k)z}{h}} \frac{(\tau - t_k)^{n-1}}{h^{n-1}(n-1)!} \,d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  \phi_n (z) = \frac{1}{h^l}\int_{t_k}^{t_{k+1}} e^{\frac{1}{h}(t_{k+1}-\tau)z} \frac{(\tau - t_k)^{n-1}}{(n-1)!} \,d\tau.
\end{split}
\end{equation*}
\sphinxAtStartPar
Information from {[}1{]}.

\sphinxstepscope


\section{Exponential methods}
\label{\detokenize{cap4:exponential-methods}}\label{\detokenize{cap4::doc}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
from basecode import *
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{n}{Cell} \PYG{n}{In}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{line} \PYG{l+m+mi}{1}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{k+kn}{from} \PYG{n+nn}{basecode} \PYG{k+kn}{import} \PYG{o}{*}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}basecode\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
In this chapter, exponential methods are introduced, with further analysis of some of them, being tested and compared to more classical equivalents.

\sphinxAtStartPar
All the codes that created the convergence and deduction tables are in the appendix.

\sphinxAtStartPar
The stiff problem used in all the convergence tables is the following one taken from {[}1{]}:
\begin{equation*}
\begin{split}
    u'(t) + 100 u(t) = \sin(t)\\
    u(0) = 1.
\end{split}
\end{equation*}
\sphinxAtStartPar
Solution:
\begin{equation*}
\begin{split}
u(t) = \exp(-100t)+\frac{\exp(-100t)+100\sin(t)-\cos(t)}{1+100^2}.
\end{split}
\end{equation*}

\subsection{Exponential Euler method}
\label{\detokenize{cap4:exponential-euler-method}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2).
\end{split}
\end{equation*}
\sphinxAtStartPar
Table of convergence:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
4.398075514689716e\sphinxhyphen{}05
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
2.074422525626487e\sphinxhyphen{}05
&
\sphinxAtStartPar
1.0841625981445133
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
1.0056221183126109e\sphinxhyphen{}05
&
\sphinxAtStartPar
1.0446214904461004
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar

&
\sphinxAtStartPar

\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
The table proved the order of conergence given by the deduction, and, comparing to the one of the classic Euler method:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
0.2391072699739873
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
0.08650412059872986
&
\sphinxAtStartPar
1.466817233501749
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
0.039214210532948934
&
\sphinxAtStartPar
1.1413923006132296
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar
0.018739566082401515
&
\sphinxAtStartPar
1.0652890085799935
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
the exponential one has much better approximations since the beginning, proving the efficiency of the exponential method.


\subsection{Exponential time differencing methods (ETD)}
\label{\detokenize{cap4:exponential-time-differencing-methods-etd}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
h\phi_1(-\lambda h) g(y(t_k), t_k) +
h^2\phi_2(-\lambda h) \frac{dg}{dt}(y(t_k), t_k) +
h^3\phi_3(-\lambda h)\frac{d^2g}{dt^2} (y(t_k), t_k) +
\dotsi + \\
h^n\phi_n(-\lambda h) \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)+
O(h^{n+1}).
\end{split}
\end{equation*}
\sphinxAtStartPar
It is possible to note that the exponential euler is essentially the exponential time differencing method of order 1.

\sphinxAtStartPar
In the same way as Taylor methods, the problem here is that at the expense of a higher order of convergence, ends up requiring the evaluation and implementation of multiple derivatives that may not even be easy to calculate. It can be avoided using Runge\sphinxhyphen{}Kutta methods, the next to be analyzed.


\subsection{Exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping}
\label{\detokenize{cap4:exponential-time-differencing-methods-with-runge-kutta-time-stepping}}
\sphinxAtStartPar
Here, the exponential Runge\sphinxhyphen{}Kutta were compared to methods from deductions following the classic runge\sphinxhyphen{}kutta approach in the constant variation formula.

\sphinxAtStartPar
All convergence tables prove the deduced order.

\sphinxAtStartPar
However, it is remarkable how much better the exponential methods are in relation to the new ones presented here, showing that we cannot be naive and apply the integral approximations expecting an exponential Runge\sphinxhyphen{}Kutta performance, the treatment must be exact for the linear part, as is done in all exponential methods.


\subsubsection{Exponential \sphinxhyphen{} Trapezoidal rule}
\label{\detokenize{cap4:exponential-trapezoidal-rule}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h) + \\
  + O(h^3) \\
  \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Convergence table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
4.186569175362864e\sphinxhyphen{}08
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
1.0575183428604418e\sphinxhyphen{}08
&
\sphinxAtStartPar
1.985085775819591
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
2.652380943352073e\sphinxhyphen{}09
&
\sphinxAtStartPar
1.9953227875115886
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar
6.638462730912398e\sphinxhyphen{}10
&
\sphinxAtStartPar
1.9983668943519293
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Naive deduction \sphinxhyphen{} Trapezoidal rule}
\label{\detokenize{cap4:naive-deduction-trapezoidal-rule}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right] +  O(h^3) \\
    \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}
\end{equation*}
\sphinxAtStartPar
Convergence table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
0.0004242643044311458
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
0.00010714498082271644
&
\sphinxAtStartPar
1.9853990333325726
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
2.6871031228085582e\sphinxhyphen{}05
&
\sphinxAtStartPar
1.9954406751889993
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar
6.725136514989377e\sphinxhyphen{}06
&
\sphinxAtStartPar
1.9984162299862431
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}


\subsubsection{Exponential \sphinxhyphen{} Third order}
\label{\detokenize{cap4:exponential-third-order}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(c'_k, t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) + %ok
  \left[g(c_k, t_{k+1}) - g(y(t_k), t_k)\right]
  \left( h \phi_2 (-h \lambda) - \frac{h \phi_1(-h \lambda)}{2} \right) +
  \\
  + 4 \left[g(c_k, t_{k+1}) + g(y(t_k), t_k) - 2 g\left(c'_k, t_{k+\frac{1}{2}}\right) \right]
  \left( h \phi_3 (-h \lambda) + \frac{h \phi_1(-h \lambda)}{8} - \frac{h \phi_2(-h \lambda)}{2} \right) + O(h^4),
\end{split}
\end{equation*}
\sphinxAtStartPar
with
\begin{equation*}
\begin{split}
  c_k = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h),
  \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1(-h\lambda),
  \\
  c'_k = e^{- \frac{h \lambda}{2}} y(t_k) +
  \frac{h}{2} \phi_1 \left(- \frac{\lambda h}{2} \right) g(y(t_k), t_k) +
  \left[g\left(a'_k, t_{k+\frac{1}{2}}\right) - g(y(t_k), t_k) \right] \frac{h}{2} \phi_2 \left(-\frac{\lambda h}{2}\right),
  \\
  a'_k = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left(-\frac{h \lambda}{2}\right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Convergence table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
5.0853024048669315e\sphinxhyphen{}12
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
3.212833644961055e\sphinxhyphen{}13
&
\sphinxAtStartPar
3.9844153810116354
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
2.0132983821752326e\sphinxhyphen{}14
&
\sphinxAtStartPar
3.996213373698299
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar
1.2602766052971504e\sphinxhyphen{}15
&
\sphinxAtStartPar
3.997748687591092
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Better than what expected, giving order 4.


\subsubsection{Naive deduction \sphinxhyphen{} Trapezoidal rule}
\label{\detokenize{cap4:id1}}
\sphinxAtStartPar
Expression:
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda h} g(y(t_k), t_k) + 4 e^{-\frac{ \lambda h}{2}} g\left( b'_{k}, t_k + \frac{h}{2} \right) + g(b_k, t_{k+1}) \right] +  O(h^4), \\
  \text{with } b'_{k} = e^{- \frac{h \lambda}{2}}y(t_k) + \frac{h}{4} \left[ e^{- \frac{h \lambda}{2}} g(y(t_k), t_k) + g \left(a'_{k}, t_k + \frac{h}{2} \right) \right], \\
  b_k = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right], \\
  a'_{k} = e^{- \frac{h \lambda}{2}} y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1 \left(-\lambda \frac{h}{2} \right), \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}
\end{equation*}
\sphinxAtStartPar
Convergence table:


\begin{savenotes}\sphinxattablestart
\centering
\begin{tabulary}{\linewidth}[t]{|T|T|T|T|}
\hline
\sphinxstyletheadfamily 
\sphinxAtStartPar
n
&\sphinxstyletheadfamily 
\sphinxAtStartPar
h = \(\frac{1}{h}\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
\(\tau(0,h)\)
&\sphinxstyletheadfamily 
\sphinxAtStartPar
q = \(\frac{tau(0,h)}{tau(0, 2h)}\)
\\
\hline
\sphinxAtStartPar
128
&
\sphinxAtStartPar
0.0078125
&
\sphinxAtStartPar
1.083876968009309e\sphinxhyphen{}06
&
\sphinxAtStartPar
\sphinxhyphen{}
\\
\hline
\sphinxAtStartPar
256
&
\sphinxAtStartPar
0.00390625
&
\sphinxAtStartPar
6.883813637344194e\sphinxhyphen{}08
&
\sphinxAtStartPar
3.9768491535433466
\\
\hline
\sphinxAtStartPar
512
&
\sphinxAtStartPar
0.001953125
&
\sphinxAtStartPar
4.322307012305515e\sphinxhyphen{}09
&
\sphinxAtStartPar
3.9933345852265947
\\
\hline
\sphinxAtStartPar
1024
&
\sphinxAtStartPar
0.0009765625
&
\sphinxAtStartPar
2.705360744453822e\sphinxhyphen{}10
&
\sphinxAtStartPar
3.9979086629155343
\\
\hline
\end{tabulary}
\par
\sphinxattableend\end{savenotes}

\sphinxAtStartPar
Also with order 4, better than what expected.


\subsection{Graphics}
\label{\detokenize{cap4:graphics}}
\sphinxAtStartPar
Next, it is shown graphics from the same problem, but first showing the error as the linear part, \(100\), changes from \(0\) to \(100\) and next with \(\lambda = 100\) but changng the time step.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n = 128
lmba0 = 1
lmbaf = 100
t0 = 0.0
tf = 1.0
x0 = np.array([1])
lmba\PYGZus{}1D\PYGZus{}classic, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, classic\PYGZus{}euler, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}exponential, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, exponential\PYGZus{}euler, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd2rk, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd2rk, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd3rk\PYGZus{}similar, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd3rk\PYGZus{}naive, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}rk2, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, rk2, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}rk4, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, rk4, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/home/miki/IC/Relatorio\PYGZus{}github/\PYGZus{}build/jupyter\PYGZus{}execute/basecode.py:247: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.sqrt(float(np.sum(v)/x\PYGZus{}approx.size)) \PYGZsh{}normalized
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
matrix\PYGZus{}1D = [lmba\PYGZus{}1D\PYGZus{}classic, lmba\PYGZus{}1D\PYGZus{}exponential, lmba\PYGZus{}1D\PYGZus{}rk2, lmba\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, lmba\PYGZus{}1D\PYGZus{}etd2rk, lmba\PYGZus{}1D\PYGZus{}rk4, lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar]
names = [\PYGZsq{}classic euler\PYGZsq{}, \PYGZsq{}exponential euler\PYGZsq{}, \PYGZsq{}rk2\PYGZsq{}, \PYGZsq{}etd2rk naive\PYGZsq{}, \PYGZsq{}etd2rk\PYGZsq{}, \PYGZsq{}rk4\PYGZsq{}, \PYGZsq{}etd3rk naive\PYGZsq{}, \PYGZdq{}etd3rk (similar)\PYGZdq{}]
fig, ax = graphic\PYGZus{}2D(8*[domain], matrix\PYGZus{}1D, names, \PYGZdq{}lambda\PYGZdq{}, \PYGZdq{}error\PYGZdq{}, \PYGZdq{}1D problem from [1]\PYGZdq{}, False, True)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{cap4_14_0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here it is notable that as the lambda increases, and so does the stiffness, the exponential methods deal really well, even dropping the error, since the exponential part is precisely solved, so, as it gains more relevance, the method perfoms better. Meanwhile, the other methods (classic and naive) start to decline, dealing badly with the stiffness. Just as predicted.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 10
k = 10
lmba = 100
A = lmba * np.array([[1]])
t0 = 0.0
tf = 1.0
x0 = np.array([1])
n\PYGZus{}1D\PYGZus{}classic, domain = errors\PYGZus{}2x(n0, k, classic\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}exponential, domain = errors\PYGZus{}2x(n0, k, exponential\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd2rk, domain = errors\PYGZus{}2x(n0, k, etd2rk, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, domain = errors\PYGZus{}2x(n0, k, etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}similar, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}rk2, domain = errors\PYGZus{}2x(n0, k, rk2, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}rk4, domain = errors\PYGZus{}2x(n0, k, rk4, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
matrix\PYGZus{}2D = [n\PYGZus{}1D\PYGZus{}classic, n\PYGZus{}1D\PYGZus{}exponential, n\PYGZus{}1D\PYGZus{}rk2, n\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, n\PYGZus{}1D\PYGZus{}etd2rk, n\PYGZus{}1D\PYGZus{}rk4, n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar]
names = [\PYGZsq{}classic euler\PYGZsq{}, \PYGZsq{}exponential euler\PYGZsq{}, \PYGZsq{}rk2\PYGZsq{}, \PYGZsq{}etd2rk naive\PYGZsq{}, \PYGZsq{}etd2rk\PYGZsq{}, \PYGZsq{}rk4\PYGZsq{}, \PYGZsq{}etd3rk naive\PYGZsq{}, \PYGZdq{}etd3rk (similar)\PYGZdq{}]
fig\PYGZus{}2D, ax\PYGZus{}2D = graphic\PYGZus{}2D(8*[1/domain], matrix\PYGZus{}2D, names, \PYGZdq{}h\PYGZdq{}, \PYGZdq{}error\PYGZdq{}, \PYGZdq{}1D problem with lmba = \PYGZdq{}+str(lmba), False, True)
plt.xscale(\PYGZsq{}log\PYGZsq{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{cap4_17_0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
Here is visually clear the orders already confirmed by the convergence tables.

\sphinxstepscope


\section{Swing spring application}
\label{\detokenize{cap5:swing-spring-application}}\label{\detokenize{cap5::doc}}
\sphinxAtStartPar
Finally, an application is done for the swing spring problem.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
from basecode import *
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
\PYG{g+gt}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}}
\PYG{n+ne}{ModuleNotFoundError}\PYG{g+gWhitespace}{                       }Traceback (most recent call last)
\PYG{n}{Cell} \PYG{n}{In}\PYG{p}{[}\PYG{l+m+mi}{1}\PYG{p}{]}\PYG{p}{,} \PYG{n}{line} \PYG{l+m+mi}{1}
\PYG{n+ne}{\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZgt{} }\PYG{l+m+mi}{1} \PYG{k+kn}{from} \PYG{n+nn}{basecode} \PYG{k+kn}{import} \PYG{o}{*}

\PYG{n+ne}{ModuleNotFoundError}: No module named \PYGZsq{}basecode\PYGZsq{}
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxAtStartPar
!{[}spring.png{]}(data:image/png;base64,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)

\sphinxAtStartPar
Image taken from {[}8{]}.

\sphinxAtStartPar
From {[}9{]}, the model is, given \(m, k, l\) and \(g\),

\sphinxAtStartPar
\textbackslash{}begin\{cases\}
\textbackslash{}dot\{\textbackslash{}theta\} = \textbackslash{}frac\{\textbackslash{}rho\_\textbackslash{}theta\}\{mr\textasciicircum{}2\}\textbackslash{}
\textbackslash{}dot\{\textbackslash{}rho\_\textbackslash{}theta\} = \sphinxhyphen{}mgr \textbackslash{}sin\{\textbackslash{}theta\}\textbackslash{}
\textbackslash{}dot\{r\} = \textbackslash{}frac\{\textbackslash{}rho\_r\}\{m\} \textbackslash{}
\textbackslash{}dot\{\textbackslash{}rho\_r\} = \textbackslash{}frac\{\textbackslash{}rho\textasciicircum{}2\_\textbackslash{}theta\}\{mr\textasciicircum{}3\} \sphinxhyphen{} k(r \sphinxhyphen{} l) + mg \textbackslash{}cos\{\textbackslash{}theta\}.
\textbackslash{}end\{cases\}

\sphinxAtStartPar
In matrix form,
\begin{equation*}
\begin{split}
  \frac{d}{dt}\begin{bmatrix}
              \theta\\
              \rho_\theta\\
              r\\
              \rho_r
              \end{bmatrix}
  =
  \begin{bmatrix}
  0 & \frac{1}{ml^2} & 0 & 0\\
  -mgl & 0 & 0 & 0\\
  0 & 0 & 0 & \frac{1}{m}\\
  0 & 0 & -k & 0
  \end{bmatrix}
  \begin{bmatrix}
  \theta\\
  \rho_\theta\\
  r\\
  \rho_r
  \end{bmatrix}
  +
  \begin{bmatrix}
  \frac{\rho_\theta}{m} \left(\frac{1}{r^2}-\frac{1}{l^2}\right)\\
  -mg(r\sin{\theta}-l\theta)\\
  0\\
  \frac{\rho^2_\theta}{mr^3} + kl + mg \cos{\theta}
  \end{bmatrix}.
\end{split}
\end{equation*}
\sphinxAtStartPar
For \(m = 1, l = 1, g = \pi^2, k = 100 \pi^2\), using the etd3rk method deduced, the best one tested,

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
def g\PYGZus{}swing\PYGZus{}spring(x, t):
  m = 1
  l = 1
  gr = np.pi**2
  k = 100 * np.pi**2
  vector = np.zeros(x.size)
  theta = x[0]
  p\PYGZus{}theta = x[1]
  r = x[2]
  pr = x[3]
  vector[0] = p\PYGZus{}theta/m * (1/r**2 \PYGZhy{} 1/l**2)
  vector[1] = \PYGZhy{}m*gr*(r*np.sin(theta)\PYGZhy{}l*theta)
  vector[3] = p\PYGZus{}theta**2/(m*r**3) + k*l + m*gr*np.cos(theta)
  return vector
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
m = 1
l = 1
g = np.pi**2
k = 100 * np.pi**2
A = np.matrix([[0,\PYGZhy{}1/(m*l**2),0,0], [m*g*l,0,0,0], [0,0,0,\PYGZhy{}1/m], [0,0,k,0]])
n = 10000
t0 = 0.0
tf = 5.0
x0 = np.array([np.pi/2,3,l,1])
domains = 4*[np.arange(t0, tf, (tf\PYGZhy{}t0)/n)]
x = etd3rk\PYGZus{}similar(t0, tf, n, x0, A, g\PYGZus{}swing\PYGZus{}spring)
names = [\PYGZsq{}theta\PYGZsq{},\PYGZsq{}p\PYGZus{}theta\PYGZsq{}, \PYGZsq{}r\PYGZsq{}, \PYGZsq{}pr\PYGZsq{}]
matrix1 = [x[0,:], x[1,:], x[2,:], x[3,:]]

fig1, ax1 = graphic\PYGZus{}2D(domains, matrix1, names, \PYGZsq{}t\PYGZsq{}, \PYGZsq{} \PYGZsq{}, \PYGZsq{}swing spring etdrk3 n = \PYGZsq{}+str(n), False, False)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/tmp/ipykernel\PYGZus{}9663/2307441015.py:11: ComplexWarning: Casting complex values to real discards the imaginary part
  vector[0] = p\PYGZus{}theta/m * (1/r**2 \PYGZhy{} 1/l**2)
/tmp/ipykernel\PYGZus{}9663/2307441015.py:12: ComplexWarning: Casting complex values to real discards the imaginary part
  vector[1] = \PYGZhy{}m*gr*(r*np.sin(theta)\PYGZhy{}l*theta)
/tmp/ipykernel\PYGZus{}9663/2307441015.py:13: ComplexWarning: Casting complex values to real discards the imaginary part
  vector[3] = p\PYGZus{}theta**2/(m*r**3) + k*l + m*gr*np.cos(theta)
/home/miki/.local/lib/python3.10/site\PYGZhy{}packages/matplotlib/cbook/\PYGZus{}\PYGZus{}init\PYGZus{}\PYGZus{}.py:1369: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.asarray(x, float)
\end{sphinxVerbatim}

\noindent\sphinxincludegraphics{{cap5_8_1}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\sphinxstepscope


\chapter{References}
\label{\detokenize{References:references}}\label{\detokenize{References::doc}}\begin{enumerate}
\sphinxsetlistlabels{\arabic}{enumi}{enumii}{}{.}%
\item {} 
\sphinxAtStartPar
HOCHBRUCK, M.; OSTERMANN, A. Exponential integrators. Acta Numer, Cambridge Univ Press, v. 19, p. 209–286, 2010.

\item {} 
\sphinxAtStartPar
BURDEN, Richard L.; FAIRES, J. Douglas. Numerical Analysis. 9.ed. Boston:Brooks/Cole, 2010. p.348\sphinxhyphen{}353.

\item {} 
\sphinxAtStartPar
ROMA, Alexandre. Lecture notes. Introdução à Resolução Numérica do Problema de Cauchy (Introduction to numerical resolution of Cauchy problem), MAP5002. Jan. and Feb. 2023. IME\sphinxhyphen{}USP University of São Paulo.

\item {} 
\sphinxAtStartPar
TAL, Fábio A. Lecture notes. Técnicas em Teoria do Controle (techniques in control theory), MAP2321. Aug. to Dez. 2022. IME\sphinxhyphen{}USP University from São Paulo.

\item {} 
\sphinxAtStartPar
Apostol, T.M. Calculus v. 1. Blaisdell book in pure and applied mathematics. \sphinxurl{https://books.google.com.br/books?id=sR\_vAAAAMAAJ}. 1961. Blaisdell Publishing Company.

\item {} 
\sphinxAtStartPar
S.M. Cox, P.C. Matthews, Exponential Time Differencing for Stiff Systems, Journal of Computational Physics, Volume 176, Issue 2, 2002, Pages 430\sphinxhyphen{}455, ISSN 0021\sphinxhyphen{}9991, \sphinxurl{https://doi.org/10.1006/jcph.2002.6995}.

\item {} 
\sphinxAtStartPar
Hochbruck, Marlis, and Alexander Ostermann. “Explicit Exponential Runge\sphinxhyphen{}Kutta Methods for Semilinear Parabolic Problems.” SIAM Journal on Numerical Analysis, vol. 43, no. 3, 2006, pp. 1069–90. JSTOR, \sphinxurl{http://www.jstor.org/stable/4101280}. Accessed 27 June 2023.

\item {} 
\sphinxAtStartPar
DOBRUSHKIN, Vladimir. “MATHEMATICA TUTORIAL
for the Second Course. Part III: Spring Pendulum”. Monday, September 4, 2023 10:24:40 PM. \sphinxurl{https://www.cfm.brown.edu/people/dobrush/am34/Mathematica/ch3/spendulum.html}

\item {} 
\sphinxAtStartPar
Lynch, Peter. (2000). The Swinging Spring: A Simple Model of Atmospheric Balance. \sphinxurl{https://maths.ucd.ie/~plynch/Publications/AOD\_Paper.pdf}

\end{enumerate}

\sphinxstepscope


\chapter{Participation in scientific event, list of publications and list of papers prepared or submitted}
\label{\detokenize{Participation_in_scientific_event,_list_of_publications_and_list_of_papers_prepared_or_submitted:participation-in-scientific-event-list-of-publications-and-list-of-papers-prepared-or-submitted}}\label{\detokenize{Participation_in_scientific_event,_list_of_publications_and_list_of_papers_prepared_or_submitted::doc}}
\sphinxAtStartPar
Nothing to declare.

\sphinxstepscope


\chapter{Appendix}
\label{\detokenize{appendix:appendix}}\label{\detokenize{appendix::doc}}

\section{Code}
\label{\detokenize{appendix:code}}
\sphinxAtStartPar
All the functions coded are in the following environment.

\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
from math import *
import numpy as np
from collections import deque
import matplotlib.pyplot as plt
from scipy.linalg import expm
from scipy import linalg

stab\PYGZus{}lim = 1000.0

def classic\PYGZus{}euler(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        x[:,i] = x[:,i\PYGZhy{}1] + h*(np.matmul(\PYGZhy{}A,x[:,i\PYGZhy{}1]) + g(x[:,i\PYGZhy{}1],t))
        t = t0 + i*h
        if np.any(x[:,i].real \PYGZgt{} stab\PYGZus{}lim):
            x[:,i] = np.nan
    return x

def exponential\PYGZus{}euler(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0] = x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    hphi1 = calculate\PYGZus{}hphi1(h, A)
    for i in range(1, n):
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t))
        t = t0 + i*h
    return x

def calculate\PYGZus{}hphi1(h, A):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  dim = A.shape[0]
  hphi1 = np.matmul(np.eye(dim)\PYGZhy{}expm(\PYGZhy{}h*A), linalg.inv(A))
  return hphi1

def calculate\PYGZus{}hphi2(h, A, hphi1):
    \PYGZsh{}IT IS NOT H2PHI2
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, np.matrix, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    dim = A.shape[0]
    hphi2 = np.matmul(np.eye(dim)\PYGZhy{}hphi1/h, linalg.inv(A))
    return hphi2

def calculate\PYGZus{}hphi3(h, A, hphi2):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, np.matrix, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    dim = A.shape[0]
    hphi3 = np.matmul(1/2*np.eye(dim)\PYGZhy{}hphi2/h, linalg.inv(A))
    return hphi3

def etd2(t0, tf, n, x0, A, g, derivate\PYGZus{}of\PYGZus{}g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0] = x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    hphi1 = calculate\PYGZus{}hphi1(h, A)
    hphi2 = calculate\PYGZus{}hphi2(h, A, hphi1)
    for i in range(1, n):
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t)) + h*np.matmul(hphi2,derivate\PYGZus{}of\PYGZus{}g(x[:,i\PYGZhy{}1],t))
        t = t0 + i*h
    return x

def rk2(t0, tf, n, x0, A, g): \PYGZsh{}heun s method
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        a = x[:,i\PYGZhy{}1] + h*(np.matmul(\PYGZhy{}A,x[:,i\PYGZhy{}1]) + g(x[:,i\PYGZhy{}1],t))
        f1 = np.matmul(\PYGZhy{}A,x[:,i\PYGZhy{}1]) + g(x[:,i\PYGZhy{}1],t)
        f2 = np.matmul(\PYGZhy{}A,a) + g(a,t)
        x[:,i] = x[:,i\PYGZhy{}1] + .5 * h * (f1 + f2)
        t = t0 + i*h
        if np.any(x[:,i].real \PYGZgt{} stab\PYGZus{}lim):
            x[:,i] = np.nan
    return x

def etd2rk(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    hphi1 = calculate\PYGZus{}hphi1(h, A)
    hphi2 = calculate\PYGZus{}hphi2(h, A, hphi1)
    for i in range(1, n):
        a = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t))
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t)) + np.matmul(hphi2,g(a, t0 + i*h)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
        t = t0 + i*h
    return x

def etd2rk\PYGZus{}midpoint\PYGZus{}rule(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    exponential\PYGZus{}matrix\PYGZus{}2 = expm(\PYGZhy{}h/2*A)
    h\PYGZus{}2phi1\PYGZus{}2 = calculate\PYGZus{}hphi1(h/2, A)
    hphi1 = calculate\PYGZus{}hphi1(h, A)
    hphi2 = calculate\PYGZus{}hphi2(h, A, hphi1)
    for i in range(1, n):
        b = np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, x[:,i\PYGZhy{}1]) + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t))
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t)) + 2*np.matmul(hphi2,g(b, t + h/2)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
        t = t0 + i*h
    return x

def etd2rk\PYGZus{}trapezoidal\PYGZus{}naive(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    hphi1 = calculate\PYGZus{}hphi1(h, A)
    for i in range(1, n):
        a = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t))
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + .5 * h * (np.matmul(exponential\PYGZus{}matrix, g(x[:,i\PYGZhy{}1],t)) + g(a, t0 + i*h))
        t = t0 + i*h
    return x

def etd2rk\PYGZus{}midpoint\PYGZus{}rule\PYGZus{}naive(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
    exponential\PYGZus{}matrix\PYGZus{}2 = expm(\PYGZhy{}h/2*A)
    h\PYGZus{}2phi1\PYGZus{}2 = calculate\PYGZus{}hphi1(h/2, A)
    for i in range(1, n):
        b = np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, x[:,i\PYGZhy{}1]) + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t))
        x[:,i] = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1]) + h * np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, g(b, t+h/2))
        t = t0 + i*h
    return x

def rk4(t0, tf, n, x0, A, g):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
    h = (tf\PYGZhy{}t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        k1 = np.matmul(\PYGZhy{}A,x[:,i\PYGZhy{}1]) + g(x[:,i\PYGZhy{}1],t)
        x2 = x[:,i\PYGZhy{}1] + h * k1 / 2
        k2 = np.matmul(\PYGZhy{}A,x2) + g(x2,t+h/2)
        x3 = x[:,i\PYGZhy{}1] + h * k2 / 2
        k3 = np.matmul(\PYGZhy{}A,x3) + g(x3,t+h/2)
        x4 = x[:,i\PYGZhy{}1] + h * k3
        k4 = np.matmul(\PYGZhy{}A,x4) + g(x4,t0 + i*h)
        x[:,i] = x[:,i\PYGZhy{}1] + h / 6 * (k1 + 2*k2 + 2*k3 + k4)
        t = t0 + i*h
        if np.any(x[:,i].real \PYGZgt{} stab\PYGZus{}lim):
            x[:,i] = np.nan
    return x

def etd3rk\PYGZus{}similar(t0, tf, n, x0, A, g):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  h = (tf\PYGZhy{}t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
  x[:,0]=x0
  t = t0
  exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
  exponential\PYGZus{}matrix\PYGZus{}2 = expm(\PYGZhy{}h/2*A)
  hphi1 = calculate\PYGZus{}hphi1(h, A)
  h\PYGZus{}2phi1\PYGZus{}2 = calculate\PYGZus{}hphi1(h/2, A)
  hphi2 = calculate\PYGZus{}hphi2(h, A, hphi1)
  h\PYGZus{}2phi2\PYGZus{}2 = calculate\PYGZus{}hphi2(h/2, A, h\PYGZus{}2phi1\PYGZus{}2)
  hphi3 = calculate\PYGZus{}hphi3(h, A, hphi2)
  for i in range(1, n):
    fst\PYGZus{}term = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1])
    fst\PYGZus{}term\PYGZus{}2 = np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, x[:,i\PYGZhy{}1])
    a = fst\PYGZus{}term + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t))
    a\PYGZus{} = fst\PYGZus{}term\PYGZus{}2 + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t))
    c = fst\PYGZus{}term + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t)) + np.matmul(hphi2,g(a, t0 + i*h)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
    c\PYGZus{} = fst\PYGZus{}term\PYGZus{}2 + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t)) + np.matmul(h\PYGZus{}2phi2\PYGZus{}2,g(a\PYGZus{}, t0 + i*h)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
    snd\PYGZus{}term = np.matmul(hphi1, g(c\PYGZus{}, t+h/2))
    trd\PYGZus{}term = np.matmul(hphi2 \PYGZhy{} hphi1/2,g(c, t0 + i*h)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
    fth\PYGZus{}term = 4 * np.matmul(hphi3+hphi1/8\PYGZhy{}hphi2/2, g(c, t0 + i*h)+g(x[:,i\PYGZhy{}1],t)\PYGZhy{}2*g(c\PYGZus{}, t + h/2))
    x[:,i] = fst\PYGZus{}term + snd\PYGZus{}term + trd\PYGZus{}term + fth\PYGZus{}term
    t = t0 + i*h
  return x

def etd3rk(t0, tf, n, x0, A, g):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  h = (tf\PYGZhy{}t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
  x[:,0]=x0
  t = t0
  exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
  exponential\PYGZus{}matrix\PYGZus{}2 = expm(\PYGZhy{}h/2*A)
  hphi1 = calculate\PYGZus{}hphi1(h, A)
  h\PYGZus{}2phi1\PYGZus{}2 = calculate\PYGZus{}hphi1(h/2, A)
  hphi2 = calculate\PYGZus{}hphi2(h, A, hphi1)
  h\PYGZus{}2phi2\PYGZus{}2 = calculate\PYGZus{}hphi2(h/2, A, h\PYGZus{}2phi1\PYGZus{}2)
  hphi3 = calculate\PYGZus{}hphi3(h, A, hphi2)
  for i in range(1, n):
    fst\PYGZus{}term = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1])
    fst\PYGZus{}term\PYGZus{}2 = np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, x[:,i\PYGZhy{}1])
    a = fst\PYGZus{}term\PYGZus{}2 + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t))
    b = fst\PYGZus{}term + np.matmul(hphi1,2*g(a,t+h/2)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
    snd\PYGZus{}term = np.matmul(hphi1, g(a, t+h/2))
    trd\PYGZus{}term = np.matmul(hphi2 \PYGZhy{} hphi1/2,g(b, t0 + i*h)\PYGZhy{}g(x[:,i\PYGZhy{}1],t))
    fth\PYGZus{}term = 4 * np.matmul(hphi3+hphi1/8\PYGZhy{}hphi2/2, g(b, t0 + i*h)+g(x[:,i\PYGZhy{}1],t)\PYGZhy{}2*g(a, t + h/2))
    x[:,i] = fst\PYGZus{}term + snd\PYGZus{}term + trd\PYGZus{}term + fth\PYGZus{}term
    t = t0 + i*h
  return x

def etd3rk\PYGZus{}naive(t0, tf, n, x0, A, g):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(float, float, int, np.array, np.matrix, function, np.matrix) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  h = (tf\PYGZhy{}t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex\PYGZus{})
  x[:,0]=x0
  t = t0
  exponential\PYGZus{}matrix = expm(\PYGZhy{}h*A)
  exponential\PYGZus{}matrix\PYGZus{}2 = expm(\PYGZhy{}h/2*A)
  hphi1 = calculate\PYGZus{}hphi1(h, A)
  h\PYGZus{}2phi1\PYGZus{}2 = calculate\PYGZus{}hphi1(h/2, A)
  for i in range(1, n):
    fst\PYGZus{}term = np.matmul(exponential\PYGZus{}matrix, x[:,i\PYGZhy{}1])
    fst\PYGZus{}term\PYGZus{}2 = np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, x[:,i\PYGZhy{}1])
    a = fst\PYGZus{}term + np.matmul(hphi1,g(x[:,i\PYGZhy{}1],t))
    a\PYGZus{} = fst\PYGZus{}term\PYGZus{}2 + np.matmul(h\PYGZus{}2phi1\PYGZus{}2,g(x[:,i\PYGZhy{}1],t))
    c = fst\PYGZus{}term + .5 * h * (np.matmul(exponential\PYGZus{}matrix, g(x[:,i\PYGZhy{}1],t)) + g(a, t0 + i*h))
    c\PYGZus{} = fst\PYGZus{}term\PYGZus{}2 + .25 * h * (np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, g(x[:,i\PYGZhy{}1],t)) + g(a\PYGZus{}, t0 + i*h))
    snd\PYGZus{}term = np.matmul(exponential\PYGZus{}matrix, g(x[:,i\PYGZhy{}1],t))
    trd\PYGZus{}term = 4*np.matmul(exponential\PYGZus{}matrix\PYGZus{}2, g(c\PYGZus{},t+h/2))
    fth\PYGZus{}term = g(c, t0 + i*h)
    x[:,i] = fst\PYGZus{}term + h*(snd\PYGZus{}term + trd\PYGZus{}term + fth\PYGZus{}term)/6
    t = t0 + i*h
  return x

def error\PYGZus{}2(x\PYGZus{}approx, x\PYGZus{}exact):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (np.vector, np.vector) \PYGZhy{}\PYGZgt{} float \PYGZsq{}\PYGZsq{}\PYGZsq{}
    \PYGZsh{}make sure that x\PYGZus{}approx and x\PYGZus{}exact have the same lenght
    v = (x\PYGZus{}approx \PYGZhy{} x\PYGZus{}exact)*(x\PYGZus{}approx \PYGZhy{} x\PYGZus{}exact).conjugate()
    \PYGZsh{}\PYGZca{}certainly pure real
    return np.sqrt(float(np.sum(v)/x\PYGZus{}approx.size)) \PYGZsh{}normalized

def error\PYGZus{}sup(x\PYGZus{}approx, x\PYGZus{}exact):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (np.vector, np.vector) \PYGZhy{}\PYGZgt{} float \PYGZsq{}\PYGZsq{}\PYGZsq{}
    \PYGZsh{}make sure that x\PYGZus{}approx and x\PYGZus{}exact have the same lenght
    v = abs(x\PYGZus{}approx \PYGZhy{} x\PYGZus{}exact)
    return np.amax(v)

def g(x, t):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (np.array, float) \PYGZhy{}\PYGZgt{} float
        (x, t) \PYGZhy{}\PYGZgt{} g(x, t)
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    g = np.array([np.sin(t)])
    return g

def g\PYGZus{}linear( x, t ):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (np.array, float) \PYGZhy{}\PYGZgt{} np.array
        (x, t) \PYGZhy{}\PYGZgt{} g(x, t)
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    g = np.zeros(x.size)
    return g

def sol( t ):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (float, float) \PYGZhy{}\PYGZgt{} float
    RECEIVES the initial value and a real (t).
    APPLIES the cauchy problem solution to this initial value at this point.
    RETURNS a real value.
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    lmba = 100
    sol = np.exp(\PYGZhy{}lmba*t)+(np.exp(\PYGZhy{}lmba*t)+lmba*np.sin(t)\PYGZhy{}np.cos(t))/(1+lmba*lmba)
    return sol

def sol\PYGZus{}given\PYGZus{}lmba(lmba, t ):
    \PYGZsq{}\PYGZsq{}\PYGZsq{} (float, float) \PYGZhy{}\PYGZgt{} float
    RECEIVES the initial value and a real (t).
    APPLIES the cauchy problem solution to this initial value at this point.
    RETURNS a real value.
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    sol = np.exp(\PYGZhy{}lmba*t)+(np.exp(\PYGZhy{}lmba*t)+lmba*np.sin(t)\PYGZhy{}np.cos(t))/(1+lmba*lmba)
    return sol

def vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba(lmba, t0, t1, n, sol):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    (float, float, float, int, function) \PYGZhy{}\PYGZgt{} np.vector
    n is the number of steps
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    x = np.zeros((sol(lmba,t0).size,n), dtype=np.complex\PYGZus{})
    h = (t1\PYGZhy{}t0)/n
    for i in range(n):
        x[:,i] = sol(lmba, t0+i*h)
    return x

def vectorize\PYGZus{}sol(t0, t1, n, sol):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    (float, float, int, function) \PYGZhy{}\PYGZgt{} np.vector
    n is the number of steps
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    x = np.zeros((sol(t0).size,n), dtype=np.complex\PYGZus{})
    h = (t1\PYGZhy{}t0)/n
    for i in range(n):
        x[:,i] = sol(t0+i*h)
    return x

def A\PYGZus{}1D(lmba):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(int) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  return np.array([[lmba]])

def A\PYGZus{}2D(lmba):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}(int) \PYGZhy{}\PYGZgt{} np.matrix\PYGZsq{}\PYGZsq{}\PYGZsq{}
  return np.array([[0, \PYGZhy{}lmba],[lmba, 0]])

def errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, method, t0, tf, x0, lmba0, lmbaf, Af, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error):
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    This function is a variation of the errors\PYGZus{}array function. Here, the linear
    part of the problem is varying instead of the number of steps, which is now
    fixed.
    This function will RETURN 2 arrays.
    The first one has the errors of the approximations given by the method with
    coefficient of the linear part of the ploblem
    A = Af(lmba0), Af(lmba0+1), Af(lmba0+2), ..., Af(lmbaf\PYGZhy{}1).
    The second is [lmba0, lmba0+1, lmba0+2, ..., lmbaf\PYGZhy{}1]

    RECEIVES:
    n is the number of steps. (int)
    method have arguments (t0, tf, n, x0, lmba, g) and return a
    np.vector of length n (0, 1, 2, ..., n\PYGZhy{}1), n is the number of steps. (function)
    t0 is the initial point of the approximation. (float)
    tf is the last one. (float)
    x0 is the initial value of the Cauchy problem. (np.array)
    lmba0 and lmbaf are integers as described before. (int)
    Af is a function that receives the stiffness parameter and returns the
    corresponding linear coefficient. (function)
    g is a function (float, float) \PYGZhy{}\PYGZgt{} (float). (function)
    sol is a function (float) \PYGZhy{}\PYGZgt{} (float). (function)
    vectorize\PYGZus{}sol is a function that \PYGZdq{}transforms sol in a vector\PYGZdq{} (function)
    (float, float, int, function) \PYGZhy{}\PYGZgt{} (np.array)
    (t0, tf, n, sol) \PYGZhy{}\PYGZgt{} np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf\PYGZhy{}1]])
    error is a function (np.array, np.array) \PYGZhy{}\PYGZgt{} (float) (function)
    \PYGZsq{}\PYGZsq{}\PYGZsq{}
    v = np.zeros(lmbaf\PYGZhy{}lmba0)
    domain = np.arange(lmba0, lmbaf)
    for i in range(lmbaf\PYGZhy{}lmba0):
        lmba = lmba0 + i
        m = method(t0, tf, n, x0, Af(lmba), g)
        exact = vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba(lmba, t0, tf, n, sol\PYGZus{}given\PYGZus{}lmba)
        if np.max(np.abs(m))\PYGZgt{}1000:
            v[lmba\PYGZhy{}lmba0]=np.nan
        else:
            v[lmba\PYGZhy{}lmba0] = error(m, exact)
    return v, domain

def errors\PYGZus{}array(n0, nf, method, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  This function will RETURN 2 arrays.
  The first one has the errors of the approximations given by the method with
  number of steps n = n0, n0+1, n0+2, ..., nf\PYGZhy{}1.
  The second is [n0, n0+1, n0+2, ..., nf\PYGZhy{}1]

  RECEIVES:
  n0 is the first number of steps. (int)
  nf is the last one plus 1. (int)
  method have arguments (t0, tf, n, x0, A, lmba, g) and return a
  np.vector of length n (0, 1, 2, ..., n\PYGZhy{}1), n is the number of steps. (function)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  x0 is the initial value of the Cauchy problem. (float)
  A is the coefficient os the linear part of the ploblem. (float)
  g is a function (int, float, float) \PYGZhy{}\PYGZgt{} (float). (function)
  sol is a function (int, float) \PYGZhy{}\PYGZgt{} (float). (function)
  vectorize\PYGZus{}sol is a function that \PYGZdq{}transforms sol in a vector\PYGZdq{} (function)
  (float, float, int, function) \PYGZhy{}\PYGZgt{} (np.array)
  (t0, tf, n, sol) \PYGZhy{}\PYGZgt{} np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf\PYGZhy{}1]])
  error is a function (np.array, np.array) \PYGZhy{}\PYGZgt{} (float) (function)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  v = np.zeros(nf\PYGZhy{}n0)
  domain = np.arange(n0, nf)
  for n in range(n0, nf):
    m = method(t0, tf, n, x0, A, g)
    exact = vectorize\PYGZus{}sol(t0, tf, n, sol)
    if np.max(np.abs(m))\PYGZgt{}1000:
        v[n\PYGZhy{}n0]=np.nan
    else:
        v[n\PYGZhy{}n0] = error(m, exact)
  return v, domain

def graphic\PYGZus{}2D(domain, matrix, names, labelx, labely, title, key1, key2):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  domain is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines. (list)
  matrix is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines \PYGZhy{} same length that domain. (list)
  names is a list of the labels for the graphs, must have the same length that
  the number of lines in matrix. (list of Strings)
  labelx is the name of the x coordinate. (String)
  labely is the name of the y coordinate. (String)
  title is the title of the graph. (String)
  key1 is a boolean that indicates if the last graph must be black. (bool)
  key2 is a boolean that indicates if it should use the log scale. (bool)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  fig, ax = plt.subplots()

  colors = [\PYGZsq{}red\PYGZsq{}, \PYGZsq{}orange\PYGZsq{}, \PYGZsq{}brown\PYGZsq{}, \PYGZsq{}green\PYGZsq{}, \PYGZsq{}cyan\PYGZsq{}, \PYGZsq{}blue\PYGZsq{}, \PYGZsq{}pink\PYGZsq{}, \PYGZsq{}yellow\PYGZsq{}, \PYGZsq{}gold\PYGZsq{}, \PYGZsq{}maroon\PYGZsq{}]
  for i in range(len(names)\PYGZhy{}1):
    ax.plot(domain[i], matrix[i], color=colors[i], label=names[i])
  if key1:
    ax.plot(domain[len(names)\PYGZhy{}1], matrix[len(names)\PYGZhy{}1], color=\PYGZsq{}black\PYGZsq{}, label=names[len(names)\PYGZhy{}1])
  else:
    ax.plot(domain[len(names)\PYGZhy{}1], matrix[len(names)\PYGZhy{}1], color=colors[len(names)\PYGZhy{}1], label=names[len(names)\PYGZhy{}1])
  if key2:
    plt.yscale(\PYGZsq{}log\PYGZsq{})
  ax.legend()
  ax.set\PYGZus{}xlabel(labelx)
  ax.set\PYGZus{}ylabel(labely)
  ax.set\PYGZus{}title(title)
  return fig, ax

def graphic\PYGZus{}3D(domain, matrix1, matrix2, names, labelx, labely, labelz, title, key1, key2):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  domain is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines. (list)
  matrix1 and matrix2 are lists of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines \PYGZhy{} same length that domain. (list)
  names is a list of the labels for the graphs, must have the same length that
  the number of lines in matrix. (list of Strings)
  labelx is the name of the x coordinate. (String)
  labely is the name of the y coordinate. (String)
  labelz is the name of the z coordinate. (String)
  title is the title of the graph. (String)
  key1 is a boolean that indicates if the last graph must be black. (bool)
  key2 is a boolean that indicates if it should use the log scale. (bool)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  fig = plt.figure()
  ax = plt.figure().add\PYGZus{}subplot(projection=\PYGZsq{}3d\PYGZsq{})

  colors = [\PYGZsq{}blue\PYGZsq{}, \PYGZsq{}green\PYGZsq{}, \PYGZsq{}red\PYGZsq{}, \PYGZsq{}cyan\PYGZsq{}, \PYGZsq{}magenta\PYGZsq{}, \PYGZsq{}yellow\PYGZsq{}]
  for i in range(len(names)\PYGZhy{}1):
    ax.plot(domain[i], matrix1[i], matrix2[i], color=colors[i], label=names[i])
  if key1:
    ax.plot(domain[len(names)\PYGZhy{}1], matrix1[len(names)\PYGZhy{}1], matrix2[len(names)\PYGZhy{}1], color=\PYGZsq{}black\PYGZsq{}, label=names[len(names)\PYGZhy{}1])
  else:
    ax.plot(domain[len(names)\PYGZhy{}1], matrix1[len(names)\PYGZhy{}1], matrix2[len(names)\PYGZhy{}1], color=colors[len(names)\PYGZhy{}1], label=names[len(names)\PYGZhy{}1])
  if key2:
    plt.yscale(\PYGZsq{}log\PYGZsq{})
  ax.legend()
  ax.set\PYGZus{}xlabel(labelx)
  ax.set\PYGZus{}ylabel(labely)
  ax.set\PYGZus{}zlabel(labelz)
  ax.set\PYGZus{}title(title)
  return fig, ax

def errors\PYGZus{}2x(n0, k, method, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  This function will RETURN a np.array with the errors of the approximations given
  by the method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k\PYGZhy{}1)*n0.

  RECEIVES:
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  method have arguments (t0, tf, n, x0, lmba, g) and return a
  np.vector of length n (0, 1, 2, ..., n\PYGZhy{}1), n is the number of steps. (function)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  x0 is the initial value of the Cauchy problem. (float)
  A is the coefficient of the linear part of the ploblem. (np.matrix)
  g is a function (float, float) \PYGZhy{}\PYGZgt{} (float). (function)
  sol is a function (float) \PYGZhy{}\PYGZgt{} (float). (function)
  vectorize\PYGZus{}sol is a function that \PYGZdq{}transforms sol in a vector\PYGZdq{} (function)
  (float, float, int, function) \PYGZhy{}\PYGZgt{} (np.array)
  (t0, tf, n, sol) \PYGZhy{}\PYGZgt{} np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf\PYGZhy{}1]])
  error is a function (np.array, np.array) \PYGZhy{}\PYGZgt{} (float) (function)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  v = np.zeros(k)
  domain = np.zeros(k)
  for i in range(k):
    domain[i] = n0*2**i
    m = method(t0, tf, n0*2**i, x0, A, g)
    exact = vectorize\PYGZus{}sol(t0, tf, n0*2**i, sol)
    v[i] = error(m, exact)
  return v, domain

def convergence\PYGZus{}table(errors\PYGZus{}2x, n0, k, t0, tf):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  RECEIVES:
  errors\PYGZus{}2x is a array with the errors of the approximations given
  by a method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k\PYGZhy{}1)*n0. (np.array)
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  n = n0
  print(n, (tf\PYGZhy{}t0)/n, errors\PYGZus{}2x[0], \PYGZdq{}\PYGZhy{}\PYGZdq{}, sep=\PYGZdq{} \PYGZam{} \PYGZdq{}, end=\PYGZdq{} \PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{} \PYGZbs{}n\PYGZdq{})
  for i in range(1, k):
      n = n0 * 2 ** i
      h = (tf\PYGZhy{}t0)/n
      q = errors\PYGZus{}2x[i\PYGZhy{}1]/errors\PYGZus{}2x[i] \PYGZsh{}q=erro(h)/erro(h)
      r = ((tf\PYGZhy{}t0)/(n/2))/((tf\PYGZhy{}t0)/n)
      print(n, h, errors\PYGZus{}2x[i], log(q,2)/log(r,2), sep=\PYGZdq{} \PYGZam{} \PYGZdq{}, end=\PYGZdq{} \PYGZbs{}\PYGZbs{}\PYGZbs{}\PYGZbs{} \PYGZbs{}n\PYGZdq{})

def convergence\PYGZus{}table(errors\PYGZus{}2x, n0, k, t0, tf):
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  RECEIVES:
  errors\PYGZus{}2x is a array with the errors of the approximations given
  by a method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k\PYGZhy{}1)*n0. (np.array)
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  \PYGZsq{}\PYGZsq{}\PYGZsq{}
  n = n0
  print(\PYGZdq{}| n | h = \PYGZdl{}\PYGZbs{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |\PYGZdq{})
  print(\PYGZdq{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZdq{})
  print(\PYGZdq{}\PYGZdq{}, n, (tf\PYGZhy{}t0)/n, errors\PYGZus{}2x[0], \PYGZdq{}\PYGZhy{}\PYGZdq{}, sep=\PYGZdq{} | \PYGZdq{}, end=\PYGZdq{} | \PYGZbs{}n\PYGZdq{})
  for i in range(1, k):
      n = n0 * 2 ** i
      h = (tf\PYGZhy{}t0)/n
      q = errors\PYGZus{}2x[i\PYGZhy{}1]/errors\PYGZus{}2x[i] \PYGZsh{}q=erro(h)/erro(h)
      r = ((tf\PYGZhy{}t0)/(n/2))/((tf\PYGZhy{}t0)/n)
      print( \PYGZdq{}\PYGZdq{}, n, h, errors\PYGZus{}2x[i], log(q,2)/log(r,2), sep=\PYGZdq{} | \PYGZdq{}, end=\PYGZdq{} | \PYGZbs{}n\PYGZdq{})

def lmba\PYGZus{}n\PYGZus{}error(errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array, method, x0, Af, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error, method\PYGZus{}name):
  lmba0 = 5
  lmbaf = 100
  n0 = 10
  nf = 128
  t0 = 0.0
  tf = 1.0
  \PYGZsh{} Create data for X, Y
  lmba\PYGZus{}values = np.arange(lmba0, lmbaf)
  n\PYGZus{}values = np.arange(n0, nf)
  X, Y = np.meshgrid(lmba\PYGZus{}values, 1/n\PYGZus{}values)
  \PYGZsh{} Create a matrix of zeros for Z
  Z = np.zeros\PYGZus{}like(X)
  \PYGZsh{} Populate the Z matrix with data using a function
  for n in range(n0, nf):
    Z[n\PYGZhy{}n0], domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, method, t0, tf, x0, lmba0, lmbaf, Af, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error)
  \PYGZsh{} Create filled contour plot
  plt.contourf(X, Y, Z)
  \PYGZsh{} Add color bar for the contour plot
  plt.colorbar()
  \PYGZsh{} Add labels and title (optional)
  plt.xlabel(\PYGZsq{}lambda\PYGZsq{})
  plt.ylabel(\PYGZsq{}h\PYGZsq{})
  plt.title(\PYGZsq{}errors for the \PYGZsq{}+method\PYGZus{}name+\PYGZsq{} method \PYGZsq{})
  \PYGZsh{} Show the plot
  plt.show()
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}

\end{sphinxuseclass}

\section{Convergence tables}
\label{\detokenize{appendix:convergence-tables}}

\subsection{Classic Euler}
\label{\detokenize{appendix:classic-euler}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])
errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, classic\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 0.2391072699739873 | \PYGZhy{} | 
 | 256 | 0.00390625 | 0.08650412059872986 | 1.466817233501749 | 
 | 512 | 0.001953125 | 0.039214210532948934 | 1.1413923006132296 | 
 | 1024 | 0.0009765625 | 0.018739566082401515 | 1.0652890085799935 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Exponential Euler}
\label{\detokenize{appendix:exponential-euler}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])
errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, exponential\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 4.398075514689716e\PYGZhy{}05 | \PYGZhy{} | 
 | 256 | 0.00390625 | 2.074422525626487e\PYGZhy{}05 | 1.0841625981445133 | 
 | 512 | 0.001953125 | 1.0056221183126109e\PYGZhy{}05 | 1.0446214904461004 | 
 | 1024 | 0.0009765625 | 4.948885884282876e\PYGZhy{}06 | 1.0229126060177947 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{rk2}
\label{\detokenize{appendix:rk2}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, rk2, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 0.06606851127601271 | \PYGZhy{} | 
 | 256 | 0.00390625 | 0.01256096444797522 | 2.395015596211044 | 
 | 512 | 0.001953125 | 0.0027104154026279526 | 2.212361357172686 | 
 | 1024 | 0.0009765625 | 0.0006264383048139033 | 2.1132696413977325 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{etd2rk (trapezoidal)}
\label{\detokenize{appendix:etd2rk-trapezoidal}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, etd2rk, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 4.186569175362864e\PYGZhy{}08 | \PYGZhy{} | 
 | 256 | 0.00390625 | 1.0575183428604418e\PYGZhy{}08 | 1.985085775819591 | 
 | 512 | 0.001953125 | 2.652380943352073e\PYGZhy{}09 | 1.9953227875115886 | 
 | 1024 | 0.0009765625 | 6.638462730912398e\PYGZhy{}10 | 1.9983668943519293 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Naive version of etd2rk (trapezoidal)}
\label{\detokenize{appendix:naive-version-of-etd2rk-trapezoidal}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 0.0004242643044311458 | \PYGZhy{} | 
 | 256 | 0.00390625 | 0.00010714498082271644 | 1.9853990333325726 | 
 | 512 | 0.001953125 | 2.6871031228085582e\PYGZhy{}05 | 1.9954406751889993 | 
 | 1024 | 0.0009765625 | 6.725136514989377e\PYGZhy{}06 | 1.9984162299862431 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{rk4}
\label{\detokenize{appendix:rk4}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, rk4, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 0.002141816843239275 | \PYGZhy{} | 
 | 256 | 0.00390625 | 9.770249694801558e\PYGZhy{}05 | 4.4542958704375835 | 
 | 512 | 0.001953125 | 5.250705130854794e\PYGZhy{}06 | 4.21781234893684 | 
 | 1024 | 0.0009765625 | 3.024340525237257e\PYGZhy{}07 | 4.1178186851779905 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Deduced like etd3rk}
\label{\detokenize{appendix:deduced-like-etd3rk}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}similar, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 5.0853024048669315e\PYGZhy{}12 | \PYGZhy{} | 
 | 256 | 0.00390625 | 3.212833644961055e\PYGZhy{}13 | 3.9844153810116354 | 
 | 512 | 0.001953125 | 2.0132983821752326e\PYGZhy{}14 | 3.996213373698299 | 
 | 1024 | 0.0009765625 | 1.2602766052971504e\PYGZhy{}15 | 3.997748687591092 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\subsection{Naive version of etd3rk}
\label{\detokenize{appendix:naive-version-of-etd3rk}}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors\PYGZus{}2x\PYGZus{}vector, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}sup)
convergence\PYGZus{}table(errors\PYGZus{}2x\PYGZus{}vector, n0, k, t0, tf)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
| n | h = \PYGZdl{}\PYGZbs{}frac\PYGZob{}1\PYGZcb{}\PYGZob{}h\PYGZcb{}\PYGZdl{} | \PYGZdl{}\PYGZbs{}tau(0,h)\PYGZdl{} | q = \PYGZdl{}\PYGZbs{}frac\PYGZob{}tau(0,h)\PYGZcb{}\PYGZob{}tau(0, 2h)\PYGZcb{}\PYGZdl{} |
|\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}\PYGZhy{}|
 | 128 | 0.0078125 | 1.083876968009309e\PYGZhy{}06 | \PYGZhy{} | 
 | 256 | 0.00390625 | 6.883813637344194e\PYGZhy{}08 | 3.9768491535433466 | 
 | 512 | 0.001953125 | 4.322307012305515e\PYGZhy{}09 | 3.9933345852265947 | 
 | 1024 | 0.0009765625 | 2.705360744453822e\PYGZhy{}10 | 3.9979086629155343 | 
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Some graphics}
\label{\detokenize{appendix:some-graphics}}
\sphinxAtStartPar
The following notation is used

\sphinxAtStartPar
\textbackslash{}begin\{cases\}
u’(t) + A u(t) = g(u(t), t)\textbackslash{}
u(0) = u\_0.
\textbackslash{}end\{cases\}

\sphinxAtStartPar
A Stiff problem shown in {[}1{]} is

\sphinxAtStartPar
\textbackslash{}begin\{cases\}
u’(t) + 100 u(t) = \textbackslash{}sin(t)\textbackslash{}
u(0) = u\_0,
\textbackslash{}end\{cases\}

\sphinxAtStartPar
with solution
\begin{equation*}
\begin{split}
u(t) = u_0 \exp(-100t)+\frac{\exp(-100t)+100\sin(t)-\cos(t)}{1+100^2}.
\end{split}
\end{equation*}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n = 128
lmba0 = 1
lmbaf = 100
t0 = 0.0
tf = 1.0
x0 = np.array([1])
lmba\PYGZus{}1D\PYGZus{}classic, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, classic\PYGZus{}euler, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}exponential, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, exponential\PYGZus{}euler, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd2rk, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd2rk, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd3rk\PYGZus{}similar, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, etd3rk\PYGZus{}naive, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}rk2, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, rk2, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
lmba\PYGZus{}1D\PYGZus{}rk4, domain = errors\PYGZus{}for\PYGZus{}lambdas\PYGZus{}array(n, rk4, t0, tf, x0, lmba0, lmbaf, A\PYGZus{}1D, g, sol\PYGZus{}given\PYGZus{}lmba, vectorize\PYGZus{}sol\PYGZus{}given\PYGZus{}lmba, error\PYGZus{}2)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/tmp/ipykernel\PYGZus{}10101/3543048019.py:247: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.sqrt(float(np.sum(v)/x\PYGZus{}approx.size)) \PYGZsh{}normalized
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
matrix\PYGZus{}1D = [lmba\PYGZus{}1D\PYGZus{}classic, lmba\PYGZus{}1D\PYGZus{}exponential, lmba\PYGZus{}1D\PYGZus{}rk2, lmba\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, lmba\PYGZus{}1D\PYGZus{}etd2rk, lmba\PYGZus{}1D\PYGZus{}rk4, lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, lmba\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar]
names = [\PYGZsq{}classic euler\PYGZsq{}, \PYGZsq{}exponential euler\PYGZsq{}, \PYGZsq{}rk2\PYGZsq{}, \PYGZsq{}etd2rk naive\PYGZsq{}, \PYGZsq{}etd2rk\PYGZsq{}, \PYGZsq{}rk4\PYGZsq{}, \PYGZsq{}etd3rk naive\PYGZsq{}, \PYGZdq{}etd3rk (similar)\PYGZdq{}]
fig, ax = graphic\PYGZus{}2D(8*[domain], matrix\PYGZus{}1D, names, \PYGZdq{}lambda\PYGZdq{}, \PYGZdq{}error\PYGZdq{}, \PYGZdq{}1D problem from [1]\PYGZdq{}, False, True)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{appendix_24_0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
n0 = 10
k = 10
lmba = 100
A = lmba * np.array([[1]])
t0 = 0.0
tf = 1.0
x0 = np.array([1])
n\PYGZus{}1D\PYGZus{}classic, domain = errors\PYGZus{}2x(n0, k, classic\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}exponential, domain = errors\PYGZus{}2x(n0, k, exponential\PYGZus{}euler, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd2rk, domain = errors\PYGZus{}2x(n0, k, etd2rk, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, domain = errors\PYGZus{}2x(n0, k, etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}similar, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, domain = errors\PYGZus{}2x(n0, k, etd3rk\PYGZus{}naive, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}rk2, domain = errors\PYGZus{}2x(n0, k, rk2, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
n\PYGZus{}1D\PYGZus{}rk4, domain = errors\PYGZus{}2x(n0, k, rk4, t0, tf, x0, A, g, sol, vectorize\PYGZus{}sol, error\PYGZus{}2)
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
/tmp/ipykernel\PYGZus{}10101/3543048019.py:247: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.sqrt(float(np.sum(v)/x\PYGZus{}approx.size)) \PYGZsh{}normalized
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}
\begin{sphinxuseclass}{cell}\begin{sphinxVerbatimInput}

\begin{sphinxuseclass}{cell_input}
\begin{sphinxVerbatim}[commandchars=\\\{\}]
matrix\PYGZus{}2D = [n\PYGZus{}1D\PYGZus{}classic, n\PYGZus{}1D\PYGZus{}exponential, n\PYGZus{}1D\PYGZus{}rk2, n\PYGZus{}1D\PYGZus{}etd2rk\PYGZus{}trapezoidal\PYGZus{}naive, n\PYGZus{}1D\PYGZus{}etd2rk, n\PYGZus{}1D\PYGZus{}rk4, n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}naive, n\PYGZus{}1D\PYGZus{}etd3rk\PYGZus{}similar]
names = [\PYGZsq{}classic euler\PYGZsq{}, \PYGZsq{}exponential euler\PYGZsq{}, \PYGZsq{}rk2\PYGZsq{}, \PYGZsq{}etd2rk naive\PYGZsq{}, \PYGZsq{}etd2rk\PYGZsq{}, \PYGZsq{}rk4\PYGZsq{}, \PYGZsq{}etd3rk naive\PYGZsq{}, \PYGZdq{}etd3rk (similar)\PYGZdq{}]
fig\PYGZus{}2D, ax\PYGZus{}2D = graphic\PYGZus{}2D(8*[1/domain], matrix\PYGZus{}2D, names, \PYGZdq{}h\PYGZdq{}, \PYGZdq{}error\PYGZdq{}, \PYGZdq{}1D problem with lmba = \PYGZdq{}+str(lmba), False, True)
plt.xscale(\PYGZsq{}log\PYGZsq{})
\end{sphinxVerbatim}

\end{sphinxuseclass}\end{sphinxVerbatimInput}
\begin{sphinxVerbatimOutput}

\begin{sphinxuseclass}{cell_output}
\noindent\sphinxincludegraphics{{appendix_26_0}.png}

\end{sphinxuseclass}\end{sphinxVerbatimOutput}

\end{sphinxuseclass}

\section{Some deductions}
\label{\detokenize{appendix:some-deductions}}
\sphinxAtStartPar
Here is used informations from {[}1{]}, {[}6{]}, {[}7{]}.


\subsection{Exponential Euler method}
\label{\detokenize{appendix:exponential-euler-method}}
\sphinxAtStartPar
For

\sphinxAtStartPar
\(\begin{cases}
    y'(t) + \lambda y(t) = g(y(t), t), t \in (t_0, T) \\
    y(0) = y_0
\end{cases}\)

\sphinxAtStartPar
the domain is evenly discretized:
\begin{equation*}
\begin{split}
    N \in \mathbb{N}; h = \frac{T-t_0}{N}; \text{Domain: }\{t_k = t_0 + k h : k = 0, 1, ...\}.
\end{split}
\end{equation*}
\sphinxAtStartPar
The discretization of the ODE takes the exact solution of the Cauchy problem, given by the variation of constants formula
\begin{equation*}
\begin{split}
    y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t [e^{-\lambda(t-\tau)} g(y(\tau), \tau)] d\tau
\end{split}
\end{equation*}
\sphinxAtStartPar
and, by Taylor expansion on \(g\):

\sphinxAtStartPar
\(\tau \in (t_k, t_{k+1})\)
\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(\theta_k), \theta_k)
\end{split}
\end{equation*}
\sphinxAtStartPar
for a \(\theta_k \in (t_k, t_{k+1}),\)
\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-(t_{k+1}-t_k) \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} [e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau)] d\tau
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} \left[e^{-\lambda(t_{k+1}-\tau)} \left( g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(\theta_k), \theta_k)\right)\right] d\tau
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d\tau + \frac{dg}{dt} (y(\theta_k), \theta_k) \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d\tau.
\end{split}
\end{equation*}
\sphinxAtStartPar
Since
\begin{equation*}
\begin{split}
    \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d\tau = h\phi_1(-\lambda h)= \frac{1-e^{-h \lambda}}{\lambda}
\end{split}
\end{equation*}
\sphinxAtStartPar
and, by the Taylor expansion of \(e^{-\lambda h}\) in the point zero
\begin{equation*}
\begin{split}
    e^{-\lambda h} = 1 - \lambda h + \frac{1}{2}\lambda^2h^2 - \frac{1}{3!}\lambda^3h^3 + \dotsi + \frac{1}{n!} (-\lambda h)^n + \dotsi, n \in \mathbb{N}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
     \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d\tau =
     h^2 \phi_2 (-\lambda h) =
     h \frac{\phi_1(0) - \phi_1(-\lambda h)}{\lambda} =
     \frac{h}{\lambda} - \frac{1-e^{-h \lambda}}{\lambda^2} = \\
     \frac{h}{\lambda} - \frac{1-(1 - \lambda h + \frac{1}{2}\lambda^2h^2 - \frac{1}{3!}\lambda^3h^3 + \dotsi + \frac{1}{n!} (-\lambda h)^n + \dotsi)}{\lambda^2} = \\
     \frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^n}{n!} (-\lambda)^{n-2} + \dotsi  =  O(h^2),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + \frac{dg}{dt} (y(\theta_k), \theta_k) O(h^2),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2).
\end{split}
\end{equation*}
\sphinxAtStartPar
That inspires the \(\textbf{Exponential Euler method}\) :
\begin{equation*}
\begin{split}
y_0 = y(t_0)\\
\textbf{for } k = 0, 1, 2, ..., N-1 :\\
    y_{k+1} = e^{-h \lambda}y_k + g(y_k, t_k) \frac{1-e^{-h \lambda}}{\lambda}\\
    t_{k+1} = t_k + h
\end{split}
\end{equation*}
\sphinxAtStartPar
with \(y_k \thickapprox y(t_k)\).


\subsection{Exponential time differencing methods (ETD)}
\label{\detokenize{appendix:exponential-time-differencing-methods-etd}}
\sphinxAtStartPar
In the same conditions as above, it is taken a general Taylor expansion of \(g\):

\sphinxAtStartPar
\(\tau \in (t_k, t_{k+1}), n \in \mathbb{N}\)
\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + \frac{(\tau - t_k)^2}{2!} \frac{d^2g}{dt^2} (y(t_k), t_k) + \\
    \dotsi + \frac{(\tau - t_k)^{n-1}}{(n-1)!} \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k) + \frac{(\tau - t_k)^n}{n!} \frac{d^ng}{dt^n} (y(\theta_k), \theta_k)
\end{split}
\end{equation*}
\sphinxAtStartPar
for a \(\theta_k \in (t_k, t_{k+1})\)

\sphinxAtStartPar
In
\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau) d\tau
\end{split}
\end{equation*}
\sphinxAtStartPar
It will now become
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)}  g(y(t_k), t_k) +
(\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) +
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
 \frac{(\tau - t_k)^2}{2!} \frac{d^2g}{dt^2} (y(t_k), t_k) + \dotsi + 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
 + \frac{(\tau - t_k)^{n-1}}{(n-1)!} \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k) + \frac{(\tau - t_k)^n}{n!} \frac{d^ng}{dt^n} (y(\theta_k), \theta_k)  d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \frac{dg}{dt}(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} (\tau - t_k)d\tau + \frac{d^2g}{dt^2} (y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^2}{2!}d\tau +
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \dotsi +
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)\int_{t_k}^{t_{k+1}}  e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^{n-1}}{(n-1)!} d\tau + \frac{d^ng}{dt^n} (y(\theta_k), \theta_k) \int_{t_k}^{t_{k+1}}  e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^n}{n!} d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
h\phi_1(-\lambda h) g(y(t_k), t_k) +
h^2\phi_2(-\lambda h) \frac{dg}{dt}(y(t_k), t_k) +
h^3\phi_3(-\lambda h)\frac{d^2g}{dt^2} (y(t_k), t_k)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \dotsi +
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ h^n\phi_n(-\lambda h) \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)+
h^{n+1}\phi_{n+1}(-\lambda h) \frac{d^ng}{dt^n} (y(\theta_k), \theta_k).
\end{split}
\end{equation*}
\sphinxAtStartPar
From the discussion about the exponential Euler, that is known that
\begin{equation*}
\begin{split}
h^2\phi_2(-\lambda h) = \frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^l}{l!} (-\lambda)^{l-2} + \dotsi = \frac{1}{(-\lambda)^2} \sum\limits_{i=2}^{\infty} \frac{(-\lambda h)^i}{i!}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Since
\begin{equation*}
\begin{split}
  \phi_{n+1}(-\lambda h) = \frac{\phi_n(-\lambda h) - \phi_n(0)}{-\lambda h} \text{ and}\\
  \phi_n(0) = \frac{1}{n!},
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  h^3 \phi_3(-\lambda h) = h^2 \frac{\phi_2(0) - \phi_2(-\lambda h)}{\lambda} = \frac{\frac{h^2}{2} - (\frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^l}{l!} (-\lambda)^{l-2} + O(h^{l+1}))}{\lambda} = \frac{1}{(-\lambda)^3} \sum\limits_{i=3}^{\infty} \frac{(-\lambda h)^i}{i!}.
\end{split}
\end{equation*}
\sphinxAtStartPar
And if
\begin{equation*}
\begin{split}
h^l \phi_l(-\lambda h) = \frac{1}{(-\lambda)^l} \sum\limits_{i=l}^{\infty} \frac{(-\lambda h)^i}{i!}, \text{for a } l \in \mathbb{N},
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  h^{l+1}\phi_{l+1}(-\lambda h) = h^{l+1} \frac{\phi_l(-\lambda h) - \phi_l(0)}{-\lambda h} = \frac{h^l \phi_l(0) - h^l \phi_l(-\lambda h)}{\lambda} = \frac{h^l}{l! \lambda} - \frac{1}{\lambda} \frac{1}{(-\lambda)^l} \sum\limits_{i=l}^{\infty} \frac{(-\lambda h)^i}{i!} = \frac{1}{(-\lambda)^{l+1}} \sum\limits_{i=l+1}^{\infty} \frac{(-\lambda h)^i}{i!}.
\end{split}
\end{equation*}
\sphinxAtStartPar
So, by induction,
\begin{equation*}
\begin{split}
h^n \phi_n(-\lambda h) = \frac{1}{(-\lambda)^n} \sum\limits_{i=n}^{\infty} \frac{(-\lambda h)^i}{i!} = O(h^n), \forall n \geq 2.
\end{split}
\end{equation*}
\sphinxAtStartPar
Then,
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
h\phi_1(-\lambda h) g(y(t_k), t_k) +
h^2\phi_2(-\lambda h) \frac{dg}{dt}(y(t_k), t_k) +
h^3\phi_3(-\lambda h)\frac{d^2g}{dt^2} (y(t_k), t_k) +
\dotsi + \\
h^n\phi_n(-\lambda h) \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)+
O(h^{n+1}).
\end{split}
\end{equation*}

\subsection{Exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping \sphinxhyphen{} order 2 \sphinxhyphen{} Cox and Matthews \sphinxhyphen{} Trapezoidal rule}
\label{\detokenize{appendix:exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-trapezoidal-rule}}
\sphinxAtStartPar
For the second order method, that is used the approximation
\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
\(\forall \tau \in (t_k, t_{k+1}).\)

\sphinxAtStartPar
The first derivative is discretized with the Taylor expansion
\begin{equation*}
\begin{split}
g(y(t_{k+1}), t_{k+1}) = g(y(t_k), t_k) + h \frac{dg}{dt} (y(t_k), t_k) + O(h^2)
\end{split}
\end{equation*}
\sphinxAtStartPar
and the exponential Euler expression
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
so that
\begin{equation*}
\begin{split}
\frac{dg}{dt} (y(t_k), t_k)  = \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} + O(h), \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda},
\end{split}
\end{equation*}
\sphinxAtStartPar
which results in the expression
\begin{equation*}
\begin{split}
g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Putting in the variation of constants formula
\begin{equation*}
\begin{split}
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
  + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g(y(t_k), t_k) + (\tau - t_k)  \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h}  + (\tau - t_k)O(h) \right] d\tau
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) + g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau + \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau + \\
+ O(h)\int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Then,
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} h^2 \phi_2 (-\lambda h) + \\
  + O(h)h^2 \phi_2 (-\lambda h) \\
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h) + \\
  + O(h^3) \\
  \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Butcher tableau:
\begin{equation*}
\begin{split}
\begin{array}
{c|cc}
0\\
1 & \phi_1(-\lambda h)\\
\hline
& \phi_1 (-\lambda h) - \phi_2 (-\lambda h) & \phi_2 (-\lambda h)
\end{array}
\end{split}
\end{equation*}

\subsection{Exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping \sphinxhyphen{} order 2 \sphinxhyphen{} Cox and Matthews \sphinxhyphen{} Midpoint rule}
\label{\detokenize{appendix:exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-midpoint-rule}}
\sphinxAtStartPar
From the same expression:
\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
\(\forall \tau \in (t_k, t_{k+1}).\)

\sphinxAtStartPar
The first derivative is now discretized with the Taylor expansion
\begin{equation*}
\begin{split}
g\left(y\left(t_k + \frac{h}{2}\right), t_k + \frac{h}{2} \right) = g(y(t_k), t_k) + \frac{h}{2} \frac{dg}{dt} (y(t_k), t_k) + O(h^2)
\end{split}
\end{equation*}
\sphinxAtStartPar
and the exponential Euler expression taken is with time step \(\frac{h}{2}\)
\begin{equation*}
\begin{split}
  y\left(t_k + \frac{h}{2}\right) = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right) + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
so that
\begin{equation*}
\begin{split}
\frac{dg}{dt} (y(t_k), t_k)  = 2 \frac{g\left(b_k, t_k + \frac{h}{2} \right) - g(y(t_k), t_k)}{h} + O(h), \\
\text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}
\end{equation*}
\sphinxAtStartPar
which results in the expression
\begin{equation*}
\begin{split}
g(y(\tau), \tau) = g(y(t_k), t_k) + 2(\tau - t_k) \frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \\
\text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Putting in the variation of constants formula
\begin{equation*}
\begin{split}
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
    + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g(y(t_k), t_k) + 2(\tau - t_k) \frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \right] d\tau
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) + g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau + \\
  + 2\frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau + O(h)\int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau \\
  \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Then,
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  2\frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} h^2 \phi_2 (-\lambda h) + \\
  + O(h)h^2 \phi_2 (-\lambda h) \\
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  2 \left[g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h) + \\
  + O(h^3) \\
  \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Butcher tableau:

\sphinxAtStartPar
\textbackslash{}begin\{array\}
\{c|cc\}
0\textbackslash{}
\textbackslash{}frac\{1\}\{2\} \& \textbackslash{}frac\{1\}\{2\}\textbackslash{}phi\_1\textbackslash{}left(\sphinxhyphen{}\textbackslash{}frac\{\textbackslash{}lambda h\}\{2\}\textbackslash{}right)\textbackslash{}
\textbackslash{}hline
\& \textbackslash{}phi\_1 (\sphinxhyphen{}\textbackslash{}lambda h) \sphinxhyphen{} 2 \textbackslash{}phi\_2 (\sphinxhyphen{}\textbackslash{}lambda h) \& \sphinxhyphen{}2 \textbackslash{}phi\_2 (\sphinxhyphen{}\textbackslash{}lambda h)
\textbackslash{}end\{array\}


\subsection{Exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping \sphinxhyphen{} order 2 \sphinxhyphen{} Classical approach \sphinxhyphen{} Trapezoidal rule}
\label{\detokenize{appendix:exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-trapezoidal-rule}}
\sphinxAtStartPar
It is also possible to think the exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping using the numerical integration, for example, for the one with second order, it starts with the trapezoidal rule (which was taken from {[}2{]}) on the variation of constants formula:
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda(t_{k+1}-t_k)} g(y(t_k), t_k) + e^{-\lambda(t_{k+1}-t_{k+1})} g(y(t_{k+1}), t_{k+1}) \right] + O(h^3), \\
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(y(t_{k+1}), t_{k+1}) \right] +  O(h^3).
\end{split}
\end{equation*}
\sphinxAtStartPar
And then, from the expression seen before:
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    g(y(t_{k+1}), t_{k+1}) = g(a_k, t_{k+1}) + O(h^2) \text{, with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}
\end{equation*}
\sphinxAtStartPar
So,
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) + O(h^2) \right] +  O(h^3),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right] +  O(h^3) \\
    \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}
\end{equation*}
\sphinxAtStartPar
Butcher tableau:
\begin{equation*}
\begin{split}
\begin{array}
{c|cc}
0\\
1 & \phi_1(-\lambda h)\\
\hline
& \frac{1}{2} e^{-h \lambda} & \frac{1}{2}
\end{array}
\end{split}
\end{equation*}

\subsection{Exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping \sphinxhyphen{} order 2 \sphinxhyphen{} Classical approach \sphinxhyphen{} Midpoint rule}
\label{\detokenize{appendix:exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-midpoint-rule}}
\sphinxAtStartPar
Besides that, using the midpoint rule, also known as rectangle rule, again taken from {[}2{]},
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-(t_{k+1}-t_k) \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} [e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau)] d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{-\lambda\left(t_{k+1}-\frac{t_{k+1}+t_k}{2}\right)} g\left(y\left(\frac{t_{k+1}+t_k}{2}\right), \frac{t_{k+1}+t_k}{2}\right) + O(h^3),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(y\left(t_k + \frac{h}{2}\right), t_k+\frac{h}{2}\right) + O(h^3),
\end{split}
\end{equation*}
\sphinxAtStartPar
and Exponential Euler with time step \(\frac{h}{2}\)
\begin{equation*}
\begin{split}
y\left(t_k + \frac{h}{2}\right) = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right) + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
results in
\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(b_k + O(h^2), t_k + \frac{h}{2}\right) + O(h^3) \\
    \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(b_k , t_k + \frac{h}{2}\right) + O(h^3) \\
    \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}
\end{equation*}
\sphinxAtStartPar
Butcher tableau:
\begin{equation*}
\begin{split}
\begin{array}
{c|cc}
0\\
\frac{1}{2} &  \frac{1}{2} \phi_1( -\frac{\lambda h}{2})\\
\hline
& 0 & e^{-\frac{h \lambda}{2}}
\end{array}
\end{split}
\end{equation*}

\subsection{Third order exponential time differencing methods with Runge\sphinxhyphen{}Kutta time stepping (ETDRK\sphinxhyphen{}3)}
\label{\detokenize{appendix:third-order-exponential-time-differencing-methods-with-runge-kutta-time-stepping-etdrk-3}}\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O((\tau - t_k)^4),
\end{split}
\end{equation*}
\sphinxAtStartPar
\(\forall \tau \in \mathbb{R}.\)
\begin{equation*}
\begin{split}
    g(y(t_{k+1}), t_{k+1}) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(t_{k+1} - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_{k+1} - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_{k+1} - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    g(y(t_{k+1}), t_{k+1}) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \frac{h}{2} \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    +\frac{h^2}{8} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + \frac{h^3}{48} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}
\end{equation*}
\sphinxAtStartPar
and
\begin{equation*}
\begin{split}
    g(y(t_k), t_k) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(t_k - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_k - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_k - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    g(y(t_k), t_k) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) -
    \frac{h}{2} \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{h^2}{8} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    - \frac{h^3}{48} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4).
\end{split}
\end{equation*}
\sphinxAtStartPar
Subtracting the two expressions,
\begin{equation*}
\begin{split}
  g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k) = h \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + O(h^3).
\end{split}
\end{equation*}
\sphinxAtStartPar
So,
\begin{equation*}
\begin{split}
  \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) = \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + O(h^2).
\end{split}
\end{equation*}
\sphinxAtStartPar
And summing them
\begin{equation*}
\begin{split}
  g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) =
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  + \frac{h^2}{4} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + O(h^4).
\end{split}
\end{equation*}
\sphinxAtStartPar
So,
\begin{equation*}
\begin{split}
  \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) =
  4\frac{ g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)}{h^2}
  + O(h^2).
\end{split}
\end{equation*}
\sphinxAtStartPar
This results in the expression
\begin{equation*}
\begin{split}
    g(y(\tau), \tau) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right)  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2} + \\
    + O((\tau - t_k)^3),
\end{split}
\end{equation*}
\sphinxAtStartPar
\(\forall \tau \in \mathbb{R}.\)

\sphinxAtStartPar
Putting in the variation of constants formula
\begin{equation*}
\begin{split}
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
  + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right)  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2} + O((\tau - t_k)^3) \right] d\tau,
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \left(\tau - t_{k+\frac{1}{2}}\right) e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau
  + \int_{t_k}^{t_{k+1}} O((\tau - t_k)^3) e^{-\lambda(t_{k+1}-\tau)} d \tau,
\end{split}
\end{equation*}
\sphinxAtStartPar
Since \(\tau - t_{k+ \frac{1}{2}} = \tau - t_k - \frac{h}{2}\) and \(\left(\tau - t_{k+ \frac{1}{2}} \right)^2 = (\tau - t_k)^2 + \frac{h^2}{4} - h (\tau - t_k)\),
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \left(\tau - t_{k}\right) e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{(\tau - t_k)^2}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  - \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \frac{h}{2} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{h^2}{4 \cdot 2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  - \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{h (\tau - t_k)}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \int_{t_k}^{t_{k+1}} O((\tau - t_k)^3) e^{-\lambda(t_{k+1}-\tau)} d \tau.
\end{split}
\end{equation*}
\sphinxAtStartPar
Then,
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  h^2 \phi_2 (-h \lambda) +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  h^3 \phi_3 (-h \lambda) +
  \\
  - \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \frac{h^2 \phi_1(-h \lambda)}{2} +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \frac{h^3 \phi_1(-h \lambda)}{8} +
  \\
  - \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \frac{h^3 \phi_2(-h \lambda)}{2} +
  \\
  + O(h^4 \phi_4(-h \lambda)).
\end{split}
\end{equation*}
\sphinxAtStartPar
i.e.
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) + %ok
  \left[g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)\right]
  \left( h \phi_2 (-h \lambda) - \frac{h \phi_1(-h \lambda)}{2} \right) +
  \\
  + 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]
  \left( h \phi_3 (-h \lambda) + \frac{h \phi_1(-h \lambda)}{8} - \frac{h \phi_2(-h \lambda)}{2} \right) + O(h^4).
\end{split}
\end{equation*}
\sphinxAtStartPar
Using the Cox and Mathhews’s ETDRK\sphinxhyphen{}2 expressions to approximate \(y\left(t_{k+\frac{1}{2}}\right)\) and \(y(t_{k+1})\), since those are of order 2, i.e., \(O(h^3)\), the expression of the method is
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(c'_k, t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) + %ok
  \left[g(c_k, t_{k+1}) - g(y(t_k), t_k)\right]
  \left( h \phi_2 (-h \lambda) - \frac{h \phi_1(-h \lambda)}{2} \right) +
  \\
  + 4 \left[g(c_k, t_{k+1}) + g(y(t_k), t_k) - 2 g\left(c'_k, t_{k+\frac{1}{2}}\right) \right]
  \left( h \phi_3 (-h \lambda) + \frac{h \phi_1(-h \lambda)}{8} - \frac{h \phi_2(-h \lambda)}{2} \right) + O(h^4),
\end{split}
\end{equation*}
\sphinxAtStartPar
with
\begin{equation*}
\begin{split}
  c_k = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h),
  \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1(-h\lambda),
  \\
  c'_k = e^{- \frac{h \lambda}{2}} y(t_k) +
  \frac{h}{2} \phi_1 \left(- \frac{\lambda h}{2} \right) g(y(t_k), t_k) +
  \left[g\left(a'_k, t_{k+\frac{1}{2}}\right) - g(y(t_k), t_k) \right] \frac{h}{2} \phi_2 \left(-\frac{\lambda h}{2}\right),
  \\
  a'_k = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left(-\frac{h \lambda}{2}\right).
\end{split}
\end{equation*}
\sphinxAtStartPar
Here de deducing isn’t exactly in Runge Kutta form, differing on the approximations for steps in minor order, so it cannot be a Butcher tableau, but doing language abuse only on the part that would form the triangle, it would be:

\sphinxAtStartPar
\textbackslash{}begin\{array\}
\{c|cccc\}
0 \textbackslash{}
\textbackslash{}frac\{1\}\{2\} \& \textbackslash{}frac\{1\}\{2\} \textbackslash{}left( \textbackslash{}phi\_1\textbackslash{}left(\sphinxhyphen{} \textbackslash{}frac\{\textbackslash{}lambda h\}\{2\} \textbackslash{}right) \sphinxhyphen{} \textbackslash{}phi\_2\textbackslash{}left(\sphinxhyphen{} \textbackslash{}frac\{\textbackslash{}lambda h\}\{2\} \textbackslash{}right) \textbackslash{}right) \& \textbackslash{}frac\{1\}\{2\}\textbackslash{}phi\_2\textbackslash{}left(\sphinxhyphen{} \textbackslash{}frac\{\textbackslash{}lambda h\}\{2\} \textbackslash{}right) \textbackslash{}
1 \& \textbackslash{}phi\_1\textbackslash{}left(\sphinxhyphen{} \textbackslash{}lambda h \textbackslash{}right) \sphinxhyphen{} \textbackslash{}phi\_2\textbackslash{}left(\sphinxhyphen{} \textbackslash{}lambda h \textbackslash{}right) \& 0 \& \textbackslash{}phi\_2\textbackslash{}left(\sphinxhyphen{} \textbackslash{}lambda h \textbackslash{}right)  \textbackslash{}
\textbackslash{}hline
\& 4 \textbackslash{}phi\_3(\sphinxhyphen{}h \textbackslash{}lambda)\sphinxhyphen{}3\textbackslash{}phi\_2(\sphinxhyphen{}h\textbackslash{}lambda)+\textbackslash{}phi\_1(\sphinxhyphen{}h\textbackslash{}lambda) \& \sphinxhyphen{}8\textbackslash{}phi\_3(\sphinxhyphen{}h\textbackslash{}lambda)+4\textbackslash{}phi\_2(\sphinxhyphen{}h\textbackslash{}lambda) \& 4 \textbackslash{}phi\_3(\sphinxhyphen{}h\textbackslash{}lambda)\sphinxhyphen{}\textbackslash{}phi\_2(\sphinxhyphen{}h\textbackslash{}lambda) \textbackslash{}text\{   \}.
\textbackslash{}end\{array\}


\subsection{Naive etd3rk}
\label{\detokenize{appendix:naive-etd3rk}}
\sphinxAtStartPar
Here, that is taken the variation of constants formula:
\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau) d\tau,
\end{split}
\end{equation*}
\sphinxAtStartPar
and applied the Simpson’s rule (here was used the order of convergence from Burden) so that it will be:
\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda(t_{k+1}-t_k)} g(y(t_k), t_k) + 4 e^{-\lambda \left(t_{k+1}-t_{k + \frac{1}{2}} \right)} g\left(y\left(t_{k+\frac{1}{2}}\right), t_k + \frac{h}{2} \right) \\ + e^{-\lambda(t_{k+1}-t_{k+1})} g(y(t_{k+1}), t_{k+1}) \right] + O(h^5), \\
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda h} g(y(t_k), t_k) + 4 e^{-\frac{ \lambda h}{2}} g\left(y\left(t_k + \frac{h}{2} \right), t_k + \frac{h}{2} \right) + g(y(t_{k+1}), t_{k+1}) \right] +  O(h^5).
\end{split}
\end{equation*}
\sphinxAtStartPar
To approximate \(y\left(t_k + \frac{h}{2} \right)\):
\begin{equation*}
\begin{split}
    y\left(t_k + \frac{h}{2} \right) = e^{- \frac{h \lambda}{2}}y(t_k) + \frac{h}{4} \left[ e^{- \frac{h \lambda}{2}} g(y(t_k), t_k) + g \left(a'_{k}, t_k + \frac{h}{2} \right) \right] +  O(h^3), \\
    \text{with } a'_{k} = e^{- \frac{h \lambda}{2}} y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1 \left(-\lambda \frac{h}{2} \right),
\end{split}
\end{equation*}
\sphinxAtStartPar
and, for \(y\left(t_{k+1} \right)\):
\begin{equation*}
\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right] +  O(h^3), \\
    \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}
\end{equation*}
\sphinxAtStartPar
So, the expression is
\begin{equation*}
\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda h} g(y(t_k), t_k) + 4 e^{-\frac{ \lambda h}{2}} g\left( b'_{k}, t_k + \frac{h}{2} \right) + g(b_k, t_{k+1}) \right] +  O(h^4), \\
  \text{with } b'_{k} = e^{- \frac{h \lambda}{2}}y(t_k) + \frac{h}{4} \left[ e^{- \frac{h \lambda}{2}} g(y(t_k), t_k) + g \left(a'_{k}, t_k + \frac{h}{2} \right) \right], \\
  b_k = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right], \\
  a'_{k} = e^{- \frac{h \lambda}{2}} y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1 \left(-\lambda \frac{h}{2} \right), \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}
\end{equation*}

\section{Matrix exponential}
\label{\detokenize{appendix:matrix-exponential}}
\sphinxAtStartPar
This part has information from {[}4{]}.

\sphinxAtStartPar
Based on the Maclaurin series of the exponential function
\begin{equation*}
\begin{split}
    e^x = \sum_{i=0}^{\infty} \frac{x^i}{i!},
\end{split}
\end{equation*}
\sphinxAtStartPar
the \(\textbf{exponential of a square complex matrix }A\) is defined as
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!}.
\end{split}
\end{equation*}
\sphinxAtStartPar
This is well defined because it has been proven that the sequence \({p_k}\) with, \(\forall k \in \mathbb{N}\):
\begin{equation*}
\begin{split}
    p_k = \sum_{i=0}^{k} \frac{A^i}{i!}, \forall A \text{ as decribed above,}
\end{split}
\end{equation*}
\sphinxAtStartPar
is a Cauchy sequence, and therefore converge to a limit matrix which was denoted \(e^A\), since the set of the square complex matrix with fixed lenght with the norm
\begin{equation*}
\begin{split}
||A|| = \max_{||x||=1} ||Ax||
\end{split}
\end{equation*}
\sphinxAtStartPar
is a Banach space.


\subsection{Exponential of a zeros matrix}
\label{\detokenize{appendix:exponential-of-a-zeros-matrix}}
\sphinxAtStartPar
If \(A =   
\left[ {\begin{array}{ccccc}
    0 & 0 & 0 & \dotsm & 0\\
    0 & 0 & 0 & \dotsm & 0\\
    0 & 0 & 0 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & 0\\
\end{array} } \right] \),
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = I + A + \frac{A^2}{2} + \dotsm = I + 0 + 0 + \dotsm = I.
\end{split}
\end{equation*}

\subsection{Exponential of a diagonal matrix}
\label{\detokenize{appendix:exponential-of-a-diagonal-matrix}}
\sphinxAtStartPar
If \(A =   
\left[ {\begin{array}{ccccc}
    \lambda_1 & 0 & 0 & \dotsm & 0\\
    0 & \lambda_2 & 0 & \dotsm & 0\\
    0 & 0 & \lambda_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_{N}\\
\end{array} } \right] 
  = diag(\lambda_1, \lambda_2, \lambda_3, \dotsm, \lambda_N)\),

\sphinxAtStartPar
it is easy to note that
\begin{equation*}
\begin{split}
    A^2 = diag \left(\lambda_1^2, \lambda_2^2, \lambda_3^2, \dotsc, \lambda_N^2 \right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^3 = diag \left(\lambda_1^3, \lambda_2^3, \lambda_3^3, \dotsc, \lambda_N^3 \right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\vdots
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^j = diag \left(\lambda_1^j, \lambda_2^j, \lambda_3^j, \dotsc, \lambda_N^j \right) , \forall j \in \mathbb{N}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
\vdots
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = diag\left(\sum_{i=0}^{\infty} \frac{\lambda_1^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_2^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_3^i}{i!}, \dotsc, \sum_{i=0}^{\infty} \frac{\lambda_N^i}{i!}\right)
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = diag \left( e^{\lambda_1}, e^{\lambda_2}, e^{\lambda_3}, \dotsc, e^{\lambda_N} \right).
\end{split}
\end{equation*}
\sphinxAtStartPar
In the same way, if B is a diagonal by blocks matrix:
\begin{equation*}
\begin{split}
B =   
\left[ {\begin{array}{ccccc}
    B_1 & 0 & 0 & \dotsm & 0\\
    0 & B_2 & 0 & \dotsm & 0\\
    0 & 0 & B_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & B_{N}\\
\end{array} } \right] 
  = diag(B_1, B_2, B_3, \dotsm, B_N),
\end{split}
\end{equation*}
\sphinxAtStartPar
then
\begin{equation*}
\begin{split}
e^B = diag(e^{B_1}, e^{B_2}, e^{B_3}, \dotsm, e^{B_N}).
\end{split}
\end{equation*}

\subsection{Exponential of a matrix of ones above the diagonal}
\label{\detokenize{appendix:exponential-of-a-matrix-of-ones-above-the-diagonal}}
\sphinxAtStartPar
If \(A = A_{N \times N} =   
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] \),

\sphinxAtStartPar
one can calculate
\begin{equation*}
\begin{split}
A^2 = A \cdot A =  
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right]  \cdot 
\left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
  =   \left[ {\begin{array}{ccccccc}
    0 & 0 & 1 &  &  &  & \\
     & 0 & 0 & 1 &  &  &\\
     &  & 0 & 0 & 1 &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & 1 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right], 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^3 = A \cdot A^2 = \left[ {\begin{array}{ccccccc}
    0 & 1 &  &  &  &  & \\
     & 0 & 1 &  &  &  &\\
     &  & 0 & 1 &  &  &\\
     &  &  & 0 & 1 &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & 1 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccccc}
    0 & 0 & 1 &  &  &  & \\
     & 0 & 0 & 1 &  &  &\\
     &  & 0 & 0 & 1 &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & 1 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccccc}
    0 & 0 & 0 & 1 &  &  & \\
     & 0 & 0 & 0 & 1 &  &\\
     &  & 0 & 0 & 0 & \ddots &\\
     &  &  & 0 & 0 & \ddots & 1\\
     &  &  &  & 0 & \ddots & 0 \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    \vdots
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N-2} = \left[ {\begin{array}{ccccccc}
     &  &  &  & 0 & 1 & 0\\
     &  &  &  &  & 0 & 1 \\
     &  &  &  &  &  & 0 \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N-1} = \left[ {\begin{array}{ccccccc}
     &  &  &  &  &  & 1\\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right],
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    A^{N} = 0.
\end{split}
\end{equation*}
\sphinxAtStartPar
And then, with \(t \in \mathbb{R}\)
\begin{equation*}
\begin{split}
    e^{tA} \doteq \sum_{i=0}^{\infty} \frac{tA^i}{i!}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = Id + tA + \frac{t^2 A^2}{2} + \frac{t^3 A^3}{6} + \dotsc + \frac{t^{N-2} A^{N-2}}{(N-2)!} + \frac{t^{N-1} A^{N-1}}{(N-1)!} + 0 + 0 + \dotsc + 0
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 &  &  &  &  &  & \\
     & 1 &  &  &  &  &\\
     &  & 1 &  &  &  &\\
     &  &  & 1 &  &  &\\
     &  &  &  & 1 &  &\\
     &  &  &  &  & \ddots &\\
     &  &  &  &  &  & 1 \\
\end{array} } \right] + \left[ {\begin{array}{ccccccc}
    0 & t &  &  &  &  & \\
     & 0 & t &  &  &  &\\
     &  & 0 & t &  &  &\\
     &  &  & 0 & t &  &\\
     &  &  &  & 0 & \ddots &  \\
     &  &  &  &  & \ddots & t \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] + 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
+ \left[ {\begin{array}{ccccccc}
    0 & 0 & \frac{t^2}{2} &  &  &  & \\
     & 0 & 0 & \frac{t^2}{2} &  &  &\\
     &  & 0 & 0 & \frac{t^2}{2} &  &\\
     &  &  & 0 & 0 & \ddots &\\
     &  &  &  & 0 & \ddots & \frac{t^2}{2} \\
     &  &  &  &  & \ddots & 0 \\
     &  &  &  &  &  & 0 \\
\end{array} } \right] + \dotsc + \left[ {\begin{array}{ccccccc}
     &  &  &  &  &  & \frac{t^{N-1}}{(N-1)!}\\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
     &  &  &  &  &  &  \\
\end{array} } \right]
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 & t & \frac{t^2}{2} & \frac{t^3}{3!} & \frac{t^4}{4!} & \dotsc & \frac{t^{N-1}}{(N-1)!}\\
     & 1 & t & \frac{t^2}{2} & \frac{t^3}{3!} & \ddots & \vdots \\
     &  & 1 & t & \frac{t^2}{2} & \ddots & \frac{t^4}{4!}\\
     &  &  & 1 & t & \ddots & \frac{t^3}{3!}\\
     &  &  &  & 1 & \ddots & \frac{t^2}{2} \\
     &  &  &  &  & \ddots & t \\
     &  &  &  &  &  & 1 \\
\end{array} } \right].
\end{split}
\end{equation*}

\subsection{Exponential of a Jordan block}
\label{\detokenize{appendix:exponential-of-a-jordan-block}}
\sphinxAtStartPar
\(\textbf{Proposition:}\) \(A_1, A_2 \in \mathscr{M}_{N \times N}(\mathbb{C})\). If \(A_1 \cdot A_2 = A_2 \cdot A_1\), then \(e^{A_1+A_2} = e^{A_1} \cdot e^{A_2}\).

\sphinxAtStartPar
A Jordan block is of the form:
\$\(
J = \left[ {\begin{array}{ccccc}
    \lambda_i & 1 & 0 & \dotsm & 0\\
    0 & \lambda_i & 1 & \dotsm & 0\\
    0 & 0 & \lambda_i & \ddots & 0\\
    \vdots & \vdots & \vdots & \ddots & 1\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] 
\)\$
\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] + \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
    = D + N,
\end{split}
\end{equation*}
\sphinxAtStartPar
and
\$\(
\left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] 
\)\$
\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    0 & \lambda_i &  &  & \\
     & 0 & \lambda_i &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & \lambda_i\\
     &  &  &  & 0\\
\end{array} } \right] 
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    0 & 1 &  &  & \\
     & 0 & 1 &  &\\
     &  & 0 & \ddots &\\
     &  &  & \ddots & 1\\
     &  &  &  & 0\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right],
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
    e^{tJ} = e^{tD+tN} = e^{tD} \cdot e^{tN}
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} & 0 & 0 & \dotsm & 0\\
    0 & e^{t \lambda_i} & 0 & \dotsm & 0\\
    0 & 0 & e^{t \lambda_i} & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & e^{t \lambda_i}\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    1 & t & \frac{t^2}{2} & \dotsc & \frac{t^{N-1}}{(N-1)!}\\
     & 1 & t & \ddots & \vdots\\
     &  & 1 & \ddots & \frac{t^2}{2} \\
     &  &  & \ddots & t \\
     &  &  &  & 1 \\
\end{array} } \right]
\end{split}
\end{equation*}\begin{equation*}
\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} & e^{t \lambda_i}t & \frac{e^{t \lambda_i} t^2}{2} & \dotsc & \frac{e^{t \lambda_i} t^{N-1}}{(N-1)!}\\
     & e^{t \lambda_i} & e^{t \lambda_i} t & \ddots & \vdots\\
     &  & e^{t \lambda_i} & \ddots & \frac{e^{t \lambda_i} t^2}{2} \\
     &  &  & \ddots & e^{t \lambda_i} t \\
     &  &  &  & e^{t \lambda_i} \\
\end{array} } \right], t \in \mathbb{R}.
\end{split}
\end{equation*}

\subsection{Exponential of any matrix}
\label{\detokenize{appendix:exponential-of-any-matrix}}
\sphinxAtStartPar
\(\textbf{Proposition: } \forall A \in \mathscr{M}_{N \times N}(\mathbb{C}), \exists M \in \mathscr{M}_{N \times N}(\mathbb{C})\) invertible, such that \(A = MJM^{-1}\), with
\begin{equation*}
\begin{split} 
J = \left[ {\begin{array}{ccccc}
    J_1 & 0 & 0 & \dotsm & 0\\
    0 & J_2 & 0 & \dotsm & 0\\
    0 & 0 & J_3 & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & J_{N}\\
\end{array} } \right]
\end{split}
\end{equation*}
\sphinxAtStartPar
and each \(J_i\), \(i = 1, 2, 3, \dotsc, N\) being a Jordan block, i.e.,
\begin{equation*}
\begin{split}
J_i = \left[ {\begin{array}{ccccc}
    \lambda_i & 0 & 0 & \dotsm & 0\\
    0 & \lambda_i & 0 & \dotsm & 0\\
    0 & 0 & \lambda_i & \dotsm & 0\\
    \vdots & \vdots & \vdots & \ddots & \vdots\\
    0 & 0 & 0 & \dotsm & \lambda_i\\
\end{array} } \right]
\end{split}
\end{equation*}
\sphinxAtStartPar
for some \(\lambda_i \in \mathbb{C}\) .

\sphinxAtStartPar
Note that
\$\(
    (MJM^{-1})^k = MJM^{-1}MJM^{-1}MJM^{-1} \dotsc MJM^{-1} 
\)\$
\begin{equation*}
\begin{split}
    = MJIJIJM^{-1} \dotsc MJM^{-1} = MJJJ \dotsc JM^{-1} = MJ^kM^{-1}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Because of the formula of the series that defines the expansion, it implicates in \(e^{MJM^{-1}} = M e^J M^{-1}\).

\sphinxAtStartPar
And then, using the same notation from the last proposition,
\$\(
e^{tA} = e^{tMJM^{-1}} = e^{MtJM^{-1}} = Me^{tJ}M^{-1} 
\)\$
\begin{equation*}
\begin{split}
    = M \left[ { \begin{array}{ccccc}
        e^{tJ_1} & 0 & 0 & \dotsm & 0\\
        0 & e^{tJ_2} & 0 & \dotsm & 0\\
        0 & 0 & e^{tJ_3} & \dotsm & 0\\
        \vdots & \vdots & \vdots & \ddots & \vdots\\
        0 & 0 & 0 & \dotsm & e^{tJ_{N}}\\
    \end{array} } \right] M^{-1}, t \in \mathbb{R},
\end{split}
\end{equation*}
\sphinxAtStartPar
with each block as the section above indicates.


\section{Euler method}
\label{\detokenize{appendix:euler-method}}
\sphinxAtStartPar
Further detailing this explicit one\sphinxhyphen{}step method of
\begin{equation*}
\begin{split}
    \phi (t_{k},y_{k},h) = f(t_{k},y_{k}),
\end{split}
\end{equation*}
\sphinxAtStartPar
an analysis on stability, convergence and order of convergence is done.


\subsection{Stability}
\label{\detokenize{appendix:stability}}
\sphinxAtStartPar
For the problem
\(\begin{cases}
    y'(t) = - \lambda y(t) \text{ ; } t \in [t_0 , T] \\
    y(t_0)=y_0,
\end{cases}\)

\sphinxAtStartPar
with known solution
\begin{equation*}
\begin{split} y(t) = y_0e^{-\lambda (t-t_0)},\end{split}
\end{equation*}
\sphinxAtStartPar
the method turn into:
\begin{equation*}
\begin{split}
y_0 = y(t_0)\\
\textbf{for } k = 0, 1, 2, ..., N-1 :\\
    y_{k+1} = y_k + h \lambda y_k \\
    t_{k+1} = t_k + h.
\end{split}
\end{equation*}
\sphinxAtStartPar
Then the amplification factor is:
\$\(
(1 - h \lambda).
\)\$

\sphinxAtStartPar
If
\begin{equation*}
\begin{split}
|1 - h \lambda| > 1, \text{for fixed } N,
\end{split}
\end{equation*}
\sphinxAtStartPar
it will be a divergent series
\begin{equation*}
\begin{split}
(k \rightarrow \infty \Rightarrow y_k \rightarrow \infty),
\end{split}
\end{equation*}
\sphinxAtStartPar
so, since the computer has a limitant number that can represent, even if the number of steps is such that \(h\) is not small enought, it might have sufficient steps to reach the maximum number represented by the machine.

\sphinxAtStartPar
However, if
\begin{equation*}
\begin{split}
    |1 - h \lambda| < 1 \text{ and } N \text{ is fixed,}
\end{split}
\end{equation*}
\sphinxAtStartPar
it converges to zero
\begin{equation*}
\begin{split}
    (k \rightarrow \infty \Rightarrow y_k \rightarrow 0 ).
\end{split}
\end{equation*}
\sphinxAtStartPar
Besides that,
\begin{equation*}
\begin{split}
|1 - h \lambda| < 1
\end{split}
\end{equation*}
\sphinxAtStartPar
is the same as
\begin{equation*}
\begin{split}
0 < h \lambda < 2.
\end{split}
\end{equation*}
\sphinxAtStartPar
So the interval of stability is \((0,2)\).

\sphinxAtStartPar
That’s why the method suddenly converged, it was when \(h\) got small enought to \(h \lambda\) be in the interval of stability, i.e.,
\begin{equation*}
\begin{split}
    h < 2/\lambda.
\end{split}
\end{equation*}
\sphinxAtStartPar
It is worth mentioning here that if
\begin{equation*}
\begin{split}
-1 < 1 - h \lambda < 0,
\end{split}
\end{equation*}
\sphinxAtStartPar
the error will converge oscillating since it takes positive values with even exponents and negative with odd ones.


\subsection{Convergence}
\label{\detokenize{appendix:convergence}}
\sphinxAtStartPar
Since
\begin{equation*}
\begin{split}
\lim_{m \to +\infty} \left(1 + \frac{p}{m} \right)^m = e^p,
\end{split}
\end{equation*}
\sphinxAtStartPar
and h = \(\frac{T-t_0}{N}\), for \(y_N\) we have
\begin{equation*}
\begin{split}
\lim_{N \to +\infty} y_N = \lim_{N \to +\infty} \left(1 - h \lambda \right)^N y_0 = \lim_{N \to +\infty} \left(1 - \frac{(T-t_0) \lambda}{N} \right)^N y_0.
\end{split}
\end{equation*}
\sphinxAtStartPar
It is reasonable to take \(p = -(T-t_0) \lambda\) and conclude that the last point estimated by the method will converge to
\begin{equation*}
\begin{split}
y_0e^{-\lambda (T-t_0)}.
\end{split}
\end{equation*}
\sphinxAtStartPar
Which is precisely \(y(T)\) and proves the convergence.


\subsection{Order of convergence}
\label{\detokenize{appendix:order-of-convergence}}
\sphinxAtStartPar
Being \(\tau(h, t_k)\) the local truncation error.

\sphinxAtStartPar
From
\begin{equation*}
\begin{split}
    y(t_{k+1}) = y(t_k) + h f(y(t_k),t_k) + O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
we have
\begin{equation*}
\begin{split}
    h \tau(h, t_k) \doteq \frac{y(t_{k+1}) - y(t_k)}{h} - f(t_k, y(t_k)) = O(h^2),
\end{split}
\end{equation*}
\sphinxAtStartPar
so
\begin{equation*}
\begin{split}
    \tau(h, t_k) = O(h).
\end{split}
\end{equation*}
\sphinxAtStartPar
Since for one step methods the order of convergence is the order of the local truncation error, the order is of \(O(h)\), order 1.







\renewcommand{\indexname}{Index}
\printindex
\end{document}