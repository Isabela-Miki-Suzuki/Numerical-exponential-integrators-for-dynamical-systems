
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Appendix &#8212; Numerical exponential integrators for dynamical systems</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="prev" title="Participation in scientific event, list of publications and list of papers prepared or submitted" href="Participation_in_scientific_event%2C_list_of_publications_and_list_of_papers_prepared_or_submitted.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Numerical exponential integrators for dynamical systems</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    General Information about the Project
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Summary_of_the_proposed_project.html">
   Summary of the proposed project
  </a>
 </li>
 <li class="toctree-l1 has-children">
  <a class="reference internal" href="Project_execution.html">
   Project execution
  </a>
  <input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/>
  <label for="toctree-checkbox-1">
   <i class="fas fa-chevron-down">
   </i>
  </label>
  <ul>
   <li class="toctree-l2">
    <a class="reference internal" href="cap1.html">
     Motivation - Stiffness
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cap2.html">
     Classical methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cap3.html">
     Important concepts for the study of exponential methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cap4.html">
     Exponential methods
    </a>
   </li>
   <li class="toctree-l2">
    <a class="reference internal" href="cap5.html">
     Swing spring application
    </a>
   </li>
  </ul>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="References.html">
   References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Participation_in_scientific_event%2C_list_of_publications_and_list_of_papers_prepared_or_submitted.html">
   Participation in scientific event, list of publications and list of papers prepared or submitted
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Appendix
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/Isabela-Miki-Suzuki/Numerical-exponential-integrators-for-dynamical-systems/master?urlpath=tree/docs/appendix.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/Isabela-Miki-Suzuki/Numerical-exponential-integrators-for-dynamical-systems"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/Isabela-Miki-Suzuki/Numerical-exponential-integrators-for-dynamical-systems/issues/new?title=Issue%20on%20page%20%2Fappendix.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/appendix.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#code">
   Code
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convergence-tables">
   Convergence tables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classic-euler">
     Classic Euler
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-euler">
     Exponential Euler
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rk2">
     rk2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etd2rk-trapezoidal">
     etd2rk (trapezoidal)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-version-of-etd2rk-trapezoidal">
     Naive version of etd2rk (trapezoidal)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rk4">
     rk4
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deduced-like-etd3rk">
     Deduced like etd3rk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-version-of-etd3rk">
     Naive version of etd3rk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-graphics">
   Some graphics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-deductions">
   Some deductions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-euler-method">
     Exponential Euler method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-etd">
     Exponential time differencing methods (ETD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-trapezoidal-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Trapezoidal rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-midpoint-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Midpoint rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-trapezoidal-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Trapezoidal rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-midpoint-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Midpoint rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#third-order-exponential-time-differencing-methods-with-runge-kutta-time-stepping-etdrk-3">
     Third order exponential time differencing methods with Runge-Kutta time stepping (ETDRK-3)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-etd3rk">
     Naive etd3rk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-exponential">
   Matrix exponential
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-zeros-matrix">
     Exponential of a zeros matrix
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-diagonal-matrix">
     Exponential of a diagonal matrix
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-matrix-of-ones-above-the-diagonal">
     Exponential of a matrix of ones above the diagonal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-jordan-block">
     Exponential of a Jordan block
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-any-matrix">
     Exponential of any matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#euler-method">
   Euler method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stability">
     Stability
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convergence">
     Convergence
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#order-of-convergence">
     Order of convergence
    </a>
   </li>
  </ul>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Appendix</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#code">
   Code
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#convergence-tables">
   Convergence tables
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#classic-euler">
     Classic Euler
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-euler">
     Exponential Euler
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rk2">
     rk2
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#etd2rk-trapezoidal">
     etd2rk (trapezoidal)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-version-of-etd2rk-trapezoidal">
     Naive version of etd2rk (trapezoidal)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#rk4">
     rk4
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#deduced-like-etd3rk">
     Deduced like etd3rk
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-version-of-etd3rk">
     Naive version of etd3rk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-graphics">
   Some graphics
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#some-deductions">
   Some deductions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-euler-method">
     Exponential Euler method
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-etd">
     Exponential time differencing methods (ETD)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-trapezoidal-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Trapezoidal rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-midpoint-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Midpoint rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-trapezoidal-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Trapezoidal rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-midpoint-rule">
     Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Midpoint rule
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#third-order-exponential-time-differencing-methods-with-runge-kutta-time-stepping-etdrk-3">
     Third order exponential time differencing methods with Runge-Kutta time stepping (ETDRK-3)
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#naive-etd3rk">
     Naive etd3rk
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#matrix-exponential">
   Matrix exponential
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-zeros-matrix">
     Exponential of a zeros matrix
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-diagonal-matrix">
     Exponential of a diagonal matrix
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-matrix-of-ones-above-the-diagonal">
     Exponential of a matrix of ones above the diagonal
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-a-jordan-block">
     Exponential of a Jordan block
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#exponential-of-any-matrix">
     Exponential of any matrix
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#euler-method">
   Euler method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#stability">
     Stability
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#convergence">
     Convergence
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#order-of-convergence">
     Order of convergence
    </a>
   </li>
  </ul>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="appendix">
<h1>Appendix<a class="headerlink" href="#appendix" title="Permalink to this headline">#</a></h1>
<section id="code">
<h2>Code<a class="headerlink" href="#code" title="Permalink to this headline">#</a></h2>
<p>All the functions coded are in the following environment.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>from math import *
import numpy as np
from collections import deque
import matplotlib.pyplot as plt
from scipy.linalg import expm
from scipy import linalg

stab_lim = 1000.0

def classic_euler(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        x[:,i] = x[:,i-1] + h*(np.matmul(-A,x[:,i-1]) + g(x[:,i-1],t))
        t = t0 + i*h
        if np.any(x[:,i].real &gt; stab_lim):
            x[:,i] = np.nan
    return x

def exponential_euler(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0] = x0
    t = t0
    exponential_matrix = expm(-h*A)
    hphi1 = calculate_hphi1(h, A)
    for i in range(1, n):
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t))
        t = t0 + i*h
    return x

def calculate_hphi1(h, A):
  &#39;&#39;&#39;(float, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
  dim = A.shape[0]
  hphi1 = np.matmul(np.eye(dim)-expm(-h*A), linalg.inv(A))
  return hphi1

def calculate_hphi2(h, A, hphi1):
    #IT IS NOT H2PHI2
    &#39;&#39;&#39;(float, np.matrix, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
    dim = A.shape[0]
    hphi2 = np.matmul(np.eye(dim)-hphi1/h, linalg.inv(A))
    return hphi2

def calculate_hphi3(h, A, hphi2):
    &#39;&#39;&#39;(float, np.matrix, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
    dim = A.shape[0]
    hphi3 = np.matmul(1/2*np.eye(dim)-hphi2/h, linalg.inv(A))
    return hphi3

def etd2(t0, tf, n, x0, A, g, derivate_of_g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0] = x0
    t = t0
    exponential_matrix = expm(-h*A)
    hphi1 = calculate_hphi1(h, A)
    hphi2 = calculate_hphi2(h, A, hphi1)
    for i in range(1, n):
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t)) + h*np.matmul(hphi2,derivate_of_g(x[:,i-1],t))
        t = t0 + i*h
    return x

def rk2(t0, tf, n, x0, A, g): #heun s method
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        a = x[:,i-1] + h*(np.matmul(-A,x[:,i-1]) + g(x[:,i-1],t))
        f1 = np.matmul(-A,x[:,i-1]) + g(x[:,i-1],t)
        f2 = np.matmul(-A,a) + g(a,t)
        x[:,i] = x[:,i-1] + .5 * h * (f1 + f2)
        t = t0 + i*h
        if np.any(x[:,i].real &gt; stab_lim):
            x[:,i] = np.nan
    return x

def etd2rk(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    exponential_matrix = expm(-h*A)
    hphi1 = calculate_hphi1(h, A)
    hphi2 = calculate_hphi2(h, A, hphi1)
    for i in range(1, n):
        a = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t))
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t)) + np.matmul(hphi2,g(a, t0 + i*h)-g(x[:,i-1],t))
        t = t0 + i*h
    return x

def etd2rk_midpoint_rule(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    exponential_matrix = expm(-h*A)
    exponential_matrix_2 = expm(-h/2*A)
    h_2phi1_2 = calculate_hphi1(h/2, A)
    hphi1 = calculate_hphi1(h, A)
    hphi2 = calculate_hphi2(h, A, hphi1)
    for i in range(1, n):
        b = np.matmul(exponential_matrix_2, x[:,i-1]) + np.matmul(h_2phi1_2,g(x[:,i-1],t))
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t)) + 2*np.matmul(hphi2,g(b, t + h/2)-g(x[:,i-1],t))
        t = t0 + i*h
    return x

def etd2rk_trapezoidal_naive(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    exponential_matrix = expm(-h*A)
    hphi1 = calculate_hphi1(h, A)
    for i in range(1, n):
        a = np.matmul(exponential_matrix, x[:,i-1]) + np.matmul(hphi1,g(x[:,i-1],t))
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + .5 * h * (np.matmul(exponential_matrix, g(x[:,i-1],t)) + g(a, t0 + i*h))
        t = t0 + i*h
    return x

def etd2rk_midpoint_rule_naive(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    exponential_matrix = expm(-h*A)
    exponential_matrix_2 = expm(-h/2*A)
    h_2phi1_2 = calculate_hphi1(h/2, A)
    for i in range(1, n):
        b = np.matmul(exponential_matrix_2, x[:,i-1]) + np.matmul(h_2phi1_2,g(x[:,i-1],t))
        x[:,i] = np.matmul(exponential_matrix, x[:,i-1]) + h * np.matmul(exponential_matrix_2, g(b, t+h/2))
        t = t0 + i*h
    return x

def rk4(t0, tf, n, x0, A, g):
    &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function) -&gt; np.matrix&#39;&#39;&#39;
    h = (tf-t0)/n
    x = np.zeros((x0.size,n), dtype=np.complex_)
    x[:,0]=x0
    t = t0
    for i in range(1, n):
        k1 = np.matmul(-A,x[:,i-1]) + g(x[:,i-1],t)
        x2 = x[:,i-1] + h * k1 / 2
        k2 = np.matmul(-A,x2) + g(x2,t+h/2)
        x3 = x[:,i-1] + h * k2 / 2
        k3 = np.matmul(-A,x3) + g(x3,t+h/2)
        x4 = x[:,i-1] + h * k3
        k4 = np.matmul(-A,x4) + g(x4,t0 + i*h)
        x[:,i] = x[:,i-1] + h / 6 * (k1 + 2*k2 + 2*k3 + k4)
        t = t0 + i*h
        if np.any(x[:,i].real &gt; stab_lim):
            x[:,i] = np.nan
    return x

def etd3rk_similar(t0, tf, n, x0, A, g):
  &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
  h = (tf-t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex_)
  x[:,0]=x0
  t = t0
  exponential_matrix = expm(-h*A)
  exponential_matrix_2 = expm(-h/2*A)
  hphi1 = calculate_hphi1(h, A)
  h_2phi1_2 = calculate_hphi1(h/2, A)
  hphi2 = calculate_hphi2(h, A, hphi1)
  h_2phi2_2 = calculate_hphi2(h/2, A, h_2phi1_2)
  hphi3 = calculate_hphi3(h, A, hphi2)
  for i in range(1, n):
    fst_term = np.matmul(exponential_matrix, x[:,i-1])
    fst_term_2 = np.matmul(exponential_matrix_2, x[:,i-1])
    a = fst_term + np.matmul(hphi1,g(x[:,i-1],t))
    a_ = fst_term_2 + np.matmul(h_2phi1_2,g(x[:,i-1],t))
    c = fst_term + np.matmul(hphi1,g(x[:,i-1],t)) + np.matmul(hphi2,g(a, t0 + i*h)-g(x[:,i-1],t))
    c_ = fst_term_2 + np.matmul(h_2phi1_2,g(x[:,i-1],t)) + np.matmul(h_2phi2_2,g(a_, t0 + i*h)-g(x[:,i-1],t))
    snd_term = np.matmul(hphi1, g(c_, t+h/2))
    trd_term = np.matmul(hphi2 - hphi1/2,g(c, t0 + i*h)-g(x[:,i-1],t))
    fth_term = 4 * np.matmul(hphi3+hphi1/8-hphi2/2, g(c, t0 + i*h)+g(x[:,i-1],t)-2*g(c_, t + h/2))
    x[:,i] = fst_term + snd_term + trd_term + fth_term
    t = t0 + i*h
  return x

def etd3rk(t0, tf, n, x0, A, g):
  &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
  h = (tf-t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex_)
  x[:,0]=x0
  t = t0
  exponential_matrix = expm(-h*A)
  exponential_matrix_2 = expm(-h/2*A)
  hphi1 = calculate_hphi1(h, A)
  h_2phi1_2 = calculate_hphi1(h/2, A)
  hphi2 = calculate_hphi2(h, A, hphi1)
  h_2phi2_2 = calculate_hphi2(h/2, A, h_2phi1_2)
  hphi3 = calculate_hphi3(h, A, hphi2)
  for i in range(1, n):
    fst_term = np.matmul(exponential_matrix, x[:,i-1])
    fst_term_2 = np.matmul(exponential_matrix_2, x[:,i-1])
    a = fst_term_2 + np.matmul(h_2phi1_2,g(x[:,i-1],t))
    b = fst_term + np.matmul(hphi1,2*g(a,t+h/2)-g(x[:,i-1],t))
    snd_term = np.matmul(hphi1, g(a, t+h/2))
    trd_term = np.matmul(hphi2 - hphi1/2,g(b, t0 + i*h)-g(x[:,i-1],t))
    fth_term = 4 * np.matmul(hphi3+hphi1/8-hphi2/2, g(b, t0 + i*h)+g(x[:,i-1],t)-2*g(a, t + h/2))
    x[:,i] = fst_term + snd_term + trd_term + fth_term
    t = t0 + i*h
  return x

def etd3rk_naive(t0, tf, n, x0, A, g):
  &#39;&#39;&#39;(float, float, int, np.array, np.matrix, function, np.matrix) -&gt; np.matrix&#39;&#39;&#39;
  h = (tf-t0)/n
  x = np.zeros((x0.size,n), dtype=np.complex_)
  x[:,0]=x0
  t = t0
  exponential_matrix = expm(-h*A)
  exponential_matrix_2 = expm(-h/2*A)
  hphi1 = calculate_hphi1(h, A)
  h_2phi1_2 = calculate_hphi1(h/2, A)
  for i in range(1, n):
    fst_term = np.matmul(exponential_matrix, x[:,i-1])
    fst_term_2 = np.matmul(exponential_matrix_2, x[:,i-1])
    a = fst_term + np.matmul(hphi1,g(x[:,i-1],t))
    a_ = fst_term_2 + np.matmul(h_2phi1_2,g(x[:,i-1],t))
    c = fst_term + .5 * h * (np.matmul(exponential_matrix, g(x[:,i-1],t)) + g(a, t0 + i*h))
    c_ = fst_term_2 + .25 * h * (np.matmul(exponential_matrix_2, g(x[:,i-1],t)) + g(a_, t0 + i*h))
    snd_term = np.matmul(exponential_matrix, g(x[:,i-1],t))
    trd_term = 4*np.matmul(exponential_matrix_2, g(c_,t+h/2))
    fth_term = g(c, t0 + i*h)
    x[:,i] = fst_term + h*(snd_term + trd_term + fth_term)/6
    t = t0 + i*h
  return x

def error_2(x_approx, x_exact):
    &#39;&#39;&#39; (np.vector, np.vector) -&gt; float &#39;&#39;&#39;
    #make sure that x_approx and x_exact have the same lenght
    v = (x_approx - x_exact)*(x_approx - x_exact).conjugate()
    #^certainly pure real
    return np.sqrt(float(np.sum(v)/x_approx.size)) #normalized

def error_sup(x_approx, x_exact):
    &#39;&#39;&#39; (np.vector, np.vector) -&gt; float &#39;&#39;&#39;
    #make sure that x_approx and x_exact have the same lenght
    v = abs(x_approx - x_exact)
    return np.amax(v)

def g(x, t):
    &#39;&#39;&#39; (np.array, float) -&gt; float
        (x, t) -&gt; g(x, t)
    &#39;&#39;&#39;
    g = np.array([np.sin(t)])
    return g

def g_linear( x, t ):
    &#39;&#39;&#39; (np.array, float) -&gt; np.array
        (x, t) -&gt; g(x, t)
    &#39;&#39;&#39;
    g = np.zeros(x.size)
    return g

def sol( t ):
    &#39;&#39;&#39; (float, float) -&gt; float
    RECEIVES the initial value and a real (t).
    APPLIES the cauchy problem solution to this initial value at this point.
    RETURNS a real value.
    &#39;&#39;&#39;
    lmba = 100
    sol = np.exp(-lmba*t)+(np.exp(-lmba*t)+lmba*np.sin(t)-np.cos(t))/(1+lmba*lmba)
    return sol

def sol_given_lmba(lmba, t ):
    &#39;&#39;&#39; (float, float) -&gt; float
    RECEIVES the initial value and a real (t).
    APPLIES the cauchy problem solution to this initial value at this point.
    RETURNS a real value.
    &#39;&#39;&#39;
    sol = np.exp(-lmba*t)+(np.exp(-lmba*t)+lmba*np.sin(t)-np.cos(t))/(1+lmba*lmba)
    return sol

def vectorize_sol_given_lmba(lmba, t0, t1, n, sol):
    &#39;&#39;&#39;
    (float, float, float, int, function) -&gt; np.vector
    n is the number of steps
    &#39;&#39;&#39;
    x = np.zeros((sol(lmba,t0).size,n), dtype=np.complex_)
    h = (t1-t0)/n
    for i in range(n):
        x[:,i] = sol(lmba, t0+i*h)
    return x

def vectorize_sol(t0, t1, n, sol):
    &#39;&#39;&#39;
    (float, float, int, function) -&gt; np.vector
    n is the number of steps
    &#39;&#39;&#39;
    x = np.zeros((sol(t0).size,n), dtype=np.complex_)
    h = (t1-t0)/n
    for i in range(n):
        x[:,i] = sol(t0+i*h)
    return x

def A_1D(lmba):
  &#39;&#39;&#39;(int) -&gt; np.matrix&#39;&#39;&#39;
  return np.array([[lmba]])

def A_2D(lmba):
  &#39;&#39;&#39;(int) -&gt; np.matrix&#39;&#39;&#39;
  return np.array([[0, -lmba],[lmba, 0]])

def errors_for_lambdas_array(n, method, t0, tf, x0, lmba0, lmbaf, Af, g, sol_given_lmba, vectorize_sol_given_lmba, error):
    &#39;&#39;&#39;
    This function is a variation of the errors_array function. Here, the linear
    part of the problem is varying instead of the number of steps, which is now
    fixed.
    This function will RETURN 2 arrays.
    The first one has the errors of the approximations given by the method with
    coefficient of the linear part of the ploblem
    A = Af(lmba0), Af(lmba0+1), Af(lmba0+2), ..., Af(lmbaf-1).
    The second is [lmba0, lmba0+1, lmba0+2, ..., lmbaf-1]

    RECEIVES:
    n is the number of steps. (int)
    method have arguments (t0, tf, n, x0, lmba, g) and return a
    np.vector of length n (0, 1, 2, ..., n-1), n is the number of steps. (function)
    t0 is the initial point of the approximation. (float)
    tf is the last one. (float)
    x0 is the initial value of the Cauchy problem. (np.array)
    lmba0 and lmbaf are integers as described before. (int)
    Af is a function that receives the stiffness parameter and returns the
    corresponding linear coefficient. (function)
    g is a function (float, float) -&gt; (float). (function)
    sol is a function (float) -&gt; (float). (function)
    vectorize_sol is a function that &quot;transforms sol in a vector&quot; (function)
    (float, float, int, function) -&gt; (np.array)
    (t0, tf, n, sol) -&gt; np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf-1]])
    error is a function (np.array, np.array) -&gt; (float) (function)
    &#39;&#39;&#39;
    v = np.zeros(lmbaf-lmba0)
    domain = np.arange(lmba0, lmbaf)
    for i in range(lmbaf-lmba0):
        lmba = lmba0 + i
        m = method(t0, tf, n, x0, Af(lmba), g)
        exact = vectorize_sol_given_lmba(lmba, t0, tf, n, sol_given_lmba)
        if np.max(np.abs(m))&gt;1000:
            v[lmba-lmba0]=np.nan
        else:
            v[lmba-lmba0] = error(m, exact)
    return v, domain

def errors_array(n0, nf, method, t0, tf, x0, A, g, sol, vectorize_sol, error):
  &#39;&#39;&#39;
  This function will RETURN 2 arrays.
  The first one has the errors of the approximations given by the method with
  number of steps n = n0, n0+1, n0+2, ..., nf-1.
  The second is [n0, n0+1, n0+2, ..., nf-1]

  RECEIVES:
  n0 is the first number of steps. (int)
  nf is the last one plus 1. (int)
  method have arguments (t0, tf, n, x0, A, lmba, g) and return a
  np.vector of length n (0, 1, 2, ..., n-1), n is the number of steps. (function)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  x0 is the initial value of the Cauchy problem. (float)
  A is the coefficient os the linear part of the ploblem. (float)
  g is a function (int, float, float) -&gt; (float). (function)
  sol is a function (int, float) -&gt; (float). (function)
  vectorize_sol is a function that &quot;transforms sol in a vector&quot; (function)
  (float, float, int, function) -&gt; (np.array)
  (t0, tf, n, sol) -&gt; np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf-1]])
  error is a function (np.array, np.array) -&gt; (float) (function)
  &#39;&#39;&#39;
  v = np.zeros(nf-n0)
  domain = np.arange(n0, nf)
  for n in range(n0, nf):
    m = method(t0, tf, n, x0, A, g)
    exact = vectorize_sol(t0, tf, n, sol)
    if np.max(np.abs(m))&gt;1000:
        v[n-n0]=np.nan
    else:
        v[n-n0] = error(m, exact)
  return v, domain

def graphic_2D(domain, matrix, names, labelx, labely, title, key1, key2):
  &#39;&#39;&#39;
  domain is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines. (list)
  matrix is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines - same length that domain. (list)
  names is a list of the labels for the graphs, must have the same length that
  the number of lines in matrix. (list of Strings)
  labelx is the name of the x coordinate. (String)
  labely is the name of the y coordinate. (String)
  title is the title of the graph. (String)
  key1 is a boolean that indicates if the last graph must be black. (bool)
  key2 is a boolean that indicates if it should use the log scale. (bool)
  &#39;&#39;&#39;
  fig, ax = plt.subplots()

  colors = [&#39;red&#39;, &#39;orange&#39;, &#39;brown&#39;, &#39;green&#39;, &#39;cyan&#39;, &#39;blue&#39;, &#39;pink&#39;, &#39;yellow&#39;, &#39;gold&#39;, &#39;maroon&#39;]
  for i in range(len(names)-1):
    ax.plot(domain[i], matrix[i], color=colors[i], label=names[i])
  if key1:
    ax.plot(domain[len(names)-1], matrix[len(names)-1], color=&#39;black&#39;, label=names[len(names)-1])
  else:
    ax.plot(domain[len(names)-1], matrix[len(names)-1], color=colors[len(names)-1], label=names[len(names)-1])
  if key2:
    plt.yscale(&#39;log&#39;)
  ax.legend()
  ax.set_xlabel(labelx)
  ax.set_ylabel(labely)
  ax.set_title(title)
  return fig, ax

def graphic_3D(domain, matrix1, matrix2, names, labelx, labely, labelz, title, key1, key2):
  &#39;&#39;&#39;
  domain is a list of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines. (list)
  matrix1 and matrix2 are lists of np.arrays [[length n1], [legth n2], ..., [length nk]]
  k = 1, 2, ..., 5 lines - same length that domain. (list)
  names is a list of the labels for the graphs, must have the same length that
  the number of lines in matrix. (list of Strings)
  labelx is the name of the x coordinate. (String)
  labely is the name of the y coordinate. (String)
  labelz is the name of the z coordinate. (String)
  title is the title of the graph. (String)
  key1 is a boolean that indicates if the last graph must be black. (bool)
  key2 is a boolean that indicates if it should use the log scale. (bool)
  &#39;&#39;&#39;
  fig = plt.figure()
  ax = plt.figure().add_subplot(projection=&#39;3d&#39;)

  colors = [&#39;blue&#39;, &#39;green&#39;, &#39;red&#39;, &#39;cyan&#39;, &#39;magenta&#39;, &#39;yellow&#39;]
  for i in range(len(names)-1):
    ax.plot(domain[i], matrix1[i], matrix2[i], color=colors[i], label=names[i])
  if key1:
    ax.plot(domain[len(names)-1], matrix1[len(names)-1], matrix2[len(names)-1], color=&#39;black&#39;, label=names[len(names)-1])
  else:
    ax.plot(domain[len(names)-1], matrix1[len(names)-1], matrix2[len(names)-1], color=colors[len(names)-1], label=names[len(names)-1])
  if key2:
    plt.yscale(&#39;log&#39;)
  ax.legend()
  ax.set_xlabel(labelx)
  ax.set_ylabel(labely)
  ax.set_zlabel(labelz)
  ax.set_title(title)
  return fig, ax

def errors_2x(n0, k, method, t0, tf, x0, A, g, sol, vectorize_sol, error):
  &#39;&#39;&#39;
  This function will RETURN a np.array with the errors of the approximations given
  by the method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k-1)*n0.

  RECEIVES:
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  method have arguments (t0, tf, n, x0, lmba, g) and return a
  np.vector of length n (0, 1, 2, ..., n-1), n is the number of steps. (function)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  x0 is the initial value of the Cauchy problem. (float)
  A is the coefficient of the linear part of the ploblem. (np.matrix)
  g is a function (float, float) -&gt; (float). (function)
  sol is a function (float) -&gt; (float). (function)
  vectorize_sol is a function that &quot;transforms sol in a vector&quot; (function)
  (float, float, int, function) -&gt; (np.array)
  (t0, tf, n, sol) -&gt; np.array([sol[t0], sol[t0+h], sol[t0+2h], ..., sol[tf-1]])
  error is a function (np.array, np.array) -&gt; (float) (function)
  &#39;&#39;&#39;
  v = np.zeros(k)
  domain = np.zeros(k)
  for i in range(k):
    domain[i] = n0*2**i
    m = method(t0, tf, n0*2**i, x0, A, g)
    exact = vectorize_sol(t0, tf, n0*2**i, sol)
    v[i] = error(m, exact)
  return v, domain

def convergence_table(errors_2x, n0, k, t0, tf):
  &#39;&#39;&#39;
  RECEIVES:
  errors_2x is a array with the errors of the approximations given
  by a method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k-1)*n0. (np.array)
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  &#39;&#39;&#39;
  n = n0
  print(n, (tf-t0)/n, errors_2x[0], &quot;-&quot;, sep=&quot; &amp; &quot;, end=&quot; \\\\ \n&quot;)
  for i in range(1, k):
      n = n0 * 2 ** i
      h = (tf-t0)/n
      q = errors_2x[i-1]/errors_2x[i] #q=erro(h)/erro(h)
      r = ((tf-t0)/(n/2))/((tf-t0)/n)
      print(n, h, errors_2x[i], log(q,2)/log(r,2), sep=&quot; &amp; &quot;, end=&quot; \\\\ \n&quot;)

def convergence_table(errors_2x, n0, k, t0, tf):
  &#39;&#39;&#39;
  RECEIVES:
  errors_2x is a array with the errors of the approximations given
  by a method with number of steps n = n0, 2*n0, 2**2*n0, ..., 2**(k-1)*n0. (np.array)
  n0 is the first number of steps. (int)
  k is the number of errors in the final array. (int)
  t0 is the initial point of the approximation. (float)
  tf is the last one. (float)
  &#39;&#39;&#39;
  n = n0
  print(&quot;| n | h = $\\frac{1}{h}$ | $\\tau(0,h)$ | q = $\\frac{tau(0,h)}{tau(0, 2h)}$ |&quot;)
  print(&quot;|---|-----------------|-----------|---------------------------------|&quot;)
  print(&quot;&quot;, n, (tf-t0)/n, errors_2x[0], &quot;-&quot;, sep=&quot; | &quot;, end=&quot; | \n&quot;)
  for i in range(1, k):
      n = n0 * 2 ** i
      h = (tf-t0)/n
      q = errors_2x[i-1]/errors_2x[i] #q=erro(h)/erro(h)
      r = ((tf-t0)/(n/2))/((tf-t0)/n)
      print( &quot;&quot;, n, h, errors_2x[i], log(q,2)/log(r,2), sep=&quot; | &quot;, end=&quot; | \n&quot;)

def lmba_n_error(errors_for_lambdas_array, method, x0, Af, g, sol_given_lmba, vectorize_sol_given_lmba, error, method_name):
  lmba0 = 5
  lmbaf = 100
  n0 = 10
  nf = 128
  t0 = 0.0
  tf = 1.0
  # Create data for X, Y
  lmba_values = np.arange(lmba0, lmbaf)
  n_values = np.arange(n0, nf)
  X, Y = np.meshgrid(lmba_values, 1/n_values)
  # Create a matrix of zeros for Z
  Z = np.zeros_like(X)
  # Populate the Z matrix with data using a function
  for n in range(n0, nf):
    Z[n-n0], domain = errors_for_lambdas_array(n, method, t0, tf, x0, lmba0, lmbaf, Af, g, sol_given_lmba, vectorize_sol_given_lmba, error)
  # Create filled contour plot
  plt.contourf(X, Y, Z)
  # Add color bar for the contour plot
  plt.colorbar()
  # Add labels and title (optional)
  plt.xlabel(&#39;lambda&#39;)
  plt.ylabel(&#39;h&#39;)
  plt.title(&#39;errors for the &#39;+method_name+&#39; method &#39;)
  # Show the plot
  plt.show()
</pre></div>
</div>
</div>
</div>
</section>
<section id="convergence-tables">
<h2>Convergence tables<a class="headerlink" href="#convergence-tables" title="Permalink to this headline">#</a></h2>
<section id="classic-euler">
<h3>Classic Euler<a class="headerlink" href="#classic-euler" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])
errors_2x_vector, domain = errors_2x(n0, k, classic_euler, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 0.2391072699739873 | - | 
 | 256 | 0.00390625 | 0.08650412059872986 | 1.466817233501749 | 
 | 512 | 0.001953125 | 0.039214210532948934 | 1.1413923006132296 | 
 | 1024 | 0.0009765625 | 0.018739566082401515 | 1.0652890085799935 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="exponential-euler">
<h3>Exponential Euler<a class="headerlink" href="#exponential-euler" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])
errors_2x_vector, domain = errors_2x(n0, k, exponential_euler, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 4.398075514689716e-05 | - | 
 | 256 | 0.00390625 | 2.074422525626487e-05 | 1.0841625981445133 | 
 | 512 | 0.001953125 | 1.0056221183126109e-05 | 1.0446214904461004 | 
 | 1024 | 0.0009765625 | 4.948885884282876e-06 | 1.0229126060177947 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="rk2">
<h3>rk2<a class="headerlink" href="#rk2" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, rk2, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 0.06606851127601271 | - | 
 | 256 | 0.00390625 | 0.01256096444797522 | 2.395015596211044 | 
 | 512 | 0.001953125 | 0.0027104154026279526 | 2.212361357172686 | 
 | 1024 | 0.0009765625 | 0.0006264383048139033 | 2.1132696413977325 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="etd2rk-trapezoidal">
<h3>etd2rk (trapezoidal)<a class="headerlink" href="#etd2rk-trapezoidal" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, etd2rk, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 4.186569175362864e-08 | - | 
 | 256 | 0.00390625 | 1.0575183428604418e-08 | 1.985085775819591 | 
 | 512 | 0.001953125 | 2.652380943352073e-09 | 1.9953227875115886 | 
 | 1024 | 0.0009765625 | 6.638462730912398e-10 | 1.9983668943519293 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="naive-version-of-etd2rk-trapezoidal">
<h3>Naive version of etd2rk (trapezoidal)<a class="headerlink" href="#naive-version-of-etd2rk-trapezoidal" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, etd2rk_trapezoidal_naive, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 0.0004242643044311458 | - | 
 | 256 | 0.00390625 | 0.00010714498082271644 | 1.9853990333325726 | 
 | 512 | 0.001953125 | 2.6871031228085582e-05 | 1.9954406751889993 | 
 | 1024 | 0.0009765625 | 6.725136514989377e-06 | 1.9984162299862431 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="rk4">
<h3>rk4<a class="headerlink" href="#rk4" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, rk4, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 0.002141816843239275 | - | 
 | 256 | 0.00390625 | 9.770249694801558e-05 | 4.4542958704375835 | 
 | 512 | 0.001953125 | 5.250705130854794e-06 | 4.21781234893684 | 
 | 1024 | 0.0009765625 | 3.024340525237257e-07 | 4.1178186851779905 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="deduced-like-etd3rk">
<h3>Deduced like etd3rk<a class="headerlink" href="#deduced-like-etd3rk" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, etd3rk_similar, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 5.0853024048669315e-12 | - | 
 | 256 | 0.00390625 | 3.212833644961055e-13 | 3.9844153810116354 | 
 | 512 | 0.001953125 | 2.0132983821752326e-14 | 3.996213373698299 | 
 | 1024 | 0.0009765625 | 1.2602766052971504e-15 | 3.997748687591092 | 
</pre></div>
</div>
</div>
</div>
</section>
<section id="naive-version-of-etd3rk">
<h3>Naive version of etd3rk<a class="headerlink" href="#naive-version-of-etd3rk" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 128
k = 4
t0 = 0
tf = 1
x0 = np.array([1])
A = np.array([[100]])

errors_2x_vector, domain = errors_2x(n0, k, etd3rk_naive, t0, tf, x0, A, g, sol, vectorize_sol, error_sup)
convergence_table(errors_2x_vector, n0, k, t0, tf)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>| n | h = $\frac{1}{h}$ | $\tau(0,h)$ | q = $\frac{tau(0,h)}{tau(0, 2h)}$ |
|---|-----------------|-----------|---------------------------------|
 | 128 | 0.0078125 | 1.083876968009309e-06 | - | 
 | 256 | 0.00390625 | 6.883813637344194e-08 | 3.9768491535433466 | 
 | 512 | 0.001953125 | 4.322307012305515e-09 | 3.9933345852265947 | 
 | 1024 | 0.0009765625 | 2.705360744453822e-10 | 3.9979086629155343 | 
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="some-graphics">
<h2>Some graphics<a class="headerlink" href="#some-graphics" title="Permalink to this headline">#</a></h2>
<p>The following notation is used</p>
<p>\begin{cases}
u(t) + A u(t) = g(u(t), t)\
u(0) = u_0.
\end{cases}</p>
<p>A Stiff problem shown in [1] is</p>
<p>\begin{cases}
u(t) + 100 u(t) = \sin(t)\
u(0) = u_0,
\end{cases}</p>
<p>with solution</p>
<div class="math notranslate nohighlight">
\[
u(t) = u_0 \exp(-100t)+\frac{\exp(-100t)+100\sin(t)-\cos(t)}{1+100^2}.
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n = 128
lmba0 = 1
lmbaf = 100
t0 = 0.0
tf = 1.0
x0 = np.array([1])
lmba_1D_classic, domain = errors_for_lambdas_array(n, classic_euler, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_exponential, domain = errors_for_lambdas_array(n, exponential_euler, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_etd2rk, domain = errors_for_lambdas_array(n, etd2rk, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_etd2rk_trapezoidal_naive, domain = errors_for_lambdas_array(n, etd2rk_trapezoidal_naive, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_etd3rk_similar, domain = errors_for_lambdas_array(n, etd3rk_similar, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_etd3rk_naive, domain = errors_for_lambdas_array(n, etd3rk_naive, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_rk2, domain = errors_for_lambdas_array(n, rk2, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
lmba_1D_rk4, domain = errors_for_lambdas_array(n, rk4, t0, tf, x0, lmba0, lmbaf, A_1D, g, sol_given_lmba, vectorize_sol_given_lmba, error_2)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_10101/3543048019.py:247: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.sqrt(float(np.sum(v)/x_approx.size)) #normalized
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>matrix_1D = [lmba_1D_classic, lmba_1D_exponential, lmba_1D_rk2, lmba_1D_etd2rk_trapezoidal_naive, lmba_1D_etd2rk, lmba_1D_rk4, lmba_1D_etd3rk_naive, lmba_1D_etd3rk_similar]
names = [&#39;classic euler&#39;, &#39;exponential euler&#39;, &#39;rk2&#39;, &#39;etd2rk naive&#39;, &#39;etd2rk&#39;, &#39;rk4&#39;, &#39;etd3rk naive&#39;, &quot;etd3rk (similar)&quot;]
fig, ax = graphic_2D(8*[domain], matrix_1D, names, &quot;lambda&quot;, &quot;error&quot;, &quot;1D problem from [1]&quot;, False, True)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/appendix_24_0.png" src="_images/appendix_24_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>n0 = 10
k = 10
lmba = 100
A = lmba * np.array([[1]])
t0 = 0.0
tf = 1.0
x0 = np.array([1])
n_1D_classic, domain = errors_2x(n0, k, classic_euler, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_exponential, domain = errors_2x(n0, k, exponential_euler, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_etd2rk, domain = errors_2x(n0, k, etd2rk, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_etd2rk_trapezoidal_naive, domain = errors_2x(n0, k, etd2rk_trapezoidal_naive, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_etd3rk_similar, domain = errors_2x(n0, k, etd3rk_similar, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_etd3rk_naive, domain = errors_2x(n0, k, etd3rk_naive, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_rk2, domain = errors_2x(n0, k, rk2, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
n_1D_rk4, domain = errors_2x(n0, k, rk4, t0, tf, x0, A, g, sol, vectorize_sol, error_2)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/tmp/ipykernel_10101/3543048019.py:247: ComplexWarning: Casting complex values to real discards the imaginary part
  return np.sqrt(float(np.sum(v)/x_approx.size)) #normalized
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span>matrix_2D = [n_1D_classic, n_1D_exponential, n_1D_rk2, n_1D_etd2rk_trapezoidal_naive, n_1D_etd2rk, n_1D_rk4, n_1D_etd3rk_naive, n_1D_etd3rk_similar]
names = [&#39;classic euler&#39;, &#39;exponential euler&#39;, &#39;rk2&#39;, &#39;etd2rk naive&#39;, &#39;etd2rk&#39;, &#39;rk4&#39;, &#39;etd3rk naive&#39;, &quot;etd3rk (similar)&quot;]
fig_2D, ax_2D = graphic_2D(8*[1/domain], matrix_2D, names, &quot;h&quot;, &quot;error&quot;, &quot;1D problem with lmba = &quot;+str(lmba), False, True)
plt.xscale(&#39;log&#39;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/appendix_26_0.png" src="_images/appendix_26_0.png" />
</div>
</div>
</section>
<section id="some-deductions">
<h2>Some deductions<a class="headerlink" href="#some-deductions" title="Permalink to this headline">#</a></h2>
<p>Here is used informations from [1], [6], [7].</p>
<section id="exponential-euler-method">
<h3>Exponential Euler method<a class="headerlink" href="#exponential-euler-method" title="Permalink to this headline">#</a></h3>
<p>For</p>
<p><span class="math notranslate nohighlight">\(\begin{cases}
    y'(t) + \lambda y(t) = g(y(t), t), t \in (t_0, T) \\
    y(0) = y_0
\end{cases}\)</span></p>
<p>the domain is evenly discretized:</p>
<div class="math notranslate nohighlight">
\[
    N \in \mathbb{N}; h = \frac{T-t_0}{N}; \text{Domain: }\{t_k = t_0 + k h : k = 0, 1, ...\}.
\]</div>
<p>The discretization of the ODE takes the exact solution of the Cauchy problem, given by the variation of constants formula</p>
<div class="math notranslate nohighlight">
\[
    y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t [e^{-\lambda(t-\tau)} g(y(\tau), \tau)] d\tau
\]</div>
<p>and, by Taylor expansion on <span class="math notranslate nohighlight">\(g\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\tau \in (t_k, t_{k+1})\)</span></p>
<div class="math notranslate nohighlight">
\[
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(\theta_k), \theta_k)
\]</div>
<p>for a <span class="math notranslate nohighlight">\(\theta_k \in (t_k, t_{k+1}),\)</span></p>
<div class="math notranslate nohighlight">
\[
    y(t_{k+1}) = e^{-(t_{k+1}-t_k) \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} [e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau)] d\tau
\]</div>
<div class="math notranslate nohighlight">
\[
    = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} \left[e^{-\lambda(t_{k+1}-\tau)} \left( g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(\theta_k), \theta_k)\right)\right] d\tau
\]</div>
<div class="math notranslate nohighlight">
\[
    = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d\tau + \frac{dg}{dt} (y(\theta_k), \theta_k) \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d\tau.
\]</div>
<p>Since</p>
<div class="math notranslate nohighlight">
\[
    \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d\tau = h\phi_1(-\lambda h)= \frac{1-e^{-h \lambda}}{\lambda}
\]</div>
<p>and, by the Taylor expansion of <span class="math notranslate nohighlight">\(e^{-\lambda h}\)</span> in the point zero</p>
<div class="math notranslate nohighlight">
\[
    e^{-\lambda h} = 1 - \lambda h + \frac{1}{2}\lambda^2h^2 - \frac{1}{3!}\lambda^3h^3 + \dotsi + \frac{1}{n!} (-\lambda h)^n + \dotsi, n \in \mathbb{N}
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
     \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d\tau =
     h^2 \phi_2 (-\lambda h) =
     h \frac{\phi_1(0) - \phi_1(-\lambda h)}{\lambda} =
     \frac{h}{\lambda} - \frac{1-e^{-h \lambda}}{\lambda^2} = \\
     \frac{h}{\lambda} - \frac{1-(1 - \lambda h + \frac{1}{2}\lambda^2h^2 - \frac{1}{3!}\lambda^3h^3 + \dotsi + \frac{1}{n!} (-\lambda h)^n + \dotsi)}{\lambda^2} = \\
     \frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^n}{n!} (-\lambda)^{n-2} + \dotsi  =  O(h^2),
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + \frac{dg}{dt} (y(\theta_k), \theta_k) O(h^2),
\]</div>
<div class="math notranslate nohighlight">
\[
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2).
\]</div>
<p>That inspires the <span class="math notranslate nohighlight">\(\textbf{Exponential Euler method}\)</span> :</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y_0 = y(t_0)\\
\textbf{for } k = 0, 1, 2, ..., N-1 :\\
    y_{k+1} = e^{-h \lambda}y_k + g(y_k, t_k) \frac{1-e^{-h \lambda}}{\lambda}\\
    t_{k+1} = t_k + h
\end{split}\]</div>
<p>with <span class="math notranslate nohighlight">\(y_k \thickapprox y(t_k)\)</span>.</p>
</section>
<section id="exponential-time-differencing-methods-etd">
<h3>Exponential time differencing methods (ETD)<a class="headerlink" href="#exponential-time-differencing-methods-etd" title="Permalink to this headline">#</a></h3>
<p>In the same conditions as above, it is taken a general Taylor expansion of <span class="math notranslate nohighlight">\(g\)</span>:</p>
<p><span class="math notranslate nohighlight">\(\tau \in (t_k, t_{k+1}), n \in \mathbb{N}\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + \frac{(\tau - t_k)^2}{2!} \frac{d^2g}{dt^2} (y(t_k), t_k) + \\
    \dotsi + \frac{(\tau - t_k)^{n-1}}{(n-1)!} \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k) + \frac{(\tau - t_k)^n}{n!} \frac{d^ng}{dt^n} (y(\theta_k), \theta_k)
\end{split}\]</div>
<p>for a <span class="math notranslate nohighlight">\(\theta_k \in (t_k, t_{k+1})\)</span></p>
<p>In</p>
<div class="math notranslate nohighlight">
\[
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau) d\tau
\]</div>
<p>It will now become</p>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)}  g(y(t_k), t_k) +
(\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) +
\]</div>
<div class="math notranslate nohighlight">
\[
 \frac{(\tau - t_k)^2}{2!} \frac{d^2g}{dt^2} (y(t_k), t_k) + \dotsi + 
\]</div>
<div class="math notranslate nohighlight">
\[
 + \frac{(\tau - t_k)^{n-1}}{(n-1)!} \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k) + \frac{(\tau - t_k)^n}{n!} \frac{d^ng}{dt^n} (y(\theta_k), \theta_k)  d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
\]</div>
<div class="math notranslate nohighlight">
\[
+ \frac{dg}{dt}(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} (\tau - t_k)d\tau + \frac{d^2g}{dt^2} (y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^2}{2!}d\tau +
\]</div>
<div class="math notranslate nohighlight">
\[
+ \dotsi +
\]</div>
<div class="math notranslate nohighlight">
\[
+ \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)\int_{t_k}^{t_{k+1}}  e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^{n-1}}{(n-1)!} d\tau + \frac{d^ng}{dt^n} (y(\theta_k), \theta_k) \int_{t_k}^{t_{k+1}}  e^{-\lambda(t_{k+1}-\tau)} \frac{(\tau - t_k)^n}{n!} d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
h\phi_1(-\lambda h) g(y(t_k), t_k) +
h^2\phi_2(-\lambda h) \frac{dg}{dt}(y(t_k), t_k) +
h^3\phi_3(-\lambda h)\frac{d^2g}{dt^2} (y(t_k), t_k)
\]</div>
<div class="math notranslate nohighlight">
\[
+ \dotsi +
\]</div>
<div class="math notranslate nohighlight">
\[
+ h^n\phi_n(-\lambda h) \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)+
h^{n+1}\phi_{n+1}(-\lambda h) \frac{d^ng}{dt^n} (y(\theta_k), \theta_k).
\]</div>
<p>From the discussion about the exponential Euler, that is known that</p>
<div class="math notranslate nohighlight">
\[
h^2\phi_2(-\lambda h) = \frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^l}{l!} (-\lambda)^{l-2} + \dotsi = \frac{1}{(-\lambda)^2} \sum\limits_{i=2}^{\infty} \frac{(-\lambda h)^i}{i!}.
\]</div>
<p>Since</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \phi_{n+1}(-\lambda h) = \frac{\phi_n(-\lambda h) - \phi_n(0)}{-\lambda h} \text{ and}\\
  \phi_n(0) = \frac{1}{n!},
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
  h^3 \phi_3(-\lambda h) = h^2 \frac{\phi_2(0) - \phi_2(-\lambda h)}{\lambda} = \frac{\frac{h^2}{2} - (\frac{h^2}{2} - \frac{h^3}{3!} \lambda + \dotsi + \frac{h^l}{l!} (-\lambda)^{l-2} + O(h^{l+1}))}{\lambda} = \frac{1}{(-\lambda)^3} \sum\limits_{i=3}^{\infty} \frac{(-\lambda h)^i}{i!}.
\]</div>
<p>And if</p>
<div class="math notranslate nohighlight">
\[
h^l \phi_l(-\lambda h) = \frac{1}{(-\lambda)^l} \sum\limits_{i=l}^{\infty} \frac{(-\lambda h)^i}{i!}, \text{for a } l \in \mathbb{N},
\]</div>
<div class="math notranslate nohighlight">
\[
  h^{l+1}\phi_{l+1}(-\lambda h) = h^{l+1} \frac{\phi_l(-\lambda h) - \phi_l(0)}{-\lambda h} = \frac{h^l \phi_l(0) - h^l \phi_l(-\lambda h)}{\lambda} = \frac{h^l}{l! \lambda} - \frac{1}{\lambda} \frac{1}{(-\lambda)^l} \sum\limits_{i=l}^{\infty} \frac{(-\lambda h)^i}{i!} = \frac{1}{(-\lambda)^{l+1}} \sum\limits_{i=l+1}^{\infty} \frac{(-\lambda h)^i}{i!}.
\]</div>
<p>So, by induction,</p>
<div class="math notranslate nohighlight">
\[
h^n \phi_n(-\lambda h) = \frac{1}{(-\lambda)^n} \sum\limits_{i=n}^{\infty} \frac{(-\lambda h)^i}{i!} = O(h^n), \forall n \geq 2.
\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) +
h\phi_1(-\lambda h) g(y(t_k), t_k) +
h^2\phi_2(-\lambda h) \frac{dg}{dt}(y(t_k), t_k) +
h^3\phi_3(-\lambda h)\frac{d^2g}{dt^2} (y(t_k), t_k) +
\dotsi + \\
h^n\phi_n(-\lambda h) \frac{d^{n-1}g}{dt^{n-1}} (y(t_k), t_k)+
O(h^{n+1}).
\end{split}\]</div>
</section>
<section id="exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-trapezoidal-rule">
<h3>Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Trapezoidal rule<a class="headerlink" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-trapezoidal-rule" title="Permalink to this headline">#</a></h3>
<p>For the second order method, that is used the approximation</p>
<div class="math notranslate nohighlight">
\[
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + O(h^2),
\]</div>
<p><span class="math notranslate nohighlight">\(\forall \tau \in (t_k, t_{k+1}).\)</span></p>
<p>The first derivative is discretized with the Taylor expansion</p>
<div class="math notranslate nohighlight">
\[
g(y(t_{k+1}), t_{k+1}) = g(y(t_k), t_k) + h \frac{dg}{dt} (y(t_k), t_k) + O(h^2)
\]</div>
<p>and the exponential Euler expression</p>
<div class="math notranslate nohighlight">
\[
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2),
\]</div>
<p>so that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{dg}{dt} (y(t_k), t_k)  = \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} + O(h), \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda},
\end{split}\]</div>
<p>which results in the expression</p>
<div class="math notranslate nohighlight">
\[\begin{split}
g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}\]</div>
<p>Putting in the variation of constants formula</p>
<div class="math notranslate nohighlight">
\[
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
  + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g(y(t_k), t_k) + (\tau - t_k)  \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h}  + (\tau - t_k)O(h) \right] d\tau
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) + g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau + \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau + \\
+ O(h)\int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau \\
\text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \frac{g(a_k, t_{k+1}) - g(y(t_k), t_k)}{h} h^2 \phi_2 (-\lambda h) + \\
  + O(h)h^2 \phi_2 (-\lambda h) \\
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h) + \\
  + O(h^3) \\
  \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\end{split}\]</div>
<p>Butcher tableau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}
{c|cc}
0\\
1 &amp; \phi_1(-\lambda h)\\
\hline
&amp; \phi_1 (-\lambda h) - \phi_2 (-\lambda h) &amp; \phi_2 (-\lambda h)
\end{array}
\end{split}\]</div>
</section>
<section id="exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-midpoint-rule">
<h3>Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Cox and Matthews - Midpoint rule<a class="headerlink" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-cox-and-matthews-midpoint-rule" title="Permalink to this headline">#</a></h3>
<p>From the same expression:</p>
<div class="math notranslate nohighlight">
\[
    g(y(\tau), \tau) = g(y(t_k), t_k) + (\tau - t_k) \frac{dg}{dt} (y(t_k), t_k) + O(h^2),
\]</div>
<p><span class="math notranslate nohighlight">\(\forall \tau \in (t_k, t_{k+1}).\)</span></p>
<p>The first derivative is now discretized with the Taylor expansion</p>
<div class="math notranslate nohighlight">
\[
g\left(y\left(t_k + \frac{h}{2}\right), t_k + \frac{h}{2} \right) = g(y(t_k), t_k) + \frac{h}{2} \frac{dg}{dt} (y(t_k), t_k) + O(h^2)
\]</div>
<p>and the exponential Euler expression taken is with time step <span class="math notranslate nohighlight">\(\frac{h}{2}\)</span></p>
<div class="math notranslate nohighlight">
\[
  y\left(t_k + \frac{h}{2}\right) = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right) + O(h^2),
\]</div>
<p>so that</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\frac{dg}{dt} (y(t_k), t_k)  = 2 \frac{g\left(b_k, t_k + \frac{h}{2} \right) - g(y(t_k), t_k)}{h} + O(h), \\
\text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}\]</div>
<p>which results in the expression</p>
<div class="math notranslate nohighlight">
\[\begin{split}
g(y(\tau), \tau) = g(y(t_k), t_k) + 2(\tau - t_k) \frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \\
\text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}\]</div>
<p>Putting in the variation of constants formula</p>
<div class="math notranslate nohighlight">
\[
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
    + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g(y(t_k), t_k) + 2(\tau - t_k) \frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} + (\tau - t_k)O(h) \right] d\tau
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) + g(y(t_k), t_k)\int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau + \\
  + 2\frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} \int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau + O(h)\int_{t_k}^{t_{k+1}} (\tau - t_k) e^{-\lambda(t_{k+1}-\tau)} d \tau \\
  \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  2\frac{g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k)}{h} h^2 \phi_2 (-\lambda h) + \\
  + O(h)h^2 \phi_2 (-\lambda h) \\
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  2 \left[g\left(b_k, t_k + \frac{h}{2}\right) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h) + \\
  + O(h^3) \\
  \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right).
\end{split}\]</div>
<p>Butcher tableau:</p>
<p>\begin{array}
{c|cc}
0\
\frac{1}{2} &amp; \frac{1}{2}\phi_1\left(-\frac{\lambda h}{2}\right)\
\hline
&amp; \phi_1 (-\lambda h) - 2 \phi_2 (-\lambda h) &amp; -2 \phi_2 (-\lambda h)
\end{array}</p>
</section>
<section id="exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-trapezoidal-rule">
<h3>Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Trapezoidal rule<a class="headerlink" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-trapezoidal-rule" title="Permalink to this headline">#</a></h3>
<p>It is also possible to think the exponential time differencing methods with Runge-Kutta time stepping using the numerical integration, for example, for the one with second order, it starts with the trapezoidal rule (which was taken from [2]) on the variation of constants formula:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda(t_{k+1}-t_k)} g(y(t_k), t_k) + e^{-\lambda(t_{k+1}-t_{k+1})} g(y(t_{k+1}), t_{k+1}) \right] + O(h^3), \\
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(y(t_{k+1}), t_{k+1}) \right] +  O(h^3).
\end{split}\]</div>
<p>And then, from the expression seen before:</p>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h \lambda}}{\lambda} + O(h^2),
\]</div>
<div class="math notranslate nohighlight">
\[
    g(y(t_{k+1}), t_{k+1}) = g(a_k, t_{k+1}) + O(h^2) \text{, with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) \frac{1-e^{-h\lambda}}{\lambda}.
\]</div>
<p>So,</p>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) + O(h^2) \right] +  O(h^3),
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right] +  O(h^3) \\
    \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}\]</div>
<p>Butcher tableau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}
{c|cc}
0\\
1 &amp; \phi_1(-\lambda h)\\
\hline
&amp; \frac{1}{2} e^{-h \lambda} &amp; \frac{1}{2}
\end{array}
\end{split}\]</div>
</section>
<section id="exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-midpoint-rule">
<h3>Exponential time differencing methods with Runge-Kutta time stepping - order 2 - Classical approach - Midpoint rule<a class="headerlink" href="#exponential-time-differencing-methods-with-runge-kutta-time-stepping-order-2-classical-approach-midpoint-rule" title="Permalink to this headline">#</a></h3>
<p>Besides that, using the midpoint rule, also known as rectangle rule, again taken from [2],</p>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-(t_{k+1}-t_k) \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} [e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau)] d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{-\lambda\left(t_{k+1}-\frac{t_{k+1}+t_k}{2}\right)} g\left(y\left(\frac{t_{k+1}+t_k}{2}\right), \frac{t_{k+1}+t_k}{2}\right) + O(h^3),
\]</div>
<div class="math notranslate nohighlight">
\[
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(y\left(t_k + \frac{h}{2}\right), t_k+\frac{h}{2}\right) + O(h^3),
\]</div>
<p>and Exponential Euler with time step <span class="math notranslate nohighlight">\(\frac{h}{2}\)</span></p>
<div class="math notranslate nohighlight">
\[
y\left(t_k + \frac{h}{2}\right) = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right) + O(h^2),
\]</div>
<p>results in</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(b_k + O(h^2), t_k + \frac{h}{2}\right) + O(h^3) \\
    \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
y(t_{k+1}) = e^{-h\lambda}y(t_k) + h e^{- \frac{h\lambda}{2}} g\left(b_k , t_k + \frac{h}{2}\right) + O(h^3) \\
    \text{with } b_k =e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left( -\frac{\lambda h}{2} \right),
\end{split}\]</div>
<p>Butcher tableau:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{array}
{c|cc}
0\\
\frac{1}{2} &amp;  \frac{1}{2} \phi_1( -\frac{\lambda h}{2})\\
\hline
&amp; 0 &amp; e^{-\frac{h \lambda}{2}}
\end{array}
\end{split}\]</div>
</section>
<section id="third-order-exponential-time-differencing-methods-with-runge-kutta-time-stepping-etdrk-3">
<h3>Third order exponential time differencing methods with Runge-Kutta time stepping (ETDRK-3)<a class="headerlink" href="#third-order-exponential-time-differencing-methods-with-runge-kutta-time-stepping-etdrk-3" title="Permalink to this headline">#</a></h3>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(\tau), \tau) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O((\tau - t_k)^4),
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\forall \tau \in \mathbb{R}.\)</span></p>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(t_{k+1}), t_{k+1}) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(t_{k+1} - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_{k+1} - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_{k+1} - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(t_{k+1}), t_{k+1}) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \frac{h}{2} \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    +\frac{h^2}{8} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + \frac{h^3}{48} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(t_k), t_k) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(t_k - t_{k+\frac{1}{2}}\right) \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_k - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{\left(t_k - t_{k+\frac{1}{2}}\right)^3}{3!} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4),
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(t_k), t_k) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) -
    \frac{h}{2} \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + \\
    + \frac{h^2}{8} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    - \frac{h^3}{48} \frac{d^3g}{dt^3} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
    + O(h^4).
\end{split}\]</div>
<p>Subtracting the two expressions,</p>
<div class="math notranslate nohighlight">
\[
  g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k) = h \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + O(h^3).
\]</div>
<p>So,</p>
<div class="math notranslate nohighlight">
\[
  \frac{dg}{dt} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) = \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + O(h^2).
\]</div>
<p>And summing them</p>
<div class="math notranslate nohighlight">
\[
  g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) =
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  + \frac{h^2}{4} \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) + O(h^4).
\]</div>
<p>So,</p>
<div class="math notranslate nohighlight">
\[
  \frac{d^2g}{dt^2} \left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) =
  4\frac{ g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)}{h^2}
  + O(h^2).
\]</div>
<p>This results in the expression</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    g(y(\tau), \tau) = g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right)  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2} + \\
    + O((\tau - t_k)^3),
\end{split}\]</div>
<p><span class="math notranslate nohighlight">\(\forall \tau \in \mathbb{R}.\)</span></p>
<p>Putting in the variation of constants formula</p>
<div class="math notranslate nohighlight">
\[
y(t) = e^{-(t-t_0) \lambda}y_0 + \int_{t_0}^t e^{-\lambda(t-\tau)} g(y(\tau), \tau) d\tau,
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \\
  + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} \left[ g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) +
    \left(\tau - t_{k+\frac{1}{2}}\right)  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h} + \\
    + \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) -
  2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2} + O((\tau - t_k)^3) \right] d\tau,
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \left(\tau - t_{k+\frac{1}{2}}\right) e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{\left(\tau - t_{k+\frac{1}{2}}\right)^2}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau
  + \int_{t_k}^{t_{k+1}} O((\tau - t_k)^3) e^{-\lambda(t_{k+1}-\tau)} d \tau,
\end{split}\]</div>
<p>Since <span class="math notranslate nohighlight">\(\tau - t_{k+ \frac{1}{2}} = \tau - t_k - \frac{h}{2}\)</span> and <span class="math notranslate nohighlight">\(\left(\tau - t_{k+ \frac{1}{2}} \right)^2 = (\tau - t_k)^2 + \frac{h^2}{4} - h (\tau - t_k)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \left(\tau - t_{k}\right) e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{(\tau - t_k)^2}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  - \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \int_{t_k}^{t_{k+1}} \frac{h}{2} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{h^2}{4 \cdot 2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  - \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \int_{t_k}^{t_{k+1}} \frac{h (\tau - t_k)}{2!} e^{-\lambda(t_{k+1}-\tau)} d \tau +
  \\
  + \int_{t_k}^{t_{k+1}} O((\tau - t_k)^3) e^{-\lambda(t_{k+1}-\tau)} d \tau.
\end{split}\]</div>
<p>Then,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) +
  \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  h^2 \phi_2 (-h \lambda) +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  h^3 \phi_3 (-h \lambda) +
  \\
  - \frac{g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)}{h}
  \frac{h^2 \phi_1(-h \lambda)}{2} +
  \\
  + \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \frac{h^3 \phi_1(-h \lambda)}{8} +
  \\
  - \frac{ 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]}{h^2}
  \frac{h^3 \phi_2(-h \lambda)}{2} +
  \\
  + O(h^4 \phi_4(-h \lambda)).
\end{split}\]</div>
<p>i.e.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) + %ok
  \left[g(y(t_{k+1}), t_{k+1}) - g(y(t_k), t_k)\right]
  \left( h \phi_2 (-h \lambda) - \frac{h \phi_1(-h \lambda)}{2} \right) +
  \\
  + 4 \left[g(y(t_{k+1}), t_{k+1}) + g(y(t_k), t_k) - 2 g\left(y\left(t_{k+\frac{1}{2}}\right), t_{k+\frac{1}{2}}\right) \right]
  \left( h \phi_3 (-h \lambda) + \frac{h \phi_1(-h \lambda)}{8} - \frac{h \phi_2(-h \lambda)}{2} \right) + O(h^4).
\end{split}\]</div>
<p>Using the Cox and Mathhewss ETDRK-2 expressions to approximate <span class="math notranslate nohighlight">\(y\left(t_{k+\frac{1}{2}}\right)\)</span> and <span class="math notranslate nohighlight">\(y(t_{k+1})\)</span>, since those are of order 2, i.e., <span class="math notranslate nohighlight">\(O(h^3)\)</span>, the expression of the method is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda} y(t_k) +
  g\left(c'_k, t_{k+\frac{1}{2}}\right)
  h \phi_1(-h \lambda) + %ok
  \left[g(c_k, t_{k+1}) - g(y(t_k), t_k)\right]
  \left( h \phi_2 (-h \lambda) - \frac{h \phi_1(-h \lambda)}{2} \right) +
  \\
  + 4 \left[g(c_k, t_{k+1}) + g(y(t_k), t_k) - 2 g\left(c'_k, t_{k+\frac{1}{2}}\right) \right]
  \left( h \phi_3 (-h \lambda) + \frac{h \phi_1(-h \lambda)}{8} - \frac{h \phi_2(-h \lambda)}{2} \right) + O(h^4),
\end{split}\]</div>
<p>with</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  c_k = e^{-h \lambda} y(t_k) +
  h \phi_1 (-\lambda h) g(y(t_k), t_k) +
  \left[g(a_k, t_{k+1}) - g(y(t_k), t_k) \right] h \phi_2 (-\lambda h),
  \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1(-h\lambda),
  \\
  c'_k = e^{- \frac{h \lambda}{2}} y(t_k) +
  \frac{h}{2} \phi_1 \left(- \frac{\lambda h}{2} \right) g(y(t_k), t_k) +
  \left[g\left(a'_k, t_{k+\frac{1}{2}}\right) - g(y(t_k), t_k) \right] \frac{h}{2} \phi_2 \left(-\frac{\lambda h}{2}\right),
  \\
  a'_k = e^{-\frac{h \lambda}{2}}y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1\left(-\frac{h \lambda}{2}\right).
\end{split}\]</div>
<p>Here de deducing isnt exactly in Runge Kutta form, differing on the approximations for steps in minor order, so it cannot be a Butcher tableau, but doing language abuse only on the part that would form the triangle, it would be:</p>
<p>\begin{array}
{c|cccc}
0 \
\frac{1}{2} &amp; \frac{1}{2} \left( \phi_1\left(- \frac{\lambda h}{2} \right) - \phi_2\left(- \frac{\lambda h}{2} \right) \right) &amp; \frac{1}{2}\phi_2\left(- \frac{\lambda h}{2} \right) \
1 &amp; \phi_1\left(- \lambda h \right) - \phi_2\left(- \lambda h \right) &amp; 0 &amp; \phi_2\left(- \lambda h \right)  \
\hline
&amp; 4 \phi_3(-h \lambda)-3\phi_2(-h\lambda)+\phi_1(-h\lambda) &amp; -8\phi_3(-h\lambda)+4\phi_2(-h\lambda) &amp; 4 \phi_3(-h\lambda)-\phi_2(-h\lambda) \text{   }.
\end{array}</p>
</section>
<section id="naive-etd3rk">
<h3>Naive etd3rk<a class="headerlink" href="#naive-etd3rk" title="Permalink to this headline">#</a></h3>
<p>Here, that is taken the variation of constants formula:</p>
<div class="math notranslate nohighlight">
\[
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \int_{t_k}^{t_{k+1}} e^{-\lambda(t_{k+1}-\tau)} g(y(\tau), \tau) d\tau,
\]</div>
<p>and applied the Simpsons rule (here was used the order of convergence from Burden) so that it will be:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda(t_{k+1}-t_k)} g(y(t_k), t_k) + 4 e^{-\lambda \left(t_{k+1}-t_{k + \frac{1}{2}} \right)} g\left(y\left(t_{k+\frac{1}{2}}\right), t_k + \frac{h}{2} \right) \\ + e^{-\lambda(t_{k+1}-t_{k+1})} g(y(t_{k+1}), t_{k+1}) \right] + O(h^5), \\
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda h} g(y(t_k), t_k) + 4 e^{-\frac{ \lambda h}{2}} g\left(y\left(t_k + \frac{h}{2} \right), t_k + \frac{h}{2} \right) + g(y(t_{k+1}), t_{k+1}) \right] +  O(h^5).
\end{split}\]</div>
<p>To approximate <span class="math notranslate nohighlight">\(y\left(t_k + \frac{h}{2} \right)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    y\left(t_k + \frac{h}{2} \right) = e^{- \frac{h \lambda}{2}}y(t_k) + \frac{h}{4} \left[ e^{- \frac{h \lambda}{2}} g(y(t_k), t_k) + g \left(a'_{k}, t_k + \frac{h}{2} \right) \right] +  O(h^3), \\
    \text{with } a'_{k} = e^{- \frac{h \lambda}{2}} y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1 \left(-\lambda \frac{h}{2} \right),
\end{split}\]</div>
<p>and, for <span class="math notranslate nohighlight">\(y\left(t_{k+1} \right)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right] +  O(h^3), \\
    \text{with } a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}\]</div>
<p>So, the expression is</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  y(t_{k+1}) = e^{-h \lambda}y(t_k) + \frac{h}{6} \left[ e^{-\lambda h} g(y(t_k), t_k) + 4 e^{-\frac{ \lambda h}{2}} g\left( b'_{k}, t_k + \frac{h}{2} \right) + g(b_k, t_{k+1}) \right] +  O(h^4), \\
  \text{with } b'_{k} = e^{- \frac{h \lambda}{2}}y(t_k) + \frac{h}{4} \left[ e^{- \frac{h \lambda}{2}} g(y(t_k), t_k) + g \left(a'_{k}, t_k + \frac{h}{2} \right) \right], \\
  b_k = e^{-h \lambda}y(t_k) + \frac{h}{2} \left[ e^{-\lambda h} g(y(t_k), t_k) + g(a_k, t_{k+1}) \right], \\
  a'_{k} = e^{- \frac{h \lambda}{2}} y(t_k) + g(y(t_k), t_k) \frac{h}{2} \phi_1 \left(-\lambda \frac{h}{2} \right), \\
  a_k = e^{-h \lambda}y(t_k) + g(y(t_k), t_k) h \phi_1 (-\lambda h).
\end{split}\]</div>
</section>
</section>
<section id="matrix-exponential">
<h2>Matrix exponential<a class="headerlink" href="#matrix-exponential" title="Permalink to this headline">#</a></h2>
<p>This part has information from [4].</p>
<p>Based on the Maclaurin series of the exponential function</p>
<div class="math notranslate nohighlight">
\[
    e^x = \sum_{i=0}^{\infty} \frac{x^i}{i!},
\]</div>
<p>the <span class="math notranslate nohighlight">\(\textbf{exponential of a square complex matrix }A\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!}.
\]</div>
<p>This is well defined because it has been proven that the sequence <span class="math notranslate nohighlight">\({p_k}\)</span> with, <span class="math notranslate nohighlight">\(\forall k \in \mathbb{N}\)</span>:</p>
<div class="math notranslate nohighlight">
\[
    p_k = \sum_{i=0}^{k} \frac{A^i}{i!}, \forall A \text{ as decribed above,}
\]</div>
<p>is a Cauchy sequence, and therefore converge to a limit matrix which was denoted <span class="math notranslate nohighlight">\(e^A\)</span>, since the set of the square complex matrix with fixed lenght with the norm</p>
<div class="math notranslate nohighlight">
\[
||A|| = \max_{||x||=1} ||Ax||
\]</div>
<p>is a Banach space.</p>
<section id="exponential-of-a-zeros-matrix">
<h3>Exponential of a zeros matrix<a class="headerlink" href="#exponential-of-a-zeros-matrix" title="Permalink to this headline">#</a></h3>
<p>If <span class="math notranslate nohighlight">\(A =   
\left[ {\begin{array}{ccccc}
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
\end{array} } \right] \)</span>,</p>
<div class="math notranslate nohighlight">
\[
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = I + A + \frac{A^2}{2} + \dotsm = I + 0 + 0 + \dotsm = I.
\]</div>
</section>
<section id="exponential-of-a-diagonal-matrix">
<h3>Exponential of a diagonal matrix<a class="headerlink" href="#exponential-of-a-diagonal-matrix" title="Permalink to this headline">#</a></h3>
<p>If <span class="math notranslate nohighlight">\(A =   
\left[ {\begin{array}{ccccc}
    \lambda_1 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_2 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_3 &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_{N}\\
\end{array} } \right] 
  = diag(\lambda_1, \lambda_2, \lambda_3, \dotsm, \lambda_N)\)</span>,</p>
<p>it is easy to note that</p>
<div class="math notranslate nohighlight">
\[
    A^2 = diag \left(\lambda_1^2, \lambda_2^2, \lambda_3^2, \dotsc, \lambda_N^2 \right)
\]</div>
<div class="math notranslate nohighlight">
\[
    A^3 = diag \left(\lambda_1^3, \lambda_2^3, \lambda_3^3, \dotsc, \lambda_N^3 \right)
\]</div>
<div class="math notranslate nohighlight">
\[
\vdots
\]</div>
<div class="math notranslate nohighlight">
\[
    A^j = diag \left(\lambda_1^j, \lambda_2^j, \lambda_3^j, \dotsc, \lambda_N^j \right) , \forall j \in \mathbb{N}
\]</div>
<div class="math notranslate nohighlight">
\[
\vdots
\]</div>
<p>so</p>
<div class="math notranslate nohighlight">
\[
    e^A \doteq \sum_{i=0}^{\infty} \frac{A^i}{i!} = diag\left(\sum_{i=0}^{\infty} \frac{\lambda_1^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_2^i}{i!}, \sum_{i=0}^{\infty} \frac{\lambda_3^i}{i!}, \dotsc, \sum_{i=0}^{\infty} \frac{\lambda_N^i}{i!}\right)
\]</div>
<div class="math notranslate nohighlight">
\[
    = diag \left( e^{\lambda_1}, e^{\lambda_2}, e^{\lambda_3}, \dotsc, e^{\lambda_N} \right).
\]</div>
<p>In the same way, if B is a diagonal by blocks matrix:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
B =   
\left[ {\begin{array}{ccccc}
    B_1 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; B_2 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; B_3 &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; B_{N}\\
\end{array} } \right] 
  = diag(B_1, B_2, B_3, \dotsm, B_N),
\end{split}\]</div>
<p>then</p>
<div class="math notranslate nohighlight">
\[
e^B = diag(e^{B_1}, e^{B_2}, e^{B_3}, \dotsm, e^{B_N}).
\]</div>
</section>
<section id="exponential-of-a-matrix-of-ones-above-the-diagonal">
<h3>Exponential of a matrix of ones above the diagonal<a class="headerlink" href="#exponential-of-a-matrix-of-ones-above-the-diagonal" title="Permalink to this headline">#</a></h3>
<p>If <span class="math notranslate nohighlight">\(A = A_{N \times N} =   
\left[ {\begin{array}{ccccccc}
    0 &amp; 1 &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] \)</span>,</p>
<p>one can calculate</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A^2 = A \cdot A =  
\left[ {\begin{array}{ccccccc}
    0 &amp; 1 &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right]  \cdot 
\left[ {\begin{array}{ccccccc}
    0 &amp; 1 &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
  =   \left[ {\begin{array}{ccccccc}
    0 &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right], 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    A^3 = A \cdot A^2 = \left[ {\begin{array}{ccccccc}
    0 &amp; 1 &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccccc}
    0 &amp; 0 &amp; 1 &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccccc}
    0 &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 0 &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 0 &amp; \ddots &amp; 1\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right],
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
    \vdots
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    A^{N-2} = \left[ {\begin{array}{ccccccc}
     &amp;  &amp;  &amp;  &amp; 0 &amp; 1 &amp; 0\\
     &amp;  &amp;  &amp;  &amp;  &amp; 0 &amp; 1 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
\end{array} } \right],
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    A^{N-1} = \left[ {\begin{array}{ccccccc}
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 1\\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
\end{array} } \right],
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
    A^{N} = 0.
\]</div>
<p>And then, with <span class="math notranslate nohighlight">\(t \in \mathbb{R}\)</span></p>
<div class="math notranslate nohighlight">
\[
    e^{tA} \doteq \sum_{i=0}^{\infty} \frac{tA^i}{i!}
\]</div>
<div class="math notranslate nohighlight">
\[
    = Id + tA + \frac{t^2 A^2}{2} + \frac{t^3 A^3}{6} + \dotsc + \frac{t^{N-2} A^{N-2}}{(N-2)!} + \frac{t^{N-1} A^{N-1}}{(N-1)!} + 0 + 0 + \dotsc + 0
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 &amp;  &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 1 &amp;  &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 1 &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 1 &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 1 &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp;\\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 1 \\
\end{array} } \right] + \left[ {\begin{array}{ccccccc}
    0 &amp; t &amp;  &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; t &amp;  &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; t &amp;  &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; t &amp;  &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; t \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] + 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
+ \left[ {\begin{array}{ccccccc}
    0 &amp; 0 &amp; \frac{t^2}{2} &amp;  &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 0 &amp; \frac{t^2}{2} &amp;  &amp;  &amp;\\
     &amp;  &amp; 0 &amp; 0 &amp; \frac{t^2}{2} &amp;  &amp;\\
     &amp;  &amp;  &amp; 0 &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp;  &amp; 0 &amp; \ddots &amp; \frac{t^2}{2} \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; 0 \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 0 \\
\end{array} } \right] + \dotsc + \left[ {\begin{array}{ccccccc}
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; \frac{t^{N-1}}{(N-1)!}\\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
\end{array} } \right]
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    = \left[ {\begin{array}{ccccccc}
    1 &amp; t &amp; \frac{t^2}{2} &amp; \frac{t^3}{3!} &amp; \frac{t^4}{4!} &amp; \dotsc &amp; \frac{t^{N-1}}{(N-1)!}\\
     &amp; 1 &amp; t &amp; \frac{t^2}{2} &amp; \frac{t^3}{3!} &amp; \ddots &amp; \vdots \\
     &amp;  &amp; 1 &amp; t &amp; \frac{t^2}{2} &amp; \ddots &amp; \frac{t^4}{4!}\\
     &amp;  &amp;  &amp; 1 &amp; t &amp; \ddots &amp; \frac{t^3}{3!}\\
     &amp;  &amp;  &amp;  &amp; 1 &amp; \ddots &amp; \frac{t^2}{2} \\
     &amp;  &amp;  &amp;  &amp;  &amp; \ddots &amp; t \\
     &amp;  &amp;  &amp;  &amp;  &amp;  &amp; 1 \\
\end{array} } \right].
\end{split}\]</div>
</section>
<section id="exponential-of-a-jordan-block">
<h3>Exponential of a Jordan block<a class="headerlink" href="#exponential-of-a-jordan-block" title="Permalink to this headline">#</a></h3>
<p><span class="math notranslate nohighlight">\(\textbf{Proposition:}\)</span> <span class="math notranslate nohighlight">\(A_1, A_2 \in \mathscr{M}_{N \times N}(\mathbb{C})\)</span>. If <span class="math notranslate nohighlight">\(A_1 \cdot A_2 = A_2 \cdot A_1\)</span>, then <span class="math notranslate nohighlight">\(e^{A_1+A_2} = e^{A_1} \cdot e^{A_2}\)</span>.</p>
<p>A Jordan block is of the form:
$<span class="math notranslate nohighlight">\(
J = \left[ {\begin{array}{ccccc}
    \lambda_i &amp; 1 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_i &amp; 1 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_i &amp; \ddots &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; 1\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_i\\
\end{array} } \right] 
\)</span>$</p>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccc}
    \lambda_i &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_i &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_i &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_i\\
\end{array} } \right] + \left[ {\begin{array}{ccccc}
    0 &amp; 1 &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp; \ddots &amp; 1\\
     &amp;  &amp;  &amp;  &amp; 0\\
\end{array} } \right] 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[
    = D + N,
\]</div>
<p>and
$<span class="math notranslate nohighlight">\(
\left[ {\begin{array}{ccccc}
    \lambda_i &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_i &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_i &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_i\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    0 &amp; 1 &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp; \ddots &amp; 1\\
     &amp;  &amp;  &amp;  &amp; 0\\
\end{array} } \right] 
\)</span>$</p>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccc}
    0 &amp; \lambda_i &amp;  &amp;  &amp; \\
     &amp; 0 &amp; \lambda_i &amp;  &amp;\\
     &amp;  &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp; \ddots &amp; \lambda_i\\
     &amp;  &amp;  &amp;  &amp; 0\\
\end{array} } \right] 
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccc}
    0 &amp; 1 &amp;  &amp;  &amp; \\
     &amp; 0 &amp; 1 &amp;  &amp;\\
     &amp;  &amp; 0 &amp; \ddots &amp;\\
     &amp;  &amp;  &amp; \ddots &amp; 1\\
     &amp;  &amp;  &amp;  &amp; 0\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    \lambda_i &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_i &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_i &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_i\\
\end{array} } \right],
\end{split}\]</div>
<p>so</p>
<div class="math notranslate nohighlight">
\[
    e^{tJ} = e^{tD+tN} = e^{tD} \cdot e^{tN}
\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; e^{t \lambda_i} &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; e^{t \lambda_i} &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; e^{t \lambda_i}\\
\end{array} } \right] \cdot \left[ {\begin{array}{ccccc}
    1 &amp; t &amp; \frac{t^2}{2} &amp; \dotsc &amp; \frac{t^{N-1}}{(N-1)!}\\
     &amp; 1 &amp; t &amp; \ddots &amp; \vdots\\
     &amp;  &amp; 1 &amp; \ddots &amp; \frac{t^2}{2} \\
     &amp;  &amp;  &amp; \ddots &amp; t \\
     &amp;  &amp;  &amp;  &amp; 1 \\
\end{array} } \right]
\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
= \left[ {\begin{array}{ccccc}
    e^{t \lambda_i} &amp; e^{t \lambda_i}t &amp; \frac{e^{t \lambda_i} t^2}{2} &amp; \dotsc &amp; \frac{e^{t \lambda_i} t^{N-1}}{(N-1)!}\\
     &amp; e^{t \lambda_i} &amp; e^{t \lambda_i} t &amp; \ddots &amp; \vdots\\
     &amp;  &amp; e^{t \lambda_i} &amp; \ddots &amp; \frac{e^{t \lambda_i} t^2}{2} \\
     &amp;  &amp;  &amp; \ddots &amp; e^{t \lambda_i} t \\
     &amp;  &amp;  &amp;  &amp; e^{t \lambda_i} \\
\end{array} } \right], t \in \mathbb{R}.
\end{split}\]</div>
</section>
<section id="exponential-of-any-matrix">
<h3>Exponential of any matrix<a class="headerlink" href="#exponential-of-any-matrix" title="Permalink to this headline">#</a></h3>
<p><span class="math notranslate nohighlight">\(\textbf{Proposition: } \forall A \in \mathscr{M}_{N \times N}(\mathbb{C}), \exists M \in \mathscr{M}_{N \times N}(\mathbb{C})\)</span> invertible, such that <span class="math notranslate nohighlight">\(A = MJM^{-1}\)</span>, with</p>
<div class="math notranslate nohighlight">
\[\begin{split} 
J = \left[ {\begin{array}{ccccc}
    J_1 &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; J_2 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; J_3 &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; J_{N}\\
\end{array} } \right]
\end{split}\]</div>
<p>and each <span class="math notranslate nohighlight">\(J_i\)</span>, <span class="math notranslate nohighlight">\(i = 1, 2, 3, \dotsc, N\)</span> being a Jordan block, i.e.,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
J_i = \left[ {\begin{array}{ccccc}
    \lambda_i &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; \lambda_i &amp; 0 &amp; \dotsm &amp; 0\\
    0 &amp; 0 &amp; \lambda_i &amp; \dotsm &amp; 0\\
    \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
    0 &amp; 0 &amp; 0 &amp; \dotsm &amp; \lambda_i\\
\end{array} } \right]
\end{split}\]</div>
<p>for some <span class="math notranslate nohighlight">\(\lambda_i \in \mathbb{C}\)</span> .</p>
<p>Note that
$<span class="math notranslate nohighlight">\(
    (MJM^{-1})^k = MJM^{-1}MJM^{-1}MJM^{-1} \dotsc MJM^{-1} 
\)</span>$</p>
<div class="math notranslate nohighlight">
\[
    = MJIJIJM^{-1} \dotsc MJM^{-1} = MJJJ \dotsc JM^{-1} = MJ^kM^{-1}.
\]</div>
<p>Because of the formula of the series that defines the expansion, it implicates in <span class="math notranslate nohighlight">\(e^{MJM^{-1}} = M e^J M^{-1}\)</span>.</p>
<p>And then, using the same notation from the last proposition,
$<span class="math notranslate nohighlight">\(
e^{tA} = e^{tMJM^{-1}} = e^{MtJM^{-1}} = Me^{tJ}M^{-1} 
\)</span>$</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    = M \left[ { \begin{array}{ccccc}
        e^{tJ_1} &amp; 0 &amp; 0 &amp; \dotsm &amp; 0\\
        0 &amp; e^{tJ_2} &amp; 0 &amp; \dotsm &amp; 0\\
        0 &amp; 0 &amp; e^{tJ_3} &amp; \dotsm &amp; 0\\
        \vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots\\
        0 &amp; 0 &amp; 0 &amp; \dotsm &amp; e^{tJ_{N}}\\
    \end{array} } \right] M^{-1}, t \in \mathbb{R},
\end{split}\]</div>
<p>with each block as the section above indicates.</p>
</section>
</section>
<section id="euler-method">
<h2>Euler method<a class="headerlink" href="#euler-method" title="Permalink to this headline">#</a></h2>
<p>Further detailing this explicit one-step method of</p>
<div class="math notranslate nohighlight">
\[
    \phi (t_{k},y_{k},h) = f(t_{k},y_{k}),
\]</div>
<p>an analysis on stability, convergence and order of convergence is done.</p>
<section id="stability">
<h3>Stability<a class="headerlink" href="#stability" title="Permalink to this headline">#</a></h3>
<p>For the problem
<span class="math notranslate nohighlight">\(\begin{cases}
    y'(t) = - \lambda y(t) \text{ ; } t \in [t_0 , T] \\
    y(t_0)=y_0,
\end{cases}\)</span></p>
<p>with known solution</p>
<div class="math notranslate nohighlight">
\[ y(t) = y_0e^{-\lambda (t-t_0)},\]</div>
<p>the method turn into:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y_0 = y(t_0)\\
\textbf{for } k = 0, 1, 2, ..., N-1 :\\
    y_{k+1} = y_k + h \lambda y_k \\
    t_{k+1} = t_k + h.
\end{split}\]</div>
<p>Then the amplification factor is:
$<span class="math notranslate nohighlight">\(
(1 - h \lambda).
\)</span>$</p>
<p>If</p>
<div class="math notranslate nohighlight">
\[
|1 - h \lambda| &gt; 1, \text{for fixed } N,
\]</div>
<p>it will be a divergent series</p>
<div class="math notranslate nohighlight">
\[
(k \rightarrow \infty \Rightarrow y_k \rightarrow \infty),
\]</div>
<p>so, since the computer has a limitant number that can represent, even if the number of steps is such that <span class="math notranslate nohighlight">\(h\)</span> is not small enought, it might have sufficient steps to reach the maximum number represented by the machine.</p>
<p>However, if</p>
<div class="math notranslate nohighlight">
\[
    |1 - h \lambda| &lt; 1 \text{ and } N \text{ is fixed,}
\]</div>
<p>it converges to zero</p>
<div class="math notranslate nohighlight">
\[
    (k \rightarrow \infty \Rightarrow y_k \rightarrow 0 ).
\]</div>
<p>Besides that,</p>
<div class="math notranslate nohighlight">
\[
|1 - h \lambda| &lt; 1
\]</div>
<p>is the same as</p>
<div class="math notranslate nohighlight">
\[
0 &lt; h \lambda &lt; 2.
\]</div>
<p>So the interval of stability is <span class="math notranslate nohighlight">\((0,2)\)</span>.</p>
<p>Thats why the method suddenly converged, it was when <span class="math notranslate nohighlight">\(h\)</span> got small enought to <span class="math notranslate nohighlight">\(h \lambda\)</span> be in the interval of stability, i.e.,</p>
<div class="math notranslate nohighlight">
\[
    h &lt; 2/\lambda.
\]</div>
<p>It is worth mentioning here that if</p>
<div class="math notranslate nohighlight">
\[
-1 &lt; 1 - h \lambda &lt; 0,
\]</div>
<p>the error will converge oscillating since it takes positive values with even exponents and negative with odd ones.</p>
</section>
<section id="convergence">
<h3>Convergence<a class="headerlink" href="#convergence" title="Permalink to this headline">#</a></h3>
<p>Since</p>
<div class="math notranslate nohighlight">
\[
\lim_{m \to +\infty} \left(1 + \frac{p}{m} \right)^m = e^p,
\]</div>
<p>and h = <span class="math notranslate nohighlight">\(\frac{T-t_0}{N}\)</span>, for <span class="math notranslate nohighlight">\(y_N\)</span> we have</p>
<div class="math notranslate nohighlight">
\[
\lim_{N \to +\infty} y_N = \lim_{N \to +\infty} \left(1 - h \lambda \right)^N y_0 = \lim_{N \to +\infty} \left(1 - \frac{(T-t_0) \lambda}{N} \right)^N y_0.
\]</div>
<p>It is reasonable to take <span class="math notranslate nohighlight">\(p = -(T-t_0) \lambda\)</span> and conclude that the last point estimated by the method will converge to</p>
<div class="math notranslate nohighlight">
\[
y_0e^{-\lambda (T-t_0)}.
\]</div>
<p>Which is precisely <span class="math notranslate nohighlight">\(y(T)\)</span> and proves the convergence.</p>
</section>
<section id="order-of-convergence">
<h3>Order of convergence<a class="headerlink" href="#order-of-convergence" title="Permalink to this headline">#</a></h3>
<p>Being <span class="math notranslate nohighlight">\(\tau(h, t_k)\)</span> the local truncation error.</p>
<p>From</p>
<div class="math notranslate nohighlight">
\[
    y(t_{k+1}) = y(t_k) + h f(y(t_k),t_k) + O(h^2),
\]</div>
<p>we have</p>
<div class="math notranslate nohighlight">
\[
    h \tau(h, t_k) \doteq \frac{y(t_{k+1}) - y(t_k)}{h} - f(t_k, y(t_k)) = O(h^2),
\]</div>
<p>so</p>
<div class="math notranslate nohighlight">
\[
    \tau(h, t_k) = O(h).
\]</div>
<p>Since for one step methods the order of convergence is the order of the local truncation error, the order is of <span class="math notranslate nohighlight">\(O(h)\)</span>, order 1.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Participation_in_scientific_event%2C_list_of_publications_and_list_of_papers_prepared_or_submitted.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title">Participation in scientific event, list of publications and list of papers prepared or submitted</p>
        </div>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Isabela Miki Suzuki<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>